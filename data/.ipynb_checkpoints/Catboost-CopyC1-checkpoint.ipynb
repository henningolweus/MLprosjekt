{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c788fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6686ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a = pd.read_csv('cleaned_data/A/x_train_a.csv')\n",
    "x_train_b = pd.read_csv('cleaned_data/B/x_train_b.csv')\n",
    "x_train_c = pd.read_csv('cleaned_data/C/x_train_c.csv')\n",
    "\n",
    "x_test_a = pd.read_csv('cleaned_data/A/x_test_a.csv')\n",
    "x_test_b = pd.read_csv('cleaned_data/B/x_test_b.csv')\n",
    "x_test_c = pd.read_csv('cleaned_data/C/x_test_c.csv')\n",
    "\n",
    "train_a = pd.read_csv('cleaned_data/A/train_a.csv')\n",
    "train_b = pd.read_csv('cleaned_data/B/train_b.csv')\n",
    "train_c = pd.read_csv('cleaned_data/C/train_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15168876-f69f-4967-aebe-25abf4551bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx_train_a = pd.read_csv('cleaned_data_Henning/A/x_train_a.csv')\\nx_train_b = pd.read_csv('cleaned_data_Henning/B/x_train_b.csv')\\nx_train_c = pd.read_csv('cleaned_data_Henning/C/x_train_c.csv')\\n\\nx_test_a = pd.read_csv('cleaned_data_Henning/A/x_test_a.csv')\\nx_test_b = pd.read_csv('cleaned_data_Henning/B/x_test_b.csv')\\nx_test_c = pd.read_csv('cleaned_data_Henning/C/x_test_c.csv')\\n\\ntrain_a = pd.read_csv('cleaned_data_Henning/A/train_a.csv')\\ntrain_b = pd.read_csv('cleaned_data_Henning/B/train_b.csv')\\ntrain_c = pd.read_csv('cleaned_data_Henning/C/train_c.csv')\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x_train_a = pd.read_csv('cleaned_data_Henning/A/x_train_a.csv')\n",
    "x_train_b = pd.read_csv('cleaned_data_Henning/B/x_train_b.csv')\n",
    "x_train_c = pd.read_csv('cleaned_data_Henning/C/x_train_c.csv')\n",
    "\n",
    "x_test_a = pd.read_csv('cleaned_data_Henning/A/x_test_a.csv')\n",
    "x_test_b = pd.read_csv('cleaned_data_Henning/B/x_test_b.csv')\n",
    "x_test_c = pd.read_csv('cleaned_data_Henning/C/x_test_c.csv')\n",
    "\n",
    "train_a = pd.read_csv('cleaned_data_Henning/A/train_a.csv')\n",
    "train_b = pd.read_csv('cleaned_data_Henning/B/train_b.csv')\n",
    "train_c = pd.read_csv('cleaned_data_Henning/C/train_c.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad434433-3ded-4a2f-b51a-44977b1004ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_train_a = add_week_feat(x_train_a)\\nx_train_b = add_week_feat(x_train_b)\\nx_train_c = add_week_feat(x_train_c)\\n\\nx_test_a = add_week_feat(x_test_a)\\nx_test_b = add_week_feat(x_test_b)\\nx_test_c = add_week_feat(x_test_c)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_week_feat(df):\n",
    "\n",
    "    df['date_forecast'] = pd.to_datetime(df['date_forecast'])\n",
    "    \n",
    "    # Extract week number\n",
    "    df['week'] = df['date_forecast'].dt.isocalendar().week\n",
    "\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "x_train_a = add_week_feat(x_train_a)\n",
    "x_train_b = add_week_feat(x_train_b)\n",
    "x_train_c = add_week_feat(x_train_c)\n",
    "\n",
    "x_test_a = add_week_feat(x_test_a)\n",
    "x_test_b = add_week_feat(x_test_b)\n",
    "x_test_c = add_week_feat(x_test_c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d43bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a['time'] = pd.to_datetime(train_a['time'])\n",
    "train_b['time'] = pd.to_datetime(train_b['time'])\n",
    "train_c['time'] = pd.to_datetime(train_c['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd9be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a = x_test_a.drop(columns = ['date_forecast'])\n",
    "x_test_b = x_test_b.drop(columns = ['date_forecast'])\n",
    "x_test_c = x_test_c.drop(columns = ['date_forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34e17787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in X_train that has timestamp that does not exist in train_loc, and visa_verca\n",
    "#e.g missing solar power measurements from 2022-10-21 01:00 - 2022-10-28 21:00\n",
    "def align_X_y(x_train,y_train, x_date_column='date_forecast', y_date_column='time'):\n",
    "    \"\"\"\n",
    "    Aligns two dataframes based on the 'date_forecast' column of X and the 'time' column of y,\n",
    "    ensuring that only rows with matching time values are retained.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): The first dataframe with time in the 'date_forecast'\n",
    "    - y (pd.DataFrame): The second dataframe with time in the 'time' column.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the aligned dataframes.\n",
    "    \"\"\"\n",
    "    # Convert date columns to datetime format for easier comparison\n",
    "    x_train[x_date_column] = pd.to_datetime(x_train[x_date_column])\n",
    "    y_train[y_date_column] = pd.to_datetime(y_train[y_date_column])\n",
    "    \n",
    "    # Find common dates\n",
    "    common_dates = x_train[x_date_column][x_train[x_date_column].isin(y_train[y_date_column])]\n",
    "    \n",
    "    # Filter both datasets based on common dates\n",
    "    x_train_synced = x_train[x_train[x_date_column].isin(common_dates)]\n",
    "    y_train_synced = y_train[y_train[y_date_column].isin(common_dates)]\n",
    "    \n",
    "    return x_train_synced, y_train_synced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1a15d",
   "metadata": {},
   "source": [
    "# Analysis of Target variable  - Looking at PV_measurement\n",
    "1. Handle constant measurments over longer periods of time. Likely caused by sensor malfunction, data logging issues, or other external factors.\n",
    "    - Handeled by removing all constant values lasting more than 24 hours \n",
    "2. Add cyclical features \n",
    "2. Handle longer periods of missing data:\n",
    "    - Remove (currently tested)\n",
    "    - Interpolate \n",
    "    - Copy from previous year\n",
    "    - Copy solar production at missing time from another location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89446f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Handle constant PV measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5db23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series plot of PV_measurement \n",
    "\n",
    "def solar_prod_plot(y_train, resolution='year', chunks=5):\n",
    "    df = y_train.copy()\n",
    "    \n",
    "    # Determine the plotting resolution based on the 'resolution' argument\n",
    "    # Chunks = number of year/months/days in each plot\n",
    "    if resolution == 'year':\n",
    "        unique_values = df['time'].dt.year.unique()\n",
    "        label = 'Year'\n",
    "    elif resolution == 'month':\n",
    "        df['year_month'] = df['time'].dt.to_period('M')\n",
    "        unique_values = df['year_month'].unique()\n",
    "        label = 'Month'\n",
    "    elif resolution == 'week':\n",
    "        df['year_week'] = df['time'].dt.to_period('W')\n",
    "        unique_values = df['year_week'].unique()\n",
    "        label = 'Week'\n",
    "    elif resolution == 'day':\n",
    "        df['date'] = df['time'].dt.date\n",
    "        unique_values = df['date'].unique()\n",
    "        label = 'Day'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid resolution. Choose from 'year', 'month', 'week', or 'day'.\")\n",
    "    \n",
    "    # Loop over the unique values in chunks\n",
    "    for i in range(0, len(unique_values), chunks):\n",
    "        subset_values = unique_values[i:i+chunks]\n",
    "        \n",
    "        if resolution == 'year':\n",
    "            subset_df = df[df['time'].dt.year.isin(subset_values)]\n",
    "        elif resolution == 'month':\n",
    "            subset_df = df[df['year_month'].isin(subset_values)]\n",
    "        elif resolution == 'week':\n",
    "            subset_df = df[df['year_week'].isin(subset_values)]\n",
    "        elif resolution == 'day':\n",
    "            subset_df = df[df['date'].isin(subset_values)]\n",
    "        \n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(subset_df['time'], subset_df['pv_measurement'])\n",
    "\n",
    "        title = f\"Solar Power Production for {label}: {subset_values[0]}\"\n",
    "        if len(subset_values) > 1:\n",
    "            title += f\" to {subset_values[-1]}\"\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"PV Measurement\")\n",
    "        plt.show()\n",
    "\n",
    "def remove_constant_intervals(y_train, low_thresh, upp_thresh):\n",
    "    \"\"\"\n",
    "    Identify and remove intervals of constant PV readings that exceed a specified duration. \n",
    "    Constant readings may indicate sensor malfunctions or data logging issues.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_train : pd.DataFrame\n",
    "        Dataframe containing the time-series data of solar power production.\n",
    "    threshold : int\n",
    "        The minimum duration required for an interval to be considered for removal.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The input dataframe with intervals of constant readings (exceeding the duration threshold) removed.\n",
    "    \"\"\"\n",
    "    df = y_train.copy()\n",
    "    \n",
    "    # Calculate the difference in production values\n",
    "    df['diff'] = df['pv_measurement'].diff()\n",
    "\n",
    "    # Identify where the difference is zero\n",
    "    df['zero_diff'] = df['diff'].abs() < 1e-5\n",
    "\n",
    "    # Identify groups of consecutive zero differences\n",
    "    df['group'] = (df['zero_diff'] != df['zero_diff'].shift()).cumsum()\n",
    "\n",
    "    # Filter out only the groups with consecutive zero differences\n",
    "    constant_intervals = df[df['zero_diff']].groupby('group').agg(start=('time', 'min'), \n",
    "                                                                  end=('time', 'max'),\n",
    "                                                                  duration=('time', 'size'))\n",
    "    \n",
    "    # Filter intervals based on the threshold\n",
    "    interval_df_thresh = constant_intervals[(constant_intervals['duration'] > low_thresh) & (constant_intervals['duration'] <upp_thresh)]\n",
    "    \n",
    "    # Remove rows from the main dataframe that fall within these intervals\n",
    "    for _, row in interval_df_thresh.iterrows():\n",
    "        start_time, end_time = row['start'], row['end']\n",
    "        df = df[(df['time'] < start_time) | (df['time'] > end_time)]\n",
    "    \n",
    "    # Drop the added columns used for calculations\n",
    "    df.drop(columns=['diff', 'zero_diff', 'group'], inplace=True)\n",
    "    \n",
    "    return df, constant_intervals\n",
    "\n",
    "\n",
    "def get_time_interval(df, start_time = '2020-08-01 00:00:00', end_time = '2021-01-01 00:00:00'):\n",
    "    # Filter rows based on the time period\n",
    "    filtered_df = df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e1af31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed all constant values with duration > 24 hours\n",
    "\n",
    "train_a, const_interval_a = remove_constant_intervals(train_a,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_a, train_a = align_X_y(x_train_a, train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a90e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2020-01-04 15:00:00</td>\n",
       "      <td>2020-01-06 08:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "434   2020-01-04 15:00:00 2020-01-06 08:00:00        42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed_a = np.sum(const_interval_a[const_interval_a['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed_a}')\n",
    "const_interval_a[const_interval_a['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d4bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in groups of constant values, where duration of constant measurements is > 1 day (24 hours)\n",
    "train_b, const_interval_b = remove_constant_intervals(train_b,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_b, train_b = align_X_y(x_train_b, train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd0cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 6865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-01-14 15:00:00</td>\n",
       "      <td>2019-01-18 11:00:00</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-01-19 13:00:00</td>\n",
       "      <td>2019-01-26 08:00:00</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-01-27 11:00:00</td>\n",
       "      <td>2019-01-28 13:00:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2019-02-10 16:00:00</td>\n",
       "      <td>2019-02-13 07:00:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-03-23 18:00:00</td>\n",
       "      <td>2019-03-26 06:00:00</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2019-05-31 08:00:00</td>\n",
       "      <td>2019-06-03 12:00:00</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2019-10-28 14:00:00</td>\n",
       "      <td>2019-10-30 22:00:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2019-12-01 13:00:00</td>\n",
       "      <td>2019-12-04 08:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>2019-12-07 14:00:00</td>\n",
       "      <td>2019-12-11 08:00:00</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2019-12-18 14:00:00</td>\n",
       "      <td>2019-12-20 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>2019-12-25 14:00:00</td>\n",
       "      <td>2019-12-30 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2020-01-02 14:00:00</td>\n",
       "      <td>2020-01-04 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2020-01-04 14:00:00</td>\n",
       "      <td>2020-01-06 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2020-01-24 12:00:00</td>\n",
       "      <td>2020-01-26 08:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2020-02-05 14:00:00</td>\n",
       "      <td>2020-02-07 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2020-02-23 17:00:00</td>\n",
       "      <td>2020-02-25 09:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>2020-03-26 14:00:00</td>\n",
       "      <td>2020-03-27 21:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2020-04-02 02:00:00</td>\n",
       "      <td>2020-04-16 06:00:00</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2020-07-12 21:00:00</td>\n",
       "      <td>2020-08-25 21:00:00</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2020-09-24 13:00:00</td>\n",
       "      <td>2020-09-25 21:00:00</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>2020-12-16 14:00:00</td>\n",
       "      <td>2020-12-18 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>2020-12-26 14:00:00</td>\n",
       "      <td>2020-12-28 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>2021-01-09 14:00:00</td>\n",
       "      <td>2021-01-13 09:00:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2021-01-19 13:00:00</td>\n",
       "      <td>2021-01-21 09:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>2021-01-22 16:00:00</td>\n",
       "      <td>2021-01-24 08:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>2021-01-28 16:00:00</td>\n",
       "      <td>2021-01-30 08:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>2021-01-30 14:00:00</td>\n",
       "      <td>2021-02-01 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>2021-02-01 11:00:00</td>\n",
       "      <td>2021-02-03 08:00:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2021-02-18 00:00:00</td>\n",
       "      <td>2021-03-08 14:00:00</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2021-03-08 16:00:00</td>\n",
       "      <td>2021-04-19 11:00:00</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>2021-04-28 23:00:00</td>\n",
       "      <td>2021-05-01 21:00:00</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>2021-06-05 02:00:00</td>\n",
       "      <td>2021-06-07 07:00:00</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2021-06-13 02:00:00</td>\n",
       "      <td>2021-06-14 09:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>2021-06-22 02:00:00</td>\n",
       "      <td>2021-06-24 08:00:00</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2021-07-03 13:00:00</td>\n",
       "      <td>2021-07-06 05:00:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2021-08-25 23:00:00</td>\n",
       "      <td>2021-09-03 21:00:00</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>2021-09-08 13:00:00</td>\n",
       "      <td>2021-09-14 13:00:00</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2021-09-19 00:00:00</td>\n",
       "      <td>2021-09-27 08:00:00</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>2021-11-22 15:00:00</td>\n",
       "      <td>2021-11-24 08:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>2021-11-26 12:00:00</td>\n",
       "      <td>2021-12-04 08:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>2021-12-16 14:00:00</td>\n",
       "      <td>2021-12-18 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2021-12-21 14:00:00</td>\n",
       "      <td>2021-12-24 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2021-12-24 12:00:00</td>\n",
       "      <td>2022-01-03 09:00:00</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>2022-01-03 13:00:00</td>\n",
       "      <td>2022-01-11 09:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>2022-01-12 14:00:00</td>\n",
       "      <td>2022-01-14 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>2022-01-30 16:00:00</td>\n",
       "      <td>2022-02-04 09:00:00</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2022-02-10 15:00:00</td>\n",
       "      <td>2022-02-12 11:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>2022-02-14 16:00:00</td>\n",
       "      <td>2022-02-16 09:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2022-02-16 14:00:00</td>\n",
       "      <td>2022-02-18 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2022-02-19 10:00:00</td>\n",
       "      <td>2022-02-24 06:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2022-03-06 11:00:00</td>\n",
       "      <td>2022-03-07 11:00:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2022-03-19 14:00:00</td>\n",
       "      <td>2022-03-28 07:00:00</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2022-03-28 12:00:00</td>\n",
       "      <td>2022-04-05 06:00:00</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2023-01-15 15:00:00</td>\n",
       "      <td>2023-01-17 09:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "32    2019-01-14 15:00:00 2019-01-18 11:00:00        93\n",
       "36    2019-01-19 13:00:00 2019-01-26 08:00:00       164\n",
       "40    2019-01-27 11:00:00 2019-01-28 13:00:00        27\n",
       "74    2019-02-10 16:00:00 2019-02-13 07:00:00        64\n",
       "160   2019-03-23 18:00:00 2019-03-26 06:00:00        61\n",
       "302   2019-05-31 08:00:00 2019-06-03 12:00:00        77\n",
       "606   2019-10-28 14:00:00 2019-10-30 22:00:00        57\n",
       "674   2019-12-01 13:00:00 2019-12-04 08:00:00        68\n",
       "682   2019-12-07 14:00:00 2019-12-11 08:00:00        91\n",
       "700   2019-12-18 14:00:00 2019-12-20 09:00:00        44\n",
       "712   2019-12-25 14:00:00 2019-12-30 09:00:00       116\n",
       "724   2020-01-02 14:00:00 2020-01-04 08:00:00        43\n",
       "726   2020-01-04 14:00:00 2020-01-06 10:00:00        45\n",
       "768   2020-01-24 12:00:00 2020-01-26 08:00:00        45\n",
       "790   2020-02-05 14:00:00 2020-02-07 09:00:00        44\n",
       "824   2020-02-23 17:00:00 2020-02-25 09:00:00        41\n",
       "890   2020-03-26 14:00:00 2020-03-27 21:00:00        32\n",
       "906   2020-04-02 02:00:00 2020-04-16 06:00:00       341\n",
       "1090  2020-07-12 21:00:00 2020-08-25 21:00:00      1057\n",
       "1154  2020-09-24 13:00:00 2020-09-25 21:00:00        33\n",
       "1332  2020-12-16 14:00:00 2020-12-18 08:00:00        43\n",
       "1352  2020-12-26 14:00:00 2020-12-28 08:00:00        43\n",
       "1380  2021-01-09 14:00:00 2021-01-13 09:00:00        92\n",
       "1396  2021-01-19 13:00:00 2021-01-21 09:00:00        45\n",
       "1400  2021-01-22 16:00:00 2021-01-24 08:00:00        41\n",
       "1410  2021-01-28 16:00:00 2021-01-30 08:00:00        41\n",
       "1414  2021-01-30 14:00:00 2021-02-01 08:00:00        43\n",
       "1416  2021-02-01 11:00:00 2021-02-03 08:00:00        46\n",
       "1454  2021-02-18 00:00:00 2021-03-08 14:00:00       447\n",
       "1456  2021-03-08 16:00:00 2021-04-19 11:00:00      1003\n",
       "1478  2021-04-28 23:00:00 2021-05-01 21:00:00        71\n",
       "1550  2021-06-05 02:00:00 2021-06-07 07:00:00        54\n",
       "1564  2021-06-13 02:00:00 2021-06-14 09:00:00        32\n",
       "1582  2021-06-22 02:00:00 2021-06-24 08:00:00        55\n",
       "1602  2021-07-03 13:00:00 2021-07-06 05:00:00        65\n",
       "1710  2021-08-25 23:00:00 2021-09-03 21:00:00       215\n",
       "1722  2021-09-08 13:00:00 2021-09-14 13:00:00       145\n",
       "1734  2021-09-19 00:00:00 2021-09-27 08:00:00       201\n",
       "1858  2021-11-22 15:00:00 2021-11-24 08:00:00        42\n",
       "1864  2021-11-26 12:00:00 2021-12-04 08:00:00       189\n",
       "1894  2021-12-16 14:00:00 2021-12-18 09:00:00        44\n",
       "1902  2021-12-21 14:00:00 2021-12-24 09:00:00        68\n",
       "1904  2021-12-24 12:00:00 2022-01-03 09:00:00       238\n",
       "1906  2022-01-03 13:00:00 2022-01-11 09:00:00       189\n",
       "1910  2022-01-12 14:00:00 2022-01-14 08:00:00        43\n",
       "1948  2022-01-30 16:00:00 2022-02-04 09:00:00       114\n",
       "1966  2022-02-10 15:00:00 2022-02-12 11:00:00        45\n",
       "1972  2022-02-14 16:00:00 2022-02-16 09:00:00        42\n",
       "1974  2022-02-16 14:00:00 2022-02-18 10:00:00        45\n",
       "1978  2022-02-19 10:00:00 2022-02-24 06:00:00       117\n",
       "2004  2022-03-06 11:00:00 2022-03-07 11:00:00        25\n",
       "2032  2022-03-19 14:00:00 2022-03-28 07:00:00       209\n",
       "2034  2022-03-28 12:00:00 2022-04-05 06:00:00       187\n",
       "2196  2023-01-15 15:00:00 2023-01-17 09:00:00        43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed = np.sum(const_interval_b[const_interval_b['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed}')\n",
    "const_interval_b[const_interval_b['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d09483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in groups of constant values, where duration of constant measurements is > 1 day (24 hours)\n",
    "train_c, const_interval_c = remove_constant_intervals(train_c,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_c, train_c = align_X_y(x_train_c, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c619c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 4926\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-04 10:00:00</td>\n",
       "      <td>2019-09-05 12:00:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2019-11-11 12:00:00</td>\n",
       "      <td>2019-11-13 08:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2019-11-28 15:00:00</td>\n",
       "      <td>2019-12-05 09:00:00</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2019-12-07 14:00:00</td>\n",
       "      <td>2019-12-13 09:00:00</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2019-12-16 14:00:00</td>\n",
       "      <td>2019-12-21 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2019-12-25 13:00:00</td>\n",
       "      <td>2019-12-30 09:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2020-01-02 14:00:00</td>\n",
       "      <td>2020-01-07 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2020-01-23 15:00:00</td>\n",
       "      <td>2020-01-26 08:00:00</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2020-02-05 14:00:00</td>\n",
       "      <td>2020-02-10 07:00:00</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2020-02-23 17:00:00</td>\n",
       "      <td>2020-03-08 08:00:00</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2020-03-28 18:00:00</td>\n",
       "      <td>2020-03-31 09:00:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2020-11-18 13:00:00</td>\n",
       "      <td>2020-11-22 08:00:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2020-12-16 14:00:00</td>\n",
       "      <td>2020-12-18 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2020-12-21 14:00:00</td>\n",
       "      <td>2020-12-23 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>2020-12-25 14:00:00</td>\n",
       "      <td>2020-12-28 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2021-01-09 14:00:00</td>\n",
       "      <td>2021-01-22 10:00:00</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2021-01-22 15:00:00</td>\n",
       "      <td>2021-01-24 10:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>2021-01-24 13:00:00</td>\n",
       "      <td>2021-02-19 10:00:00</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>2021-03-03 17:00:00</td>\n",
       "      <td>2021-03-06 07:00:00</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>2021-03-08 14:00:00</td>\n",
       "      <td>2021-03-10 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>2021-03-20 18:00:00</td>\n",
       "      <td>2021-03-22 05:00:00</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2021-04-09 19:00:00</td>\n",
       "      <td>2021-04-11 08:00:00</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2021-11-24 14:00:00</td>\n",
       "      <td>2021-12-14 09:00:00</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2021-12-21 14:00:00</td>\n",
       "      <td>2022-01-16 10:00:00</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>2022-01-16 13:00:00</td>\n",
       "      <td>2022-01-18 10:00:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2022-01-19 14:00:00</td>\n",
       "      <td>2022-01-22 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2022-01-24 16:00:00</td>\n",
       "      <td>2022-01-26 10:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>2022-01-27 16:00:00</td>\n",
       "      <td>2022-01-30 08:00:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2022-01-30 15:00:00</td>\n",
       "      <td>2022-02-07 11:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2022-02-08 14:00:00</td>\n",
       "      <td>2022-03-02 09:00:00</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>2022-04-02 18:00:00</td>\n",
       "      <td>2022-04-04 09:00:00</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>2022-04-05 13:00:00</td>\n",
       "      <td>2022-04-08 09:00:00</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2023-02-19 14:00:00</td>\n",
       "      <td>2023-02-21 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2023-02-21 16:00:00</td>\n",
       "      <td>2023-02-23 09:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "2     2019-09-04 10:00:00 2019-09-05 12:00:00        27\n",
       "180   2019-11-11 12:00:00 2019-11-13 08:00:00        45\n",
       "230   2019-11-28 15:00:00 2019-12-05 09:00:00       163\n",
       "240   2019-12-07 14:00:00 2019-12-13 09:00:00       140\n",
       "256   2019-12-16 14:00:00 2019-12-21 09:00:00       116\n",
       "276   2019-12-25 13:00:00 2019-12-30 09:00:00       117\n",
       "290   2020-01-02 14:00:00 2020-01-07 09:00:00       116\n",
       "340   2020-01-23 15:00:00 2020-01-26 08:00:00        66\n",
       "376   2020-02-05 14:00:00 2020-02-10 07:00:00       114\n",
       "414   2020-02-23 17:00:00 2020-03-08 08:00:00       328\n",
       "484   2020-03-28 18:00:00 2020-03-31 09:00:00        64\n",
       "1150  2020-11-18 13:00:00 2020-11-22 08:00:00        92\n",
       "1238  2020-12-16 14:00:00 2020-12-18 08:00:00        43\n",
       "1252  2020-12-21 14:00:00 2020-12-23 09:00:00        44\n",
       "1264  2020-12-25 14:00:00 2020-12-28 09:00:00        68\n",
       "1312  2021-01-09 14:00:00 2021-01-22 10:00:00       309\n",
       "1316  2021-01-22 15:00:00 2021-01-24 10:00:00        44\n",
       "1318  2021-01-24 13:00:00 2021-02-19 10:00:00       622\n",
       "1358  2021-03-03 17:00:00 2021-03-06 07:00:00        63\n",
       "1374  2021-03-08 14:00:00 2021-03-10 08:00:00        43\n",
       "1408  2021-03-20 18:00:00 2021-03-22 05:00:00        36\n",
       "1458  2021-04-09 19:00:00 2021-04-11 08:00:00        38\n",
       "2122  2021-11-24 14:00:00 2021-12-14 09:00:00       476\n",
       "2146  2021-12-21 14:00:00 2022-01-16 10:00:00       621\n",
       "2148  2022-01-16 13:00:00 2022-01-18 10:00:00        46\n",
       "2152  2022-01-19 14:00:00 2022-01-22 09:00:00        68\n",
       "2164  2022-01-24 16:00:00 2022-01-26 10:00:00        43\n",
       "2168  2022-01-27 16:00:00 2022-01-30 08:00:00        65\n",
       "2172  2022-01-30 15:00:00 2022-02-07 11:00:00       189\n",
       "2178  2022-02-08 14:00:00 2022-03-02 09:00:00       524\n",
       "2284  2022-04-02 18:00:00 2022-04-04 09:00:00        40\n",
       "2290  2022-04-05 13:00:00 2022-04-08 09:00:00        69\n",
       "2486  2023-02-19 14:00:00 2023-02-21 10:00:00        45\n",
       "2490  2023-02-21 16:00:00 2023-02-23 09:00:00        42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed = np.sum(const_interval_c[const_interval_c['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed}')\n",
    "const_interval_c[const_interval_c['duration']>24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295598a-c357-4143-898f-f57bc361c20f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merge x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7084bebc-37bb-4a70-afd6-5d22049f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a = pd.merge(x_train_a, train_a, left_on='date_forecast', right_on='time', how='inner')\n",
    "merged_b = pd.merge(x_train_b, train_b, left_on='date_forecast', right_on='time', how='inner')\n",
    "merged_c = pd.merge(x_train_c, train_c, left_on='date_forecast', right_on='time', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46b11c-5cb0-445c-aa2c-b16a28f93dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are plotting on the modified dataset\n",
    "def time_series_plot(feature,merged_data):\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Solar Power Production', color='tab:blue')\n",
    "    ax1.plot(merged_data['time'], merged_data['pv_measurement'], color='tab:blue', label='Solar Power Production')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel(feature, color='tab:red')  \n",
    "    ax2.plot(merged_data['date_forecast'], merged_data[feature], color='tab:red', label=feature)\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'Time Series Plot of Solar Power Production and {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c9108-c9fe-423c-a2d3-249b198af636",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add avg pv_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25519486-5b0a-40f0-9522-9c8bd35de95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_average_pv_feature(merged_df, test_df,time_group):\n",
    "    df = merged_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    # Group by year, month, date, and hour and calculate the mean PV measurement\n",
    "    average_pv = df.groupby(time_group)['pv_measurement'].mean().reset_index()\n",
    "    average_pv = average_pv.rename(columns={'pv_measurement': 'average_pv_measurement'})\n",
    "\n",
    "    # Print for debugging\n",
    "\n",
    "\n",
    "    # Merge the average PV measurements back into the original dataframe\n",
    "    df = pd.merge(df, average_pv, on=time_group, how='left')\n",
    "    test_df = pd.merge(test_df, average_pv, on= time_group, how='left')\n",
    "    \n",
    "    # Print for debugging\n",
    "    return df,test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3f3b8-8765-4e8c-ab27-edfaa70d4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_group_1 = ['month', 'day', 'hour']\n",
    "time_group_2 = 'week'\n",
    "time_group_3 = 'month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c158542-fd5c-43a4-a308-18ad66b8d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a_avg, x_test_a_avg = add_average_pv_feature(merged_a,x_test_a,time_group_1)\n",
    "merged_b_avg, x_test_b_avg = add_average_pv_feature(merged_b,x_test_b, time_group_1)\n",
    "merged_c_avg, x_test_c_avg = add_average_pv_feature(merged_c,x_test_c,time_group_1)\n",
    "\n",
    "merged_a_avg[(merged_a_avg['month']==6) & (merged_a_avg['day']==4) & (merged_a_avg['hour']==16)][['year','month','week','day','hour','pv_measurement','average_pv_measurement']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedcdb7f-cabb-4695-90ca-ab8a5a283e42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0aae5e-3b81-426d-a165-06f346b3e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_feature(data, lag_hours, column_name='pv_measurement'):\n",
    "    \"\"\"\n",
    "    Add lag features to the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The original dataset.\n",
    "    lag_hours (int): The number of hours to lag.\n",
    "    column_name (str): The name of the column to create the lag feature for.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The dataset with the new lag feature.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the lag feature\n",
    "    df = data.copy()\n",
    "    lag_feature_name = f\"{column_name}_lag_{lag_hours}h\"\n",
    "    df[lag_feature_name] = df[column_name].shift(lag_hours)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6563274-2059-4198-a061-2875448f9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "laged_a = add_lag_feature(merged_a,24)\n",
    "laged_b = add_lag_feature(merged_b,24)\n",
    "laged_c = add_lag_feature(merged_c,24)\n",
    "\n",
    "x_test_a_laged = x_test_a.copy()\n",
    "x_test_b_laged = x_test_b.copy()\n",
    "x_test_c_laged = x_test_c.copy()\n",
    "\n",
    "\n",
    "# You can add an empty column for the lag feature in your test set:\n",
    "x_test_a_laged[f'pv_measurement_lag_{1}h'] = None\n",
    "x_test_b_laged[f'pv_measurement_lag_{1}h'] = None\n",
    "x_test_c_laged[f'pv_measurement_lag_{1}h'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b9338-8fa4-41ed-bd50-584aafeb6421",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Handle NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f652a7-cec9-4c63-83ff-cf45ad74db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a['ceiling_height_agl:m'] = merged_a['ceiling_height_agl:m'].fillna(value = 0)\n",
    "merged_b['ceiling_height_agl:m'] = merged_b['ceiling_height_agl:m'].fillna(value = 0)\n",
    "merged_c['ceiling_height_agl:m'] = merged_c['ceiling_height_agl:m'].fillna(value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d8647",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add Cyclical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cyclical features for hour of the day\n",
    "def cyclic_hourly(x):\n",
    "    train_data = x.copy()\n",
    "    train_data['hour_sin'] = np.sin(2 * np.pi * train_data['hour'] / 24)\n",
    "    train_data['hour_cos'] = np.cos(2 * np.pi * train_data['hour'] / 24)\n",
    "    return train_data\n",
    "\n",
    "\n",
    "# Creating cyclical features for month of the year\n",
    "def cyclic_monthly(x):\n",
    "    train_data = x.copy()\n",
    "    train_data['month_sin'] = np.sin(2 * np.pi * train_data['month'] / 12)\n",
    "    train_data['month_cos'] = np.cos(2 * np.pi * train_data['month'] / 12)\n",
    "    return train_data\n",
    "\n",
    "\"\"\"\n",
    "x_train_a = cyclic_hourly(x_train_a)\n",
    "x_train_a = cyclic_monthly(x_train_a)\n",
    "\n",
    "x_test_a = cyclic_hourly(x_test_a)\n",
    "x_test_a = cyclic_monthly(x_test_a)\n",
    "\n",
    "x_train_b = cyclic_hourly(x_train_b)\n",
    "x_train_b = cyclic_monthly(x_train_b)\n",
    "\n",
    "x_test_b = cyclic_hourly(x_test_b)\n",
    "x_test_b = cyclic_monthly(x_test_b)\n",
    "\n",
    "x_train_c = cyclic_hourly(x_train_c)\n",
    "x_train_c = cyclic_monthly(x_train_c)\n",
    "\n",
    "x_test_c = cyclic_hourly(x_test_c)\n",
    "x_test_c = cyclic_monthly(x_test_c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab20ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Remove outliers during night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hourly_avg(y_train):\n",
    "    # Grouping by hour and calculating the average PV measurement for each hour\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "    hourly_avg = train_data.groupby('hour')['pv_measurement'].mean()\n",
    "\n",
    "    # Plotting the average PV production for each hour\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    hourly_avg.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Average PV Production by Hour')\n",
    "    plt.xlabel('Hour of the Day')\n",
    "    plt.ylabel('Average PV Production')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_dist_hour(y_train, hour):\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "    \n",
    "    # Filtering the data for the given hour\n",
    "    hour_data = train_data[train_data['hour'] == hour]\n",
    "    \n",
    "    # Plotting the distribution of PV measurements for 1 am\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(hour_data['pv_measurement'], bins=50, color='teal', alpha=0.7)\n",
    "    plt.title(f'Distribution of PV Measurements at {hour}')\n",
    "    plt.xlabel('PV Measurement')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(hour_data['pv_measurement'].value_counts())\n",
    "#train_c[(train_c['time'].dt.hour == 2) &(train_c['pv_measurement'] == 9.8)]\n",
    "\n",
    "def get_nighttime_stats(y_train,night_start,night_end):\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "\n",
    "    # Filtering the data for nighttime hours (8 pm to 4 am)\n",
    "    nighttime_data = train_data[(train_data['hour'] >= night_start) | (train_data['hour'] <= night_end)]\n",
    "\n",
    "    # Descriptive statistics for nighttime PV measurements\n",
    "    nighttime_stats = nighttime_data['pv_measurement'].describe()\n",
    "\n",
    "    # Plotting the distribution of nighttime PV measurements\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(nighttime_data['pv_measurement'], bins=50, color='purple', alpha=0.7)\n",
    "    plt.axvline(nighttime_stats['75%'], color='red', linestyle='dashed', label='75th Percentile')\n",
    "    plt.axvline(nighttime_stats['max'], color='green', linestyle='dashed', label='Max Value')\n",
    "    plt.title('Distribution of Nighttime PV Measurements')\n",
    "    plt.xlabel('PV Measurement')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(nighttime_stats)\n",
    "    \n",
    "def set_nighttime_to_zero(y_train, night_start,night_end, thresh):\n",
    "    df = y_train.copy()\n",
    "    df['hour'] = y_train['time'].dt.hour\n",
    "    mask = (df['hour'] >= 23) | (df['hour'] <= 3) & (df['pv_measurement'] > thresh)\n",
    "    df.loc[mask, 'pv_measurement'] = 0\n",
    "    df = df.drop(columns = ['hour'])\n",
    "    return df\n",
    "\n",
    "#train_a[(train_a['time'].dt.hour == 2) &(train_a['pv_measurement'] >0)]\n",
    "#train_a = set_nighttime_to_zero(train_a,23,3,0)\n",
    "#train_b = set_nighttime_to_zero(train_b,23,3,0)\n",
    "#train_c = set_nighttime_to_zero(train_c,23,3,0)\n",
    "#train_a[(train_a['time'].dt.hour == 2) &(train_a['pv_measurement'] >0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fdf4a-51e1-41af-9e08-bd12e50f903a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Remove rows with high rad values and zero PV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ec7f2-9c3f-409b-b024-0f075b1ba9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rad_null(merged_df):\n",
    "    merged_data = merged_df.copy()\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad_1h:J'].fillna(0, inplace=True)\n",
    "    return merged_data\n",
    "\"\"\"\n",
    "m_a = remove_rad_null(merged_a)\n",
    "m_b = remove_rad_null(merged_b)\n",
    "m_c = remove_rad_null(merged_c)\n",
    "\"\"\"\n",
    "\n",
    "def get_percentiles_df(merged_df):\n",
    "    merged_data = merged_df.copy()\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad_1h:J'].fillna(0, inplace=True)\n",
    "\n",
    "    # Calculate and display percentiles\n",
    "    percentiles = [50,60,70,80,85,90,95]\n",
    "    percentile_values_direct_rad= np.percentile(merged_data['direct_rad:W'], percentiles)\n",
    "    percentile_values_direct_rad_1h = np.percentile(merged_data['direct_rad_1h:J'], percentiles)\n",
    "    percentile_values_clear_sky_rad = np.percentile(merged_data['clear_sky_rad:W'], percentiles)\n",
    "    percentile_values_clear_sky_energy = np.percentile(merged_data['clear_sky_energy_1h:J'], percentiles)\n",
    "    percentile_values_df = pd.DataFrame({\n",
    "        'Percentile': percentiles,\n",
    "        'direct_rad:W':percentile_values_direct_rad,\n",
    "        'direct_rad_1h:J': percentile_values_direct_rad_1h,\n",
    "        'clear_sky_rad:W': percentile_values_clear_sky_rad,\n",
    "        'clear_sky_energy_1h:J': percentile_values_clear_sky_energy\n",
    "        })\n",
    "    \n",
    "    return percentile_values_df\n",
    "\n",
    "def get_anomals(merged_data,feature,percentile): \n",
    "    #identify the rows where the \"direct_rad:W\" column in x_train_a is high\n",
    "    #but the PV measurement in train_a is zero -> Indicates wrong\n",
    "    \n",
    "    percentile_df = get_percentiles_df(merged_data)\n",
    "    \n",
    "    # Define a threshold for high solar radiation\n",
    "    threshold = percentile_df[percentile_df['Percentile']==percentile][feature].values[0],\n",
    "\n",
    "    # Find rows where 'direct_rad:W' is high but PV measurement is zero\n",
    "    anomalous_rows = merged_data[(merged_data[feature] > threshold) & (merged_data['pv_measurement'] == 0)]\n",
    "    \n",
    "    \n",
    "    # Display the anomalous rows\n",
    "    return anomalous_rows\n",
    "\"\"\"\n",
    "merged_a1 = merged_a.copy().drop(get_anomals(merged_a,'clear_sky_rad:W',90).index)\n",
    "merged_b1 = merged_b.copy().drop(get_anomals(merged_b,'direct_rad:W',90).index)\n",
    "merged_c1 = merged_c.copy().drop(get_anomals(merged_c,'direct_rad_1h:J',90).index)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5e046-dee0-480b-93eb-1e77befff30a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add avg pv at this time over the past week or month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ac698-54ab-4b43-8c88-42e9620dc386",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = merged_a.resample('7D', on='date_forecast',).mean()\n",
    "resampled_df['pv_measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33dc20-ae6c-4e3a-8be9-4298fb65f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_same_time_average(merged_df, period='7D'):\n",
    "    \n",
    "    df = merged_df.copy()\n",
    "    # Resample the data at the desired frequency\n",
    "    resampled_df = df.resample(period, on='date_forecast',).mean()\n",
    "    \n",
    "    \n",
    "    # Reindex the resampled data to match the original index, filling missing values by interpolation\n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6eeb4b-674d-4e18-90a1-46f390c507b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a['weekly_avg_pv_hourly'] = calculate_rolling_same_time_average(merged_a, '7D')\n",
    "\n",
    "# Calculate the rolling average at the same time over the past month\n",
    "#merged_a['monthly_avg_same_time'] = calculate_rolling_same_time_average(merged_a, '30D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bc698-2fdd-4e18-a8ed-9668d1ee8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7d537-27fa-4d76-b9f5-87a487493050",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add direct_rad * sun_elevation feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5b1dd-5ce5-4af4-8628-820e7bb1bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Did not improve kaggle score\n",
    "def add_rad_x_sun(merged_data):\n",
    "    df = merged_data.copy()\n",
    "    df['rad_x_sun_elevation'] = df['direct_rad:W']*df['sun_elevation:d']\n",
    "    return df\n",
    "\"\"\"\n",
    "mod_a = add_rad_x_sun(merged_a)\n",
    "mod_b = add_rad_x_sun(merged_b)\n",
    "mod_c = add_rad_x_sun(merged_c)\n",
    "\n",
    "x_test_a_mod = add_rad_x_sun(x_test_a)\n",
    "x_test_b_mod = add_rad_x_sun(x_test_b)\n",
    "x_test_c_mod = add_rad_x_sun(x_test_c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f54bf-c4c8-4177-8596-09a6821b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_plot('rad_x_sun_elevation',df.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fbaa3a-6a11-4d6d-8aca-2490ead53649",
   "metadata": {},
   "source": [
    "### Categorical Feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9317f8d-1845-497d-a5ea-def502c3f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_columns_to_cat(merged_data, cat_features):\n",
    "    df = merged_data.copy()\n",
    "    for col in cat_features:\n",
    "        df[col] = df[col].astype(str)\n",
    "    return df\n",
    "cat_features=['estimated','dew_or_rime:idx','is_day:idx','is_in_shadow:idx','precip_type_5min:idx','snow_drift:idx']\n",
    "cat_features1 = ['estimated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e55f9d-f2ab-48ea-977a-d20ba70f7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a_cat = convert_columns_to_cat(merged_a,cat_features1)\n",
    "merged_b_cat = convert_columns_to_cat(merged_b,cat_features1)\n",
    "merged_c_cat = convert_columns_to_cat(merged_c,cat_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629cd77-3549-4807-95ca-b5024c2cc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a_cat = convert_columns_to_cat(x_test_a,cat_features1)\n",
    "x_test_b_cat = convert_columns_to_cat(x_test_b,cat_features1)\n",
    "x_test_c_cat = convert_columns_to_cat(x_test_c,cat_features1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd791c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Catboost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d08c0333-1cb2-473c-9f34-5b9eea95f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def split_dataset(train_data, val_size=0.1, val = False, estimated_column = 'estimated'):\n",
    "    if val: \n",
    "        estimated_one = train_data[train_data[estimated_column] == 1]\n",
    "\n",
    "        #Split the filtered dataset into two\n",
    "        half_index = len(estimated_one) // 2\n",
    "        validation_set = estimated_one[half_index:]\n",
    "\n",
    "        # Combine the first half of observed_zero with the rest of the data where observed != 0\n",
    "        training_set = pd.concat([train_data[train_data[estimated_column] == 0], estimated_one[:half_index]])\n",
    "    else:\n",
    "        split_index = int(train_data.shape[0] * (1 - val_size))\n",
    "        training_set = train_data.iloc[:split_index]\n",
    "        validation_set = train_data.iloc[split_index:]\n",
    "    return training_set, validation_set\n",
    "\n",
    "\n",
    "def find_best_categorical_combination(df, cat_features, target_col='pv_measurement', iterations=2000, learning_rate=0.1, depth=6, random_seed=42):\n",
    "    best_mae = float('inf')\n",
    "    best_combination = []\n",
    "    best_model = None\n",
    "\n",
    "    # Iterate over all combinations of categorical features\n",
    "    for L in range(1, len(cat_features) + 1):\n",
    "        for subset in itertools.combinations(cat_features, L):\n",
    "            print(f\"Testing combination: {subset}\")\n",
    "            \n",
    "            # Convert the features in the subset to strings\n",
    "            for col in subset:\n",
    "                df[col] = df[col].astype(str)\n",
    "            \n",
    "            X = df.drop(columns=['pv_measurement'])\n",
    "            y = df['pv_measurement']\n",
    "            X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "            \n",
    "            # Initialize and fit the CatBoost model\n",
    "            catboost_model = CatBoostRegressor(\n",
    "                cat_features=list(subset),\n",
    "                iterations=iterations,\n",
    "                learning_rate=learning_rate,\n",
    "                depth=depth,\n",
    "                loss_function='MAE',\n",
    "                eval_metric='MAE',\n",
    "                random_seed=random_seed,\n",
    "                verbose=200\n",
    "            )\n",
    "            \n",
    "            catboost_model.fit(X_train, y_train, eval_set=(X_validation, y_validation), use_best_model=True, early_stopping_rounds=200)\n",
    "            \n",
    "            # Evaluate the model\n",
    "            predictions = catboost_model.predict(X_validation)\n",
    "            mae = mean_absolute_error(y_validation, predictions)\n",
    "            \n",
    "            # Update the best combination if the current one is better\n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_combination = subset\n",
    "                best_model = catboost_model\n",
    "\n",
    "    return best_model, best_combination, best_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bd98f7e-a049-4397-bfc0-0cf3746afa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=['estimated','dew_or_rime:idx','is_day:idx','is_in_shadow:idx','precip_type_5min:idx','snow_drift:idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50208ebf-19a4-439b-b928-aed728edd315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combination: ('estimated',)\n",
      "0:\tlearn: 592.3538894\ttest: 591.1188704\tbest: 591.1188704 (0)\ttotal: 69ms\tremaining: 2m 17s\n",
      "200:\tlearn: 186.7626008\ttest: 182.9270753\tbest: 182.9270753 (200)\ttotal: 2.32s\tremaining: 20.8s\n",
      "400:\tlearn: 173.6238514\ttest: 175.6059344\tbest: 175.6059344 (400)\ttotal: 4.53s\tremaining: 18.1s\n",
      "600:\tlearn: 165.6572712\ttest: 172.5737280\tbest: 172.5724128 (599)\ttotal: 6.67s\tremaining: 15.5s\n",
      "800:\tlearn: 159.7170395\ttest: 170.8376062\tbest: 170.7929389 (798)\ttotal: 8.75s\tremaining: 13.1s\n",
      "1000:\tlearn: 153.8277129\ttest: 169.3620220\tbest: 169.3598594 (998)\ttotal: 10.9s\tremaining: 10.8s\n",
      "1200:\tlearn: 149.6575256\ttest: 168.7140546\tbest: 168.7140546 (1200)\ttotal: 12.9s\tremaining: 8.59s\n",
      "1400:\tlearn: 146.0052578\ttest: 168.0433364\tbest: 168.0238633 (1399)\ttotal: 15s\tremaining: 6.41s\n",
      "1600:\tlearn: 142.1223233\ttest: 167.3706376\tbest: 167.3706376 (1600)\ttotal: 17.1s\tremaining: 4.25s\n",
      "1800:\tlearn: 139.3374800\ttest: 166.8226123\tbest: 166.8226123 (1800)\ttotal: 19.3s\tremaining: 2.13s\n",
      "1999:\tlearn: 136.7261493\ttest: 166.3038457\tbest: 166.2914231 (1979)\ttotal: 21.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.2914231\n",
      "bestIteration = 1979\n",
      "\n",
      "Shrink model to first 1980 iterations.\n",
      "Testing combination: ('dew_or_rime:idx',)\n",
      "0:\tlearn: 597.1378132\ttest: 595.7270253\tbest: 595.7270253 (0)\ttotal: 33.3ms\tremaining: 1m 6s\n",
      "200:\tlearn: 187.2562413\ttest: 183.6417580\tbest: 183.6417580 (200)\ttotal: 3.95s\tremaining: 35.3s\n",
      "400:\tlearn: 174.8701422\ttest: 177.2259326\tbest: 177.2089325 (397)\ttotal: 7.88s\tremaining: 31.4s\n",
      "600:\tlearn: 166.8086611\ttest: 174.1786716\tbest: 174.1784667 (598)\ttotal: 12.1s\tremaining: 28.1s\n",
      "800:\tlearn: 160.6891772\ttest: 172.1207289\tbest: 172.1168102 (794)\ttotal: 15.8s\tremaining: 23.6s\n",
      "1000:\tlearn: 156.5135125\ttest: 171.0537800\tbest: 171.0126132 (991)\ttotal: 19.5s\tremaining: 19.5s\n",
      "1200:\tlearn: 152.1189118\ttest: 169.7351604\tbest: 169.7351604 (1200)\ttotal: 23.2s\tremaining: 15.4s\n",
      "1400:\tlearn: 148.5538465\ttest: 168.8432041\tbest: 168.8384148 (1398)\ttotal: 26.9s\tremaining: 11.5s\n",
      "1600:\tlearn: 145.5709261\ttest: 168.4290782\tbest: 168.4155575 (1541)\ttotal: 30.6s\tremaining: 7.62s\n",
      "1800:\tlearn: 142.8187788\ttest: 167.8993192\tbest: 167.8887511 (1799)\ttotal: 34.2s\tremaining: 3.78s\n",
      "1999:\tlearn: 140.0422829\ttest: 167.2887480\tbest: 167.2887480 (1999)\ttotal: 37.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 167.288748\n",
      "bestIteration = 1999\n",
      "\n",
      "Testing combination: ('is_day:idx',)\n",
      "0:\tlearn: 598.6482984\ttest: 596.8633043\tbest: 596.8633043 (0)\ttotal: 29.2ms\tremaining: 58.3s\n",
      "200:\tlearn: 185.7089972\ttest: 185.8650579\tbest: 185.8650579 (200)\ttotal: 4.02s\tremaining: 36s\n",
      "400:\tlearn: 171.6324440\ttest: 178.1326195\tbest: 178.1159263 (399)\ttotal: 7.96s\tremaining: 31.7s\n",
      "600:\tlearn: 164.1935741\ttest: 175.1937770\tbest: 175.1866431 (598)\ttotal: 11.8s\tremaining: 27.4s\n",
      "800:\tlearn: 158.0888733\ttest: 172.8601240\tbest: 172.8601240 (800)\ttotal: 15.5s\tremaining: 23.3s\n",
      "1000:\tlearn: 153.5048949\ttest: 171.6051875\tbest: 171.5971430 (998)\ttotal: 19.8s\tremaining: 19.8s\n",
      "1200:\tlearn: 149.5972407\ttest: 170.5359351\tbest: 170.5359351 (1200)\ttotal: 23.7s\tremaining: 15.8s\n",
      "1400:\tlearn: 146.8102970\ttest: 169.5944581\tbest: 169.5794026 (1399)\ttotal: 27.4s\tremaining: 11.7s\n",
      "1600:\tlearn: 143.3930871\ttest: 168.6361761\tbest: 168.6361761 (1600)\ttotal: 31.1s\tremaining: 7.76s\n",
      "1800:\tlearn: 141.3828895\ttest: 168.2459046\tbest: 168.2302407 (1796)\ttotal: 34.8s\tremaining: 3.85s\n",
      "1999:\tlearn: 139.4750493\ttest: 167.6117759\tbest: 167.6090663 (1987)\ttotal: 38.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 167.6090663\n",
      "bestIteration = 1987\n",
      "\n",
      "Shrink model to first 1988 iterations.\n",
      "Testing combination: ('is_in_shadow:idx',)\n",
      "0:\tlearn: 598.6482984\ttest: 596.8633043\tbest: 596.8633043 (0)\ttotal: 26.2ms\tremaining: 52.4s\n",
      "200:\tlearn: 184.8815394\ttest: 185.0815308\tbest: 185.0815308 (200)\ttotal: 4.23s\tremaining: 37.8s\n",
      "400:\tlearn: 171.3838783\ttest: 177.0285686\tbest: 176.9948302 (393)\ttotal: 8.2s\tremaining: 32.7s\n",
      "600:\tlearn: 164.9137007\ttest: 174.5115969\tbest: 174.5115965 (599)\ttotal: 12s\tremaining: 28s\n",
      "800:\tlearn: 158.6335176\ttest: 172.5530808\tbest: 172.5530808 (800)\ttotal: 15.8s\tremaining: 23.7s\n",
      "1000:\tlearn: 152.7265064\ttest: 170.7510660\tbest: 170.7500094 (999)\ttotal: 19.6s\tremaining: 19.5s\n",
      "1200:\tlearn: 149.1725373\ttest: 169.7659932\tbest: 169.7659932 (1200)\ttotal: 23.6s\tremaining: 15.7s\n",
      "1400:\tlearn: 145.9198863\ttest: 168.8942900\tbest: 168.8881516 (1392)\ttotal: 27.4s\tremaining: 11.7s\n",
      "1600:\tlearn: 143.0608948\ttest: 168.0985384\tbest: 168.0984549 (1599)\ttotal: 31.1s\tremaining: 7.75s\n",
      "1800:\tlearn: 140.4452119\ttest: 167.4458742\tbest: 167.4431370 (1788)\ttotal: 34.8s\tremaining: 3.84s\n",
      "1999:\tlearn: 138.4357737\ttest: 167.3750741\tbest: 167.3230066 (1967)\ttotal: 38.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 167.3230066\n",
      "bestIteration = 1967\n",
      "\n",
      "Shrink model to first 1968 iterations.\n",
      "Testing combination: ('precip_type_5min:idx',)\n",
      "0:\tlearn: 598.6482984\ttest: 596.8633043\tbest: 596.8633043 (0)\ttotal: 35.5ms\tremaining: 1m 10s\n",
      "200:\tlearn: 185.9736626\ttest: 184.0276574\tbest: 184.0276574 (200)\ttotal: 4.51s\tremaining: 40.3s\n",
      "400:\tlearn: 171.7395105\ttest: 176.0693090\tbest: 176.0690357 (399)\ttotal: 8.49s\tremaining: 33.8s\n",
      "600:\tlearn: 166.4438184\ttest: 174.0689294\tbest: 174.0689223 (598)\ttotal: 12.3s\tremaining: 28.7s\n",
      "800:\tlearn: 160.1202657\ttest: 171.6423581\tbest: 171.6394887 (799)\ttotal: 16.2s\tremaining: 24.2s\n",
      "1000:\tlearn: 155.5664954\ttest: 169.9414546\tbest: 169.9339203 (999)\ttotal: 20s\tremaining: 19.9s\n",
      "1200:\tlearn: 151.4909539\ttest: 169.2105328\tbest: 169.2105328 (1200)\ttotal: 23.7s\tremaining: 15.8s\n",
      "1400:\tlearn: 148.0023817\ttest: 168.3691277\tbest: 168.3691277 (1400)\ttotal: 27.4s\tremaining: 11.7s\n",
      "1600:\tlearn: 144.8459775\ttest: 167.4425092\tbest: 167.4080001 (1582)\ttotal: 31.1s\tremaining: 7.76s\n",
      "1800:\tlearn: 142.0825913\ttest: 166.8269914\tbest: 166.8222186 (1798)\ttotal: 34.8s\tremaining: 3.85s\n",
      "1999:\tlearn: 140.0191797\ttest: 166.3510167\tbest: 166.3351729 (1979)\ttotal: 38.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.3351729\n",
      "bestIteration = 1979\n",
      "\n",
      "Shrink model to first 1980 iterations.\n",
      "Testing combination: ('snow_drift:idx',)\n",
      "0:\tlearn: 592.1234725\ttest: 590.9381626\tbest: 590.9381626 (0)\ttotal: 13.8ms\tremaining: 27.6s\n",
      "200:\tlearn: 185.8712708\ttest: 184.5015438\tbest: 184.5015438 (200)\ttotal: 2.25s\tremaining: 20.1s\n",
      "400:\tlearn: 171.8908953\ttest: 176.1471123\tbest: 176.1471123 (400)\ttotal: 4.47s\tremaining: 17.8s\n",
      "600:\tlearn: 165.2616287\ttest: 172.9541836\tbest: 172.9541836 (600)\ttotal: 6.95s\tremaining: 16.2s\n",
      "800:\tlearn: 159.7478913\ttest: 171.2111182\tbest: 171.2107341 (798)\ttotal: 9.2s\tremaining: 13.8s\n",
      "1000:\tlearn: 154.2284386\ttest: 169.7916863\tbest: 169.7547015 (996)\ttotal: 11.3s\tremaining: 11.3s\n",
      "1200:\tlearn: 150.0669836\ttest: 168.5264435\tbest: 168.5068889 (1196)\ttotal: 13.4s\tremaining: 8.93s\n",
      "1400:\tlearn: 147.2752378\ttest: 168.1190114\tbest: 168.0514109 (1365)\ttotal: 15.6s\tremaining: 6.65s\n",
      "1600:\tlearn: 143.6878288\ttest: 167.2674861\tbest: 167.2671147 (1598)\ttotal: 17.7s\tremaining: 4.4s\n",
      "1800:\tlearn: 141.2373980\ttest: 166.8977237\tbest: 166.8771560 (1799)\ttotal: 20.1s\tremaining: 2.22s\n",
      "1999:\tlearn: 138.8051858\ttest: 166.4118550\tbest: 166.3931637 (1995)\ttotal: 22.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.3931637\n",
      "bestIteration = 1995\n",
      "\n",
      "Shrink model to first 1996 iterations.\n",
      "Testing combination: ('estimated', 'dew_or_rime:idx')\n",
      "0:\tlearn: 597.1378132\ttest: 595.7270253\tbest: 595.7270253 (0)\ttotal: 26.4ms\tremaining: 52.8s\n",
      "200:\tlearn: 187.2562413\ttest: 183.6417580\tbest: 183.6417580 (200)\ttotal: 3.93s\tremaining: 35.2s\n",
      "400:\tlearn: 174.8701422\ttest: 177.2259326\tbest: 177.2089325 (397)\ttotal: 7.95s\tremaining: 31.7s\n",
      "600:\tlearn: 166.8086611\ttest: 174.1786716\tbest: 174.1784667 (598)\ttotal: 11.9s\tremaining: 27.6s\n",
      "800:\tlearn: 160.6891772\ttest: 172.1207289\tbest: 172.1168102 (794)\ttotal: 15.8s\tremaining: 23.6s\n",
      "1000:\tlearn: 156.5135125\ttest: 171.0537800\tbest: 171.0126132 (991)\ttotal: 19.5s\tremaining: 19.5s\n",
      "1200:\tlearn: 152.1189118\ttest: 169.7351604\tbest: 169.7351604 (1200)\ttotal: 23.3s\tremaining: 15.5s\n",
      "1400:\tlearn: 148.5538465\ttest: 168.8432041\tbest: 168.8384148 (1398)\ttotal: 27s\tremaining: 11.5s\n",
      "1600:\tlearn: 145.5709261\ttest: 168.4290782\tbest: 168.4155575 (1541)\ttotal: 30.7s\tremaining: 7.65s\n",
      "1800:\tlearn: 142.8187788\ttest: 167.8993192\tbest: 167.8887511 (1799)\ttotal: 34.5s\tremaining: 3.81s\n",
      "1999:\tlearn: 140.0422829\ttest: 167.2887480\tbest: 167.2887480 (1999)\ttotal: 38.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 167.288748\n",
      "bestIteration = 1999\n",
      "\n",
      "Testing combination: ('estimated', 'is_day:idx')\n",
      "0:\tlearn: 598.6482984\ttest: 596.8633043\tbest: 596.8633043 (0)\ttotal: 27.2ms\tremaining: 54.3s\n",
      "200:\tlearn: 185.7089972\ttest: 185.8650579\tbest: 185.8650579 (200)\ttotal: 4.05s\tremaining: 36.3s\n",
      "400:\tlearn: 171.6324440\ttest: 178.1326195\tbest: 178.1159263 (399)\ttotal: 8.02s\tremaining: 32s\n",
      "600:\tlearn: 164.1935741\ttest: 175.1937770\tbest: 175.1866431 (598)\ttotal: 11.8s\tremaining: 27.6s\n",
      "800:\tlearn: 158.0888733\ttest: 172.8601240\tbest: 172.8601240 (800)\ttotal: 15.6s\tremaining: 23.3s\n",
      "1000:\tlearn: 153.5048949\ttest: 171.6051875\tbest: 171.5971430 (998)\ttotal: 20.8s\tremaining: 20.8s\n",
      "1200:\tlearn: 149.5972407\ttest: 170.5359351\tbest: 170.5359351 (1200)\ttotal: 24.5s\tremaining: 16.3s\n",
      "1400:\tlearn: 146.8102970\ttest: 169.5944581\tbest: 169.5794026 (1399)\ttotal: 28.3s\tremaining: 12.1s\n",
      "1600:\tlearn: 143.3930871\ttest: 168.6361761\tbest: 168.6361761 (1600)\ttotal: 32s\tremaining: 7.97s\n",
      "1800:\tlearn: 141.3828895\ttest: 168.2459046\tbest: 168.2302407 (1796)\ttotal: 35.7s\tremaining: 3.95s\n",
      "1999:\tlearn: 139.4750493\ttest: 167.6117759\tbest: 167.6090663 (1987)\ttotal: 39.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 167.6090663\n",
      "bestIteration = 1987\n",
      "\n",
      "Shrink model to first 1988 iterations.\n",
      "Testing combination: ('estimated', 'is_in_shadow:idx')\n",
      "0:\tlearn: 598.6482984\ttest: 596.8633043\tbest: 596.8633043 (0)\ttotal: 26.4ms\tremaining: 52.7s\n",
      "200:\tlearn: 184.8815394\ttest: 185.0815308\tbest: 185.0815308 (200)\ttotal: 4.26s\tremaining: 38.1s\n",
      "400:\tlearn: 171.3838783\ttest: 177.0285686\tbest: 176.9948302 (393)\ttotal: 8.28s\tremaining: 33s\n",
      "600:\tlearn: 164.9137007\ttest: 174.5115969\tbest: 174.5115965 (599)\ttotal: 12.1s\tremaining: 28.1s\n",
      "800:\tlearn: 158.6335176\ttest: 172.5530808\tbest: 172.5530808 (800)\ttotal: 15.8s\tremaining: 23.6s\n",
      "1000:\tlearn: 152.7265064\ttest: 170.7510660\tbest: 170.7500094 (999)\ttotal: 19.6s\tremaining: 19.5s\n",
      "1200:\tlearn: 149.1725373\ttest: 169.7659932\tbest: 169.7659932 (1200)\ttotal: 23.4s\tremaining: 15.6s\n",
      "1400:\tlearn: 145.9198863\ttest: 168.8942900\tbest: 168.8881516 (1392)\ttotal: 27.1s\tremaining: 11.6s\n",
      "1600:\tlearn: 143.0608948\ttest: 168.0985384\tbest: 168.0984549 (1599)\ttotal: 30.8s\tremaining: 7.69s\n",
      "1800:\tlearn: 140.4452119\ttest: 167.4458742\tbest: 167.4431370 (1788)\ttotal: 34.5s\tremaining: 3.82s\n",
      "1999:\tlearn: 138.4357737\ttest: 167.3750741\tbest: 167.3230066 (1967)\ttotal: 38.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 167.3230066\n",
      "bestIteration = 1967\n",
      "\n",
      "Shrink model to first 1968 iterations.\n",
      "Testing combination: ('estimated', 'precip_type_5min:idx')\n",
      "0:\tlearn: 598.6482984\ttest: 596.8633043\tbest: 596.8633043 (0)\ttotal: 33.1ms\tremaining: 1m 6s\n",
      "200:\tlearn: 185.9736626\ttest: 184.0276574\tbest: 184.0276574 (200)\ttotal: 4.64s\tremaining: 41.5s\n",
      "400:\tlearn: 171.7395105\ttest: 176.0693090\tbest: 176.0690357 (399)\ttotal: 8.67s\tremaining: 34.6s\n",
      "600:\tlearn: 166.4438184\ttest: 174.0689294\tbest: 174.0689223 (598)\ttotal: 12.6s\tremaining: 29.3s\n",
      "800:\tlearn: 160.1202657\ttest: 171.6423581\tbest: 171.6394887 (799)\ttotal: 16.4s\tremaining: 24.6s\n",
      "1000:\tlearn: 155.5664954\ttest: 169.9414546\tbest: 169.9339203 (999)\ttotal: 20.3s\tremaining: 20.2s\n",
      "1200:\tlearn: 151.4909539\ttest: 169.2105328\tbest: 169.2105328 (1200)\ttotal: 24.1s\tremaining: 16s\n",
      "1400:\tlearn: 148.0023817\ttest: 168.3691277\tbest: 168.3691277 (1400)\ttotal: 27.9s\tremaining: 11.9s\n",
      "1600:\tlearn: 144.8459775\ttest: 167.4425092\tbest: 167.4080001 (1582)\ttotal: 31.7s\tremaining: 7.89s\n",
      "1800:\tlearn: 142.0825913\ttest: 166.8269914\tbest: 166.8222186 (1798)\ttotal: 35.4s\tremaining: 3.91s\n",
      "1999:\tlearn: 140.0191797\ttest: 166.3510167\tbest: 166.3351729 (1979)\ttotal: 39.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.3351729\n",
      "bestIteration = 1979\n",
      "\n",
      "Shrink model to first 1980 iterations.\n",
      "Testing combination: ('estimated', 'snow_drift:idx')\n",
      "0:\tlearn: 592.1234725\ttest: 590.9381626\tbest: 590.9381626 (0)\ttotal: 13.8ms\tremaining: 27.6s\n",
      "200:\tlearn: 185.8712708\ttest: 184.5015438\tbest: 184.5015438 (200)\ttotal: 2.26s\tremaining: 20.2s\n",
      "400:\tlearn: 171.8908953\ttest: 176.1471123\tbest: 176.1471123 (400)\ttotal: 4.49s\tremaining: 17.9s\n",
      "600:\tlearn: 165.2616287\ttest: 172.9541836\tbest: 172.9541836 (600)\ttotal: 6.7s\tremaining: 15.6s\n",
      "800:\tlearn: 159.7478913\ttest: 171.2111182\tbest: 171.2107341 (798)\ttotal: 8.84s\tremaining: 13.2s\n",
      "1000:\tlearn: 154.2284386\ttest: 169.7916863\tbest: 169.7547015 (996)\ttotal: 10.9s\tremaining: 10.9s\n",
      "1200:\tlearn: 150.0669836\ttest: 168.5264435\tbest: 168.5068889 (1196)\ttotal: 13.1s\tremaining: 8.69s\n",
      "1400:\tlearn: 147.2752378\ttest: 168.1190114\tbest: 168.0514109 (1365)\ttotal: 15.2s\tremaining: 6.49s\n",
      "1600:\tlearn: 143.6878288\ttest: 167.2674861\tbest: 167.2671147 (1598)\ttotal: 17.4s\tremaining: 4.33s\n",
      "1800:\tlearn: 141.2373980\ttest: 166.8977237\tbest: 166.8771560 (1799)\ttotal: 19.9s\tremaining: 2.2s\n",
      "1999:\tlearn: 138.8051858\ttest: 166.4118550\tbest: 166.3931637 (1995)\ttotal: 22.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.3931637\n",
      "bestIteration = 1995\n",
      "\n",
      "Shrink model to first 1996 iterations.\n",
      "Testing combination: ('dew_or_rime:idx', 'is_day:idx')\n",
      "0:\tlearn: 581.8139785\ttest: 579.8508869\tbest: 579.8508869 (0)\ttotal: 27.4ms\tremaining: 54.8s\n",
      "200:\tlearn: 184.3657162\ttest: 182.6396379\tbest: 182.6396379 (200)\ttotal: 4.48s\tremaining: 40.1s\n",
      "400:\tlearn: 173.3691606\ttest: 176.9789106\tbest: 176.9789106 (400)\ttotal: 8.81s\tremaining: 35.1s\n",
      "600:\tlearn: 165.8778501\ttest: 174.1805396\tbest: 174.1805396 (600)\ttotal: 13.1s\tremaining: 30.4s\n",
      "800:\tlearn: 159.1542602\ttest: 171.7095055\tbest: 171.7083099 (799)\ttotal: 17.8s\tremaining: 26.6s\n",
      "1000:\tlearn: 154.3560790\ttest: 170.5436120\tbest: 170.5424708 (999)\ttotal: 21.9s\tremaining: 21.9s\n",
      "1200:\tlearn: 150.9536994\ttest: 169.5902048\tbest: 169.5767584 (1194)\ttotal: 26.2s\tremaining: 17.4s\n",
      "1400:\tlearn: 148.1255456\ttest: 168.8330470\tbest: 168.8327378 (1399)\ttotal: 30.3s\tremaining: 13s\n",
      "1600:\tlearn: 144.2644239\ttest: 167.9677788\tbest: 167.9235839 (1575)\ttotal: 34.5s\tremaining: 8.6s\n",
      "1800:\tlearn: 141.7607117\ttest: 167.4036144\tbest: 167.4036144 (1800)\ttotal: 38.7s\tremaining: 4.28s\n",
      "1999:\tlearn: 139.6257009\ttest: 166.7871412\tbest: 166.7860673 (1997)\ttotal: 42.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.7860673\n",
      "bestIteration = 1997\n",
      "\n",
      "Shrink model to first 1998 iterations.\n",
      "Testing combination: ('dew_or_rime:idx', 'is_in_shadow:idx')\n",
      "0:\tlearn: 581.9558689\ttest: 580.0398210\tbest: 580.0398210 (0)\ttotal: 29.3ms\tremaining: 58.5s\n",
      "200:\tlearn: 185.6246882\ttest: 183.9207629\tbest: 183.9207629 (200)\ttotal: 4.56s\tremaining: 40.8s\n",
      "400:\tlearn: 171.7264116\ttest: 176.6728913\tbest: 176.6728636 (399)\ttotal: 8.94s\tremaining: 35.7s\n",
      "600:\tlearn: 164.4856015\ttest: 173.4983146\tbest: 173.4983146 (600)\ttotal: 13.8s\tremaining: 32.1s\n",
      "800:\tlearn: 158.9981527\ttest: 172.1388920\tbest: 172.1339044 (792)\ttotal: 18.2s\tremaining: 27.3s\n",
      "1000:\tlearn: 154.9581960\ttest: 171.0784608\tbest: 171.0289599 (995)\ttotal: 22.5s\tremaining: 22.4s\n",
      "1200:\tlearn: 151.1228025\ttest: 170.0193422\tbest: 170.0193422 (1200)\ttotal: 26.7s\tremaining: 17.7s\n",
      "1400:\tlearn: 147.4479877\ttest: 169.0757510\tbest: 169.0455300 (1395)\ttotal: 30.8s\tremaining: 13.2s\n",
      "1600:\tlearn: 144.6269090\ttest: 168.2115933\tbest: 168.2115933 (1600)\ttotal: 34.9s\tremaining: 8.7s\n",
      "1800:\tlearn: 141.4040947\ttest: 167.5767330\tbest: 167.5767330 (1800)\ttotal: 39s\tremaining: 4.31s\n",
      "1999:\tlearn: 138.8496742\ttest: 167.1509605\tbest: 167.1509490 (1998)\ttotal: 43.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 167.150949\n",
      "bestIteration = 1998\n",
      "\n",
      "Shrink model to first 1999 iterations.\n",
      "Testing combination: ('dew_or_rime:idx', 'precip_type_5min:idx')\n",
      "0:\tlearn: 600.9819669\ttest: 599.2473611\tbest: 599.2473611 (0)\ttotal: 29.3ms\tremaining: 58.6s\n",
      "200:\tlearn: 190.8504138\ttest: 187.1845259\tbest: 187.1845259 (200)\ttotal: 4.84s\tremaining: 43.4s\n",
      "400:\tlearn: 176.2999684\ttest: 178.1073750\tbest: 178.1036664 (399)\ttotal: 9.13s\tremaining: 36.4s\n",
      "600:\tlearn: 168.3009808\ttest: 174.5733295\tbest: 174.5733124 (598)\ttotal: 13.8s\tremaining: 32.1s\n",
      "800:\tlearn: 161.8295709\ttest: 172.1354665\tbest: 172.1354665 (800)\ttotal: 18s\tremaining: 27s\n",
      "1000:\tlearn: 156.0035748\ttest: 170.9914894\tbest: 170.9280407 (986)\ttotal: 22.2s\tremaining: 22.2s\n",
      "1200:\tlearn: 151.8004590\ttest: 169.3990507\tbest: 169.3959393 (1199)\ttotal: 26.4s\tremaining: 17.6s\n",
      "1400:\tlearn: 148.3252414\ttest: 168.5018285\tbest: 168.4595511 (1388)\ttotal: 31.4s\tremaining: 13.4s\n",
      "1600:\tlearn: 144.6202203\ttest: 167.4889501\tbest: 167.4502331 (1579)\ttotal: 35.5s\tremaining: 8.85s\n",
      "1800:\tlearn: 141.8783375\ttest: 166.7532232\tbest: 166.7251427 (1782)\ttotal: 39.6s\tremaining: 4.38s\n",
      "1999:\tlearn: 139.0410980\ttest: 166.1902266\tbest: 166.1902266 (1999)\ttotal: 43.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.1902266\n",
      "bestIteration = 1999\n",
      "\n",
      "Testing combination: ('dew_or_rime:idx', 'snow_drift:idx')\n",
      "0:\tlearn: 595.7832554\ttest: 594.7568359\tbest: 594.7568359 (0)\ttotal: 31.4ms\tremaining: 1m 2s\n",
      "200:\tlearn: 186.7481172\ttest: 184.6158570\tbest: 184.6158570 (200)\ttotal: 4s\tremaining: 35.8s\n",
      "400:\tlearn: 175.1736324\ttest: 177.9954338\tbest: 177.9954338 (400)\ttotal: 7.94s\tremaining: 31.7s\n",
      "600:\tlearn: 167.9091611\ttest: 175.2246251\tbest: 175.2242313 (598)\ttotal: 11.8s\tremaining: 27.4s\n",
      "800:\tlearn: 162.1898253\ttest: 173.5093897\tbest: 173.4954681 (799)\ttotal: 15.6s\tremaining: 23.3s\n",
      "1000:\tlearn: 157.3305295\ttest: 172.0555775\tbest: 172.0555775 (1000)\ttotal: 19.3s\tremaining: 19.3s\n",
      "1200:\tlearn: 152.6573533\ttest: 170.8950426\tbest: 170.8658276 (1195)\ttotal: 23.1s\tremaining: 15.3s\n",
      "1400:\tlearn: 148.6636781\ttest: 170.0320016\tbest: 170.0320016 (1400)\ttotal: 26.8s\tremaining: 11.5s\n",
      "1600:\tlearn: 145.2398921\ttest: 169.2579090\tbest: 169.2579090 (1600)\ttotal: 30.6s\tremaining: 7.61s\n",
      "1800:\tlearn: 141.5794937\ttest: 168.7706473\tbest: 168.7466423 (1786)\ttotal: 34.5s\tremaining: 3.81s\n",
      "1999:\tlearn: 138.9792671\ttest: 168.3681092\tbest: 168.3397659 (1987)\ttotal: 38.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 168.3397659\n",
      "bestIteration = 1987\n",
      "\n",
      "Shrink model to first 1988 iterations.\n",
      "Testing combination: ('is_day:idx', 'is_in_shadow:idx')\n",
      "0:\tlearn: 585.6455808\ttest: 583.9699074\tbest: 583.9699074 (0)\ttotal: 29.6ms\tremaining: 59.1s\n",
      "200:\tlearn: 186.1286241\ttest: 183.1564701\tbest: 183.1452551 (199)\ttotal: 5.23s\tremaining: 46.8s\n",
      "400:\tlearn: 171.0434309\ttest: 174.6332675\tbest: 174.6332675 (400)\ttotal: 9.97s\tremaining: 39.7s\n",
      "600:\tlearn: 165.2438587\ttest: 171.9223700\tbest: 171.9223700 (600)\ttotal: 14.3s\tremaining: 33.2s\n",
      "800:\tlearn: 159.2772719\ttest: 169.9741590\tbest: 169.9741590 (800)\ttotal: 18.4s\tremaining: 27.6s\n",
      "1000:\tlearn: 154.3018308\ttest: 168.3280016\tbest: 168.3280016 (1000)\ttotal: 22.6s\tremaining: 22.5s\n",
      "1200:\tlearn: 150.2385369\ttest: 167.6830793\tbest: 167.6815353 (1182)\ttotal: 26.7s\tremaining: 17.8s\n",
      "1400:\tlearn: 146.9071361\ttest: 166.7957573\tbest: 166.7762303 (1360)\ttotal: 30.8s\tremaining: 13.2s\n",
      "1600:\tlearn: 143.8391053\ttest: 166.5344370\tbest: 166.5336095 (1558)\ttotal: 35s\tremaining: 8.72s\n",
      "1800:\tlearn: 141.1148169\ttest: 166.0632835\tbest: 166.0632835 (1800)\ttotal: 39.1s\tremaining: 4.32s\n",
      "1999:\tlearn: 138.5696124\ttest: 165.3730335\tbest: 165.3620520 (1991)\ttotal: 43.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 165.362052\n",
      "bestIteration = 1991\n",
      "\n",
      "Shrink model to first 1992 iterations.\n",
      "Testing combination: ('is_day:idx', 'precip_type_5min:idx')\n",
      "0:\tlearn: 585.6455808\ttest: 583.9699074\tbest: 583.9699074 (0)\ttotal: 30.4ms\tremaining: 1m\n",
      "200:\tlearn: 187.6847196\ttest: 184.8240582\tbest: 184.8240582 (200)\ttotal: 4.56s\tremaining: 40.8s\n",
      "400:\tlearn: 173.8698131\ttest: 176.4302656\tbest: 176.4302656 (400)\ttotal: 8.92s\tremaining: 35.6s\n",
      "600:\tlearn: 166.5526078\ttest: 173.4530236\tbest: 173.4519344 (599)\ttotal: 13.2s\tremaining: 30.8s\n",
      "800:\tlearn: 158.4516645\ttest: 170.6275061\tbest: 170.6156249 (799)\ttotal: 17.5s\tremaining: 26.2s\n",
      "1000:\tlearn: 153.0367769\ttest: 169.1687947\tbest: 169.1687918 (999)\ttotal: 23s\tremaining: 23s\n",
      "1200:\tlearn: 148.8410375\ttest: 168.4516077\tbest: 168.4516077 (1200)\ttotal: 27.3s\tremaining: 18.1s\n",
      "1400:\tlearn: 145.3514515\ttest: 168.0696926\tbest: 168.0496514 (1385)\ttotal: 31.5s\tremaining: 13.5s\n",
      "1600:\tlearn: 142.1586565\ttest: 167.4197196\tbest: 167.4194770 (1599)\ttotal: 35.6s\tremaining: 8.87s\n",
      "1800:\tlearn: 139.2835249\ttest: 166.7462715\tbest: 166.6968242 (1776)\ttotal: 39.7s\tremaining: 4.39s\n",
      "1999:\tlearn: 137.1803004\ttest: 166.2480025\tbest: 166.2456973 (1996)\ttotal: 44s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.2456973\n",
      "bestIteration = 1996\n",
      "\n",
      "Shrink model to first 1997 iterations.\n",
      "Testing combination: ('is_day:idx', 'snow_drift:idx')\n",
      "0:\tlearn: 596.3276092\ttest: 595.5729938\tbest: 595.5729938 (0)\ttotal: 27.1ms\tremaining: 54.1s\n",
      "200:\tlearn: 188.2199261\ttest: 186.9013215\tbest: 186.9013215 (200)\ttotal: 4.01s\tremaining: 35.9s\n",
      "400:\tlearn: 173.6095715\ttest: 177.6579956\tbest: 177.6579956 (400)\ttotal: 8.02s\tremaining: 32s\n",
      "600:\tlearn: 166.1610643\ttest: 174.4407529\tbest: 174.4407529 (600)\ttotal: 11.8s\tremaining: 27.5s\n",
      "800:\tlearn: 159.9342711\ttest: 172.3192129\tbest: 172.3192129 (800)\ttotal: 15.6s\tremaining: 23.4s\n",
      "1000:\tlearn: 154.9778764\ttest: 170.6482493\tbest: 170.6150998 (996)\ttotal: 19.4s\tremaining: 19.4s\n",
      "1200:\tlearn: 150.0996766\ttest: 169.6100149\tbest: 169.6100149 (1200)\ttotal: 23.1s\tremaining: 15.4s\n",
      "1400:\tlearn: 146.5823923\ttest: 168.7635483\tbest: 168.7635483 (1400)\ttotal: 26.9s\tremaining: 11.5s\n",
      "1600:\tlearn: 143.7514310\ttest: 167.7059855\tbest: 167.6843732 (1596)\ttotal: 30.6s\tremaining: 7.64s\n",
      "1800:\tlearn: 141.3642210\ttest: 167.1686364\tbest: 167.1686364 (1800)\ttotal: 34.3s\tremaining: 3.79s\n",
      "1999:\tlearn: 138.0925517\ttest: 166.0502675\tbest: 166.0450477 (1998)\ttotal: 38.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.0450477\n",
      "bestIteration = 1998\n",
      "\n",
      "Shrink model to first 1999 iterations.\n",
      "Testing combination: ('is_in_shadow:idx', 'precip_type_5min:idx')\n",
      "0:\tlearn: 585.6455808\ttest: 583.9699074\tbest: 583.9699074 (0)\ttotal: 36.5ms\tremaining: 1m 12s\n",
      "200:\tlearn: 184.9544526\ttest: 182.6777923\tbest: 182.6777923 (200)\ttotal: 4.77s\tremaining: 42.7s\n",
      "400:\tlearn: 172.4675983\ttest: 175.1065025\tbest: 175.1059880 (398)\ttotal: 9.15s\tremaining: 36.5s\n",
      "600:\tlearn: 165.0824563\ttest: 171.4468821\tbest: 171.4401382 (597)\ttotal: 13.4s\tremaining: 31.2s\n",
      "800:\tlearn: 158.7483451\ttest: 169.3310387\tbest: 169.3187520 (797)\ttotal: 17.6s\tremaining: 26.3s\n",
      "1000:\tlearn: 154.1650753\ttest: 167.7444854\tbest: 167.7174472 (997)\ttotal: 21.8s\tremaining: 21.7s\n",
      "1200:\tlearn: 149.7089613\ttest: 166.6976617\tbest: 166.6976617 (1200)\ttotal: 26s\tremaining: 17.3s\n",
      "1400:\tlearn: 146.4174247\ttest: 166.1037088\tbest: 166.0927824 (1395)\ttotal: 30.1s\tremaining: 12.9s\n",
      "1600:\tlearn: 143.7291530\ttest: 165.4682460\tbest: 165.3716485 (1596)\ttotal: 34.2s\tremaining: 8.53s\n"
     ]
    }
   ],
   "source": [
    "model_a, best_combination, best_mae = find_best_categorical_combination(merged_a,cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a775a1b-ddaf-4ed2-988e-53856f4c9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_data, val_size=0.1, val = False, estimated_column = 'estimated'):\n",
    "    if val: \n",
    "        estimated_one = train_data[train_data[estimated_column] == 1]\n",
    "\n",
    "        #Split the filtered dataset into two\n",
    "        half_index = len(estimated_one) // 2\n",
    "        validation_set = estimated_one[half_index:]\n",
    "\n",
    "        # Combine the first half of observed_zero with the rest of the data where observed != 0\n",
    "        training_set = pd.concat([train_data[train_data[estimated_column] == 0], estimated_one[:half_index]])\n",
    "    else:\n",
    "        split_index = int(train_data.shape[0] * (1 - val_size))\n",
    "        training_set = train_data.iloc[:split_index]\n",
    "        validation_set = train_data.iloc[split_index:]\n",
    "    return training_set, validation_set\n",
    "\n",
    "def build_catboost(merged_df, val_size=0.1, randomized=False):\n",
    "    merged_df = merged_df.drop(columns=['date_forecast','time'])\n",
    "    if randomized:\n",
    "        X = merged_df.drop(columns=['pv_measurement'])\n",
    "        y = merged_df['pv_measurement']\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "    else:\n",
    "        training_set, validation_set = split_dataset(merged_df, val_size, True)\n",
    "        X_train = training_set.drop(columns=['pv_measurement'])\n",
    "        y_train = training_set['pv_measurement']\n",
    "        X_validation = validation_set.drop(columns=['pv_measurement'])\n",
    "        y_validation = validation_set['pv_measurement']\n",
    "    \n",
    "    catboost_model = CatBoostRegressor(\n",
    "        cat_features=['estimated'],\n",
    "        iterations=2000,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        loss_function='MAE',\n",
    "        eval_metric='MAE',\n",
    "        random_seed=42,\n",
    "        verbose=200\n",
    "    )\n",
    "    \n",
    "    catboost_model.fit(X_train, y_train, eval_set=(X_validation, y_validation), use_best_model=True, early_stopping_rounds=200)\n",
    "    return catboost_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e4e08-c99a-4c1b-8e7f-aaf9deeece46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = build_catboost(merged_a_cat,0.2, True)\n",
    "model_b = build_catboost(merged_b_cat,0.2, True)\n",
    "model_c = build_catboost(merged_c_cat,0.125, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8599a46-e0fd-44c5-80b7-269315fa8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = build_catboost(merged_a_avg,0.2, True)\n",
    "model_b = build_catboost(merged_b_avg,0.2, True)\n",
    "model_c = build_catboost(merged_c_avg,0.125, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318564e-878f-41b2-93a1-1c14ca270856",
   "metadata": {},
   "outputs": [],
   "source": [
    "laged_model_a = build_catboost(laged_a,0.2, True)\n",
    "laged_model_b = build_catboost(laged_b,0.2, True)\n",
    "laged_model_c = build_catboost(laged_c,0.125, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9609ca-e2a7-45c8-b3d5-8818baed82b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Predict Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415dee63-822a-42ff-b91c-acce4ef6fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict_with_lag(model, test_data, initial_lag_value, lag_hours=1, column_name='pv_measurement'):\n",
    "    \"\"\"\n",
    "    Predict using a model that requires a lag feature, updating the test set iteratively.\n",
    "\n",
    "    Parameters:\n",
    "    model (model object): The trained model used for prediction.\n",
    "    test_data (pd.DataFrame): The test dataset without the target column.\n",
    "    initial_lag_value (float): The last known value of the target variable from the training set.\n",
    "    lag_hours (int): The number of hours to lag.\n",
    "    column_name (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series of predictions for the test dataset.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    lag_feature_name = f\"{column_name}_lag_{lag_hours}h\"\n",
    "    current_lag_value = initial_lag_value\n",
    "    \n",
    "    for index, row in test_data.iterrows():\n",
    "        # Set the current lag value\n",
    "        row[lag_feature_name] = current_lag_value\n",
    "        \n",
    "        # Make a prediction\n",
    "        prediction = model.predict(row.to_frame().transpose())[0]\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # Update the lag value with the current prediction\n",
    "        current_lag_value = prediction\n",
    "    \n",
    "    return pd.Series(predictions, index=test_data.index)\n",
    "\n",
    "initial_lag_val_a = merged_a.tail(24).iloc[0,52]\n",
    "initial_lag_val_b = merged_b.tail(24).iloc[0,52]\n",
    "initial_lag_val_c = merged_c.tail(24).iloc[0,52]\n",
    "\n",
    "# Then, use the function to make predictions:\n",
    "laged_pred_a = np.array(predict_with_lag(model=laged_model_a, test_data=x_test_a_laged, \n",
    "                               initial_lag_value=initial_lag_val_a, lag_hours=24))\n",
    "laged_pred_b = np.array(predict_with_lag(model=laged_model_b, test_data=x_test_b_laged, \n",
    "                               initial_lag_value=initial_lag_val_a, lag_hours=24))\n",
    "laged_pred_c = np.array(predict_with_lag(model=laged_model_c, test_data=x_test_c_laged, \n",
    "                               initial_lag_value=initial_lag_val_a, lag_hours=24))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67684c52-a72c-492b-9428-ac0a64049be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predict and Submit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b63a33-669f-4e43-beb5-ee8a5e5df1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_a = model_a.predict(x_test_a_avg)\n",
    "pred_b = model_b.predict(x_test_b_avg)\n",
    "pred_c = model_c.predict(x_test_c_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9604ef-d4e2-4b91-8159-be5b62cd37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_a = model_a.predict(x_test_a_cat)\n",
    "pred_b = model_b.predict(x_test_b_cat)\n",
    "pred_c = model_c.predict(x_test_c_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98989635-e755-4cb3-808e-fcaffbce7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub(pred_a,pred_b,pred_c):\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    submission['prediction'] = np.concatenate([pred_a,pred_b,pred_c])\n",
    "    submission.loc[submission['prediction'] < 0, 'prediction'] = 0\n",
    "    return submission\n",
    "\n",
    "sub = create_sub(pred_a,pred_b,pred_c)\n",
    "#sub = create_sub(laged_pred_a,laged_pred_b,laged_pred_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456bf31-9668-4eb2-98a9-7097c3679b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f'Submissions/catgoricalVar.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24076d9-b911-498d-87ea-23c55b6691e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,model_name,location):\n",
    "    save_directory = 'Saved_models/'+ location.upper()\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    # Define the path to save the model\n",
    "    model_file_path = os.path.join(save_directory, f'{model_name}.cbm')\n",
    "\n",
    "    # Save the model\n",
    "    model.save_model(model_file_path)\n",
    "\n",
    "    print(f\"Model successfully saved at {model_file_path}\")\n",
    "    \n",
    "save_model(model_a,'base_catBoost','A')\n",
    "save_model(model_b,'base_catBoost','B')\n",
    "save_model(model_c,'base_catBoost','C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754cbdf-96c1-464c-8234-6b2e4ff37ab0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea45b7-a8fc-4c20-b887-b3ad124e0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_importance(model):\n",
    "    feats = {'feature':merged_a.drop(columns =['date_forecast','time','pv_measurement']).columns,\n",
    "         'importance':model.get_feature_importance()}\n",
    "    df = pd.DataFrame(feats).sort_values('importance',ascending = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231c4d3-d6ce-4ad3-8b7c-a7b1985c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feat_importance(model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf40fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_preds(pred1,pred2):\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Scatter plot\n",
    "    plt.scatter(pred1['prediction'], pred2['prediction'], alpha=0.5)\n",
    "\n",
    "    # Line of equality (for reference)\n",
    "    plt.plot([pred1['prediction'].min(), pred1['prediction'].max()],\n",
    "             [pred2['prediction'].min(), pred2['prediction'].max()],\n",
    "             color='red', linestyle='--')\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Predictions from First Model')\n",
    "    plt.ylabel('Predictions from New model')\n",
    "    plt.title('Comparison of Predictions from Two Models')\n",
    "\n",
    "    # Show plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471709c6-c455-48b0-b3b9-ff1d0eba5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_two_preds(sub,sub_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(preds):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    predictions= preds['predict'].as_data_frame()\n",
    "    predictions['time'] = test['time'].unique()\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Prediction', color='tab:blue')\n",
    "    ax1.plot(predictions['time'], predictions['predict'], color='tab:blue', label='Solar Power Production')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'Time Series Plot of prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8937d-fd7d-478c-9dae-77c249bf96d6",
   "metadata": {},
   "source": [
    "### Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1282dc2-ab41-4e86-a742-869ce7a9d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_average2.csv')\n",
    "df.loc[df['prediction'] < 8, 'prediction'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eba965-56c9-46bd-8310-64a3c19d8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'Submissions/merged_models3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34416f8d-98d7-475e-b7f7-4d9b27b49dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "maks = max([train_a['pv_measurement'].max(),train_b['pv_measurement'].max(),train_c['pv_measurement'].max()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd01df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"\"\"# Plot the distribution of \"direct_rad:W\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['direct_rad:W'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"direct_rad:W\"')\n",
    "    plt.xlabel('Direct Radiation (W)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['clear_sky_rad:W'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"clear_sky_rad:W\"')\n",
    "    plt.xlabel('Direct Radiation (W)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['direct_rad_1h:J'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"direct_rad_1h:J\"')\n",
    "    plt.xlabel('Radiation 1h(J)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['clear_sky_energy_1h:J'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"clear_sky_energy_1h:J\"')\n",
    "    plt.xlabel('Radiation 1h(J)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3b9cf-df7d-46de-a185-2a062e092aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
