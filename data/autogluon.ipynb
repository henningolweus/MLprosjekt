{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a = pd.read_csv('cleaned_data/A/x_train_a.csv')\n",
    "y_train_a = pd.read_csv('cleaned_data/A/train_a.csv')\n",
    "x_test_a = pd.read_csv('cleaned_data/A/x_test_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_year_sin</th>\n",
       "      <th>day_of_year_cos</th>\n",
       "      <th>direct_rad_3h_roll_avg</th>\n",
       "      <th>diffuse_rad_3h_roll_avg</th>\n",
       "      <th>direct_rad_6h_roll_avg</th>\n",
       "      <th>diffuse_rad_6h_roll_avg</th>\n",
       "      <th>direct_rad_x_sun_elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>5.525</td>\n",
       "      <td>1.23975</td>\n",
       "      <td>1200.6750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1200.6750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>5.425</td>\n",
       "      <td>1.23975</td>\n",
       "      <td>1131.4249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1131.4249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.825</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>5.400</td>\n",
       "      <td>1.23850</td>\n",
       "      <td>1061.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1061.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>5.350</td>\n",
       "      <td>1.23975</td>\n",
       "      <td>1021.1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1021.1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.675</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>5.675</td>\n",
       "      <td>1.23750</td>\n",
       "      <td>1033.7000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1033.7000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26956</th>\n",
       "      <td>2023-04-30 19:00:00</td>\n",
       "      <td>4.550</td>\n",
       "      <td>1.27650</td>\n",
       "      <td>1677.9500</td>\n",
       "      <td>337850.1</td>\n",
       "      <td>4.225</td>\n",
       "      <td>542.8500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.425</td>\n",
       "      <td>2.825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.882679</td>\n",
       "      <td>-0.469977</td>\n",
       "      <td>20.058333</td>\n",
       "      <td>35.033333</td>\n",
       "      <td>83.608334</td>\n",
       "      <td>94.829166</td>\n",
       "      <td>-0.01805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26957</th>\n",
       "      <td>2023-04-30 20:00:00</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.27875</td>\n",
       "      <td>1766.5000</td>\n",
       "      <td>9083.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>546.3500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.882679</td>\n",
       "      <td>-0.469977</td>\n",
       "      <td>2.458333</td>\n",
       "      <td>10.458333</td>\n",
       "      <td>52.808334</td>\n",
       "      <td>63.945835</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26958</th>\n",
       "      <td>2023-04-30 21:00:00</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.27900</td>\n",
       "      <td>1698.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>548.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.882679</td>\n",
       "      <td>-0.469977</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>26.433334</td>\n",
       "      <td>37.866667</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26959</th>\n",
       "      <td>2023-04-30 22:00:00</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.27975</td>\n",
       "      <td>1354.8250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>527.6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.882679</td>\n",
       "      <td>-0.469977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.029167</td>\n",
       "      <td>17.516666</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26960</th>\n",
       "      <td>2023-04-30 23:00:00</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.28025</td>\n",
       "      <td>1627.9751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>526.2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.882679</td>\n",
       "      <td>-0.469977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.229167</td>\n",
       "      <td>5.229167</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26961 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "0      2019-01-01 00:00:00                     5.525              1.23975   \n",
       "1      2019-01-01 01:00:00                     5.425              1.23975   \n",
       "2      2019-01-01 02:00:00                     5.400              1.23850   \n",
       "3      2019-01-01 03:00:00                     5.350              1.23975   \n",
       "4      2019-01-01 04:00:00                     5.675              1.23750   \n",
       "...                    ...                       ...                  ...   \n",
       "26956  2023-04-30 19:00:00                     4.550              1.27650   \n",
       "26957  2023-04-30 20:00:00                     4.500              1.27875   \n",
       "26958  2023-04-30 21:00:00                     4.500              1.27900   \n",
       "26959  2023-04-30 22:00:00                     4.500              1.27975   \n",
       "26960  2023-04-30 23:00:00                     4.500              1.28025   \n",
       "\n",
       "       ceiling_height_agl:m  clear_sky_energy_1h:J  clear_sky_rad:W  \\\n",
       "0                 1200.6750                    0.0            0.000   \n",
       "1                 1131.4249                    0.0            0.000   \n",
       "2                 1061.0000                    0.0            0.000   \n",
       "3                 1021.1500                    0.0            0.000   \n",
       "4                 1033.7000                    0.0            0.000   \n",
       "...                     ...                    ...              ...   \n",
       "26956             1677.9500               337850.1            4.225   \n",
       "26957             1766.5000                 9083.1            0.000   \n",
       "26958             1698.9250                    0.0            0.000   \n",
       "26959             1354.8250                    0.0            0.000   \n",
       "26960             1627.9751                    0.0            0.000   \n",
       "\n",
       "       cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  ...  \\\n",
       "0             1200.6750              0.0         275.150          0.000  ...   \n",
       "1             1131.4249              0.0         274.825          0.000  ...   \n",
       "2             1061.0000              0.0         274.800          0.000  ...   \n",
       "3             1021.1500              0.0         274.675          0.000  ...   \n",
       "4             1033.7000              0.0         275.500          0.000  ...   \n",
       "...                 ...              ...             ...            ...  ...   \n",
       "26956          542.8500              0.0         272.425          2.825  ...   \n",
       "26957          546.3500              0.0         272.300          0.000  ...   \n",
       "26958          548.0500              0.0         272.300          0.000  ...   \n",
       "26959          527.6000              0.0         272.275          0.000  ...   \n",
       "26960          526.2000              0.0         272.250          0.000  ...   \n",
       "\n",
       "       month_sin  month_cos  day_of_year  day_of_year_sin  day_of_year_cos  \\\n",
       "0       0.500000   0.866025            1         0.017166         0.999853   \n",
       "1       0.500000   0.866025            1         0.017166         0.999853   \n",
       "2       0.500000   0.866025            1         0.017166         0.999853   \n",
       "3       0.500000   0.866025            1         0.017166         0.999853   \n",
       "4       0.500000   0.866025            1         0.017166         0.999853   \n",
       "...          ...        ...          ...              ...              ...   \n",
       "26956   0.866025  -0.500000          120         0.882679        -0.469977   \n",
       "26957   0.866025  -0.500000          120         0.882679        -0.469977   \n",
       "26958   0.866025  -0.500000          120         0.882679        -0.469977   \n",
       "26959   0.866025  -0.500000          120         0.882679        -0.469977   \n",
       "26960   0.866025  -0.500000          120         0.882679        -0.469977   \n",
       "\n",
       "       direct_rad_3h_roll_avg  diffuse_rad_3h_roll_avg  \\\n",
       "0                    0.000000                 0.000000   \n",
       "1                    0.000000                 0.000000   \n",
       "2                    0.000000                 0.000000   \n",
       "3                    0.000000                 0.000000   \n",
       "4                    0.000000                 0.000000   \n",
       "...                       ...                      ...   \n",
       "26956               20.058333                35.033333   \n",
       "26957                2.458333                10.458333   \n",
       "26958                0.033333                 0.941667   \n",
       "26959                0.000000                 0.000000   \n",
       "26960                0.000000                 0.000000   \n",
       "\n",
       "       direct_rad_6h_roll_avg  diffuse_rad_6h_roll_avg  \\\n",
       "0                    0.000000                 0.000000   \n",
       "1                    0.000000                 0.000000   \n",
       "2                    0.000000                 0.000000   \n",
       "3                    0.000000                 0.000000   \n",
       "4                    0.000000                 0.000000   \n",
       "...                       ...                      ...   \n",
       "26956               83.608334                94.829166   \n",
       "26957               52.808334                63.945835   \n",
       "26958               26.433334                37.866667   \n",
       "26959               10.029167                17.516666   \n",
       "26960                1.229167                 5.229167   \n",
       "\n",
       "       direct_rad_x_sun_elevation  \n",
       "0                        -0.00000  \n",
       "1                        -0.00000  \n",
       "2                        -0.00000  \n",
       "3                        -0.00000  \n",
       "4                        -0.00000  \n",
       "...                           ...  \n",
       "26956                    -0.01805  \n",
       "26957                    -0.00000  \n",
       "26958                    -0.00000  \n",
       "26959                    -0.00000  \n",
       "26960                    -0.00000  \n",
       "\n",
       "[26961 rows x 66 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_b = pd.read_csv('cleaned_data/B/x_train_b.csv')\n",
    "y_train_b = pd.read_csv('cleaned_data/B/train_b.csv')\n",
    "x_test_b = pd.read_csv('cleaned_data/B/x_test_b.csv')\n",
    "\n",
    "x_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_c = pd.read_csv('cleaned_data/C/x_train_c.csv')\n",
    "y_train_c = pd.read_csv('cleaned_data/C/train_c.csv')\n",
    "x_test_c = pd.read_csv('cleaned_data/C/x_test_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTimeSeriesSplit(_BaseKFold):\n",
    "    def __init__(self, n_splits, train_size=None, test_size=None):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        # Define initial sizes if not provided\n",
    "        train_size = self.train_size or n_samples // (self.n_splits + 1)\n",
    "        test_size = self.test_size or n_samples // self.n_splits\n",
    "\n",
    "        for test_start in range(train_size + test_size, n_samples, test_size):\n",
    "            train_end = test_start - test_size\n",
    "            train_start = max(train_end - train_size, 0)\n",
    "            yield indices[train_start:train_end], indices[train_end:test_start]\n",
    "\n",
    "# Example usage\n",
    "# tscv = CustomTimeSeriesSplit(n_splits=5, train_size=720, test_size=120)\n",
    "\n",
    "# for train_idx, test_idx in tscv.split(x_train_a):\n",
    "#     print(\"Train indices:\", train_idx)\n",
    "#     print(\"Test indices:\", test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a_combined = x_train_a.merge(y_train_a, left_on='date_forecast', right_on='time', how='left')\n",
    "x_train_a_combined['observed'] = x_train_a_combined['calc_year'].isna().astype(int)\n",
    "train_data_a = x_train_a_combined.drop(['time', 'calc_year', 'calc_month', 'calc_day', 'calc_hour','hour_sin','hour_cos','month_sin','month_cos','day_of_year_sin','day_of_year_cos','direct_rad_3h_roll_avg','diffuse_rad_3h_roll_avg','direct_rad_6h_roll_avg','diffuse_rad_6h_roll_avg', 'direct_rad_x_sun_elevation','day_of_year', 'forecast_year','forecast_month','forecast_day','forecast_hour'], axis = 1)\n",
    "x_test_a['observed'] = x_test_a['calc_year'].isna().astype(int)\n",
    "test_data_a = x_test_a.drop([ 'calc_year', 'calc_month', 'calc_day', 'calc_hour','hour_sin','hour_cos','month_sin','month_cos','day_of_year_sin','day_of_year_cos','direct_rad_3h_roll_avg','diffuse_rad_3h_roll_avg','direct_rad_6h_roll_avg','diffuse_rad_6h_roll_avg', 'direct_rad_x_sun_elevation','day_of_year','forecast_year','forecast_month','forecast_day','forecast_hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_b_combined = x_train_b.merge(y_train_b, left_on='date_forecast', right_on='time', how='left')\n",
    "x_train_b_combined['observed'] = x_train_b_combined['calc_year'].isna().astype(int)\n",
    "\n",
    "train_data_b = x_train_b_combined.drop(['time', 'calc_year', 'calc_month', 'calc_day', 'calc_hour','hour_sin','hour_cos','month_sin','month_cos','day_of_year_sin','day_of_year_cos','direct_rad_3h_roll_avg','diffuse_rad_3h_roll_avg','direct_rad_6h_roll_avg','diffuse_rad_6h_roll_avg', 'direct_rad_x_sun_elevation','day_of_year','forecast_year','forecast_month','forecast_day','forecast_hour'], axis = 1)\n",
    "x_test_b['observed'] = x_test_b['calc_year'].isna().astype(int)\n",
    "test_data_b = x_test_b.drop([ 'calc_year', 'calc_month', 'calc_day', 'calc_hour','hour_sin','hour_cos','month_sin','month_cos','day_of_year_sin','day_of_year_cos','direct_rad_3h_roll_avg','diffuse_rad_3h_roll_avg','direct_rad_6h_roll_avg','diffuse_rad_6h_roll_avg', 'direct_rad_x_sun_elevation','day_of_year','forecast_year','forecast_month','forecast_day','forecast_hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_c_combined = x_train_c.merge(y_train_c, left_on='date_forecast', right_on='time', how='left')\n",
    "x_train_c_combined['observed'] = x_train_c_combined['calc_year'].isna().astype(int)\n",
    "train_data_c = x_train_c_combined.drop(['time', 'calc_year', 'calc_month', 'calc_day', 'calc_hour','hour_sin','hour_cos','month_sin','month_cos','day_of_year_sin','day_of_year_cos','direct_rad_3h_roll_avg','diffuse_rad_3h_roll_avg','direct_rad_6h_roll_avg','diffuse_rad_6h_roll_avg', 'direct_rad_x_sun_elevation','day_of_year','forecast_year','forecast_month','forecast_day','forecast_hour'], axis = 1)\n",
    "x_test_c['observed'] = x_test_c['calc_year'].isna().astype(int)\n",
    "test_data_c = x_test_c.drop([ 'calc_year', 'calc_month', 'calc_day', 'calc_hour','hour_sin','hour_cos','month_sin','month_cos','day_of_year_sin','day_of_year_cos','direct_rad_3h_roll_avg','diffuse_rad_3h_roll_avg','direct_rad_6h_roll_avg','diffuse_rad_6h_roll_avg', 'direct_rad_x_sun_elevation','day_of_year','forecast_year','forecast_month','forecast_day','forecast_hour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>forecast_year</th>\n",
       "      <th>forecast_month</th>\n",
       "      <th>forecast_day</th>\n",
       "      <th>forecast_hour</th>\n",
       "      <th>observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>4.300</td>\n",
       "      <td>1.28300</td>\n",
       "      <td>912.3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1059.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.65002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>31107.600</td>\n",
       "      <td>3.950</td>\n",
       "      <td>2.100</td>\n",
       "      <td>3.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>4.250</td>\n",
       "      <td>1.28300</td>\n",
       "      <td>1482.8002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1073.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.45000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>30409.700</td>\n",
       "      <td>3.825</td>\n",
       "      <td>1.925</td>\n",
       "      <td>3.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>4.150</td>\n",
       "      <td>1.28275</td>\n",
       "      <td>1765.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1200.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.05000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>31342.650</td>\n",
       "      <td>3.650</td>\n",
       "      <td>1.750</td>\n",
       "      <td>3.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>4.025</td>\n",
       "      <td>1.28225</td>\n",
       "      <td>2269.7500</td>\n",
       "      <td>40510.2</td>\n",
       "      <td>11.675</td>\n",
       "      <td>1179.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.65000</td>\n",
       "      <td>9.375</td>\n",
       "      <td>...</td>\n",
       "      <td>34475.523</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.475</td>\n",
       "      <td>3.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>3.900</td>\n",
       "      <td>1.28200</td>\n",
       "      <td>2198.2250</td>\n",
       "      <td>567057.1</td>\n",
       "      <td>76.900</td>\n",
       "      <td>919.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.37500</td>\n",
       "      <td>47.400</td>\n",
       "      <td>...</td>\n",
       "      <td>35069.074</td>\n",
       "      <td>3.325</td>\n",
       "      <td>1.300</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>B</td>\n",
       "      <td>8.350</td>\n",
       "      <td>1.19800</td>\n",
       "      <td>3640.1250</td>\n",
       "      <td>1908360.9</td>\n",
       "      <td>85.100</td>\n",
       "      <td>2015.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.57500</td>\n",
       "      <td>33.625</td>\n",
       "      <td>...</td>\n",
       "      <td>43617.250</td>\n",
       "      <td>2.475</td>\n",
       "      <td>2.075</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>B</td>\n",
       "      <td>8.525</td>\n",
       "      <td>1.20075</td>\n",
       "      <td>3351.1000</td>\n",
       "      <td>737351.8</td>\n",
       "      <td>24.800</td>\n",
       "      <td>1613.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.85000</td>\n",
       "      <td>14.350</td>\n",
       "      <td>...</td>\n",
       "      <td>43830.600</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.100</td>\n",
       "      <td>-1.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>B</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1.20375</td>\n",
       "      <td>2753.0250</td>\n",
       "      <td>149728.8</td>\n",
       "      <td>1.275</td>\n",
       "      <td>1624.450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.30000</td>\n",
       "      <td>1.300</td>\n",
       "      <td>...</td>\n",
       "      <td>43401.027</td>\n",
       "      <td>2.575</td>\n",
       "      <td>2.150</td>\n",
       "      <td>-1.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>B</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1.20600</td>\n",
       "      <td>2204.5000</td>\n",
       "      <td>1440.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1768.325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.67502</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>40885.900</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.800</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>B</td>\n",
       "      <td>9.025</td>\n",
       "      <td>1.20700</td>\n",
       "      <td>2015.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1441.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.67502</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>40104.550</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.600</td>\n",
       "      <td>-1.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    location  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "0          B                     4.300              1.28300   \n",
       "1          B                     4.250              1.28300   \n",
       "2          B                     4.150              1.28275   \n",
       "3          B                     4.025              1.28225   \n",
       "4          B                     3.900              1.28200   \n",
       "..       ...                       ...                  ...   \n",
       "715        B                     8.350              1.19800   \n",
       "716        B                     8.525              1.20075   \n",
       "717        B                     8.800              1.20375   \n",
       "718        B                     9.000              1.20600   \n",
       "719        B                     9.025              1.20700   \n",
       "\n",
       "     ceiling_height_agl:m  clear_sky_energy_1h:J  clear_sky_rad:W  \\\n",
       "0                912.3000                    0.0            0.000   \n",
       "1               1482.8002                    0.0            0.000   \n",
       "2               1765.9000                    0.0            0.000   \n",
       "3               2269.7500                40510.2           11.675   \n",
       "4               2198.2250               567057.1           76.900   \n",
       "..                    ...                    ...              ...   \n",
       "715             3640.1250              1908360.9           85.100   \n",
       "716             3351.1000               737351.8           24.800   \n",
       "717             2753.0250               149728.8            1.275   \n",
       "718             2204.5000                 1440.5            0.000   \n",
       "719             2015.1000                    0.0            0.000   \n",
       "\n",
       "     cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  ...  \\\n",
       "0            1059.750              0.0       271.65002          0.000  ...   \n",
       "1            1073.700              0.0       271.45000          0.000  ...   \n",
       "2            1200.100              0.0       271.05000          0.000  ...   \n",
       "3            1179.000              0.0       270.65000          9.375  ...   \n",
       "4             919.150              0.0       270.37500         47.400  ...   \n",
       "..                ...              ...             ...            ...  ...   \n",
       "715          2015.750              0.0       281.57500         33.625  ...   \n",
       "716          1613.375              0.0       281.85000         14.350  ...   \n",
       "717          1624.450              0.0       282.30000          1.300  ...   \n",
       "718          1768.325              0.0       282.67502          0.000  ...   \n",
       "719          1441.100              0.0       282.67502          0.000  ...   \n",
       "\n",
       "     visibility:m  wind_speed_10m:ms  wind_speed_u_10m:ms  \\\n",
       "0       31107.600              3.950                2.100   \n",
       "1       30409.700              3.825                1.925   \n",
       "2       31342.650              3.650                1.750   \n",
       "3       34475.523              3.500                1.475   \n",
       "4       35069.074              3.325                1.300   \n",
       "..            ...                ...                  ...   \n",
       "715     43617.250              2.475                2.075   \n",
       "716     43830.600              2.450                2.100   \n",
       "717     43401.027              2.575                2.150   \n",
       "718     40885.900              2.250                1.800   \n",
       "719     40104.550              2.000                1.600   \n",
       "\n",
       "     wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  forecast_year  \\\n",
       "0                  3.375                      0.0           2023   \n",
       "1                  3.300                      0.0           2023   \n",
       "2                  3.225                      0.0           2023   \n",
       "3                  3.150                      0.0           2023   \n",
       "4                  3.075                      0.0           2023   \n",
       "..                   ...                      ...            ...   \n",
       "715               -1.350                      0.0           2023   \n",
       "716               -1.275                      0.0           2023   \n",
       "717               -1.400                      0.0           2023   \n",
       "718               -1.350                      0.0           2023   \n",
       "719               -1.175                      0.0           2023   \n",
       "\n",
       "     forecast_month  forecast_day  forecast_hour  observed  \n",
       "0                 5             1              0         0  \n",
       "1                 5             1              1         0  \n",
       "2                 5             1              2         0  \n",
       "3                 5             1              3         0  \n",
       "4                 5             1              4         0  \n",
       "..              ...           ...            ...       ...  \n",
       "715               7             3             19         0  \n",
       "716               7             3             20         0  \n",
       "717               7             3             21         0  \n",
       "718               7             3             22         0  \n",
       "719               7             3             23         0  \n",
       "\n",
       "[720 rows x 51 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>forecast_year</th>\n",
       "      <th>forecast_month</th>\n",
       "      <th>forecast_day</th>\n",
       "      <th>forecast_hour</th>\n",
       "      <th>pv_measurement</th>\n",
       "      <th>observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-02 22:00:00</td>\n",
       "      <td>7.700</td>\n",
       "      <td>1.22825</td>\n",
       "      <td>1728.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1728.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.30000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.600</td>\n",
       "      <td>-3.575</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-02 23:00:00</td>\n",
       "      <td>7.700</td>\n",
       "      <td>1.22350</td>\n",
       "      <td>1689.825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1689.825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.30000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.350</td>\n",
       "      <td>-3.350</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-03 00:00:00</td>\n",
       "      <td>7.875</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1563.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1563.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.65000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.050</td>\n",
       "      <td>-2.950</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-03 01:00:00</td>\n",
       "      <td>8.425</td>\n",
       "      <td>1.21800</td>\n",
       "      <td>1283.425</td>\n",
       "      <td>834.6</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1283.425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.67500</td>\n",
       "      <td>0.300</td>\n",
       "      <td>...</td>\n",
       "      <td>2.725</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-03 02:00:00</td>\n",
       "      <td>8.950</td>\n",
       "      <td>1.21800</td>\n",
       "      <td>1003.500</td>\n",
       "      <td>129872.6</td>\n",
       "      <td>23.100</td>\n",
       "      <td>1003.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.50000</td>\n",
       "      <td>11.975</td>\n",
       "      <td>...</td>\n",
       "      <td>2.550</td>\n",
       "      <td>-2.350</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>2023-01-29 06:00:00</td>\n",
       "      <td>5.125</td>\n",
       "      <td>1.26000</td>\n",
       "      <td>1747.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1091.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.05000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.600</td>\n",
       "      <td>1.275</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31884</th>\n",
       "      <td>2023-01-29 07:00:00</td>\n",
       "      <td>5.200</td>\n",
       "      <td>1.25800</td>\n",
       "      <td>1342.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1084.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.20000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.800</td>\n",
       "      <td>3.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31885</th>\n",
       "      <td>2023-01-29 08:00:00</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1.25575</td>\n",
       "      <td>1255.175</td>\n",
       "      <td>19398.6</td>\n",
       "      <td>6.625</td>\n",
       "      <td>974.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.15002</td>\n",
       "      <td>1.625</td>\n",
       "      <td>...</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.300</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31886</th>\n",
       "      <td>2023-01-29 09:00:00</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1.25300</td>\n",
       "      <td>1177.000</td>\n",
       "      <td>320519.0</td>\n",
       "      <td>40.525</td>\n",
       "      <td>916.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.15000</td>\n",
       "      <td>8.175</td>\n",
       "      <td>...</td>\n",
       "      <td>2.675</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2.650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>52.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31887</th>\n",
       "      <td>2023-01-29 10:00:00</td>\n",
       "      <td>5.300</td>\n",
       "      <td>1.24975</td>\n",
       "      <td>1147.650</td>\n",
       "      <td>854954.8</td>\n",
       "      <td>76.625</td>\n",
       "      <td>806.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.45000</td>\n",
       "      <td>13.625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.275</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>66.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31888 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "0      2019-06-02 22:00:00                     7.700              1.22825   \n",
       "1      2019-06-02 23:00:00                     7.700              1.22350   \n",
       "2      2019-06-03 00:00:00                     7.875              1.21975   \n",
       "3      2019-06-03 01:00:00                     8.425              1.21800   \n",
       "4      2019-06-03 02:00:00                     8.950              1.21800   \n",
       "...                    ...                       ...                  ...   \n",
       "31883  2023-01-29 06:00:00                     5.125              1.26000   \n",
       "31884  2023-01-29 07:00:00                     5.200              1.25800   \n",
       "31885  2023-01-29 08:00:00                     5.175              1.25575   \n",
       "31886  2023-01-29 09:00:00                     5.175              1.25300   \n",
       "31887  2023-01-29 10:00:00                     5.300              1.24975   \n",
       "\n",
       "       ceiling_height_agl:m  clear_sky_energy_1h:J  clear_sky_rad:W  \\\n",
       "0                  1728.950                    0.0            0.000   \n",
       "1                  1689.825                    0.0            0.000   \n",
       "2                  1563.225                    0.0            0.000   \n",
       "3                  1283.425                  834.6            0.750   \n",
       "4                  1003.500               129872.6           23.100   \n",
       "...                     ...                    ...              ...   \n",
       "31883              1747.100                    0.0            0.000   \n",
       "31884              1342.025                    0.0            0.000   \n",
       "31885              1255.175                19398.6            6.625   \n",
       "31886              1177.000               320519.0           40.525   \n",
       "31887              1147.650               854954.8           76.625   \n",
       "\n",
       "       cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  ...  \\\n",
       "0              1728.950              0.0       280.30000          0.000  ...   \n",
       "1              1689.825              0.0       280.30000          0.000  ...   \n",
       "2              1563.225              0.0       280.65000          0.000  ...   \n",
       "3              1283.425              0.0       281.67500          0.300  ...   \n",
       "4              1003.500              0.0       282.50000         11.975  ...   \n",
       "...                 ...              ...             ...            ...  ...   \n",
       "31883          1091.250              0.0       274.05000          0.000  ...   \n",
       "31884          1084.025              0.0       274.20000          0.000  ...   \n",
       "31885           974.000              0.0       274.15002          1.625  ...   \n",
       "31886           916.350              0.0       274.15000          8.175  ...   \n",
       "31887           806.000              0.0       274.45000         13.625  ...   \n",
       "\n",
       "       wind_speed_10m:ms  wind_speed_u_10m:ms  wind_speed_v_10m:ms  \\\n",
       "0                  3.600               -3.575               -0.500   \n",
       "1                  3.350               -3.350                0.275   \n",
       "2                  3.050               -2.950                0.750   \n",
       "3                  2.725               -2.600                0.875   \n",
       "4                  2.550               -2.350                0.925   \n",
       "...                  ...                  ...                  ...   \n",
       "31883              3.600                1.275                3.350   \n",
       "31884              3.350                0.800                3.250   \n",
       "31885              3.050                0.300                3.050   \n",
       "31886              2.675                0.250                2.650   \n",
       "31887              2.275                0.400                2.250   \n",
       "\n",
       "       wind_speed_w_1000hPa:ms  forecast_year  forecast_month  forecast_day  \\\n",
       "0                          0.0           2019               6             2   \n",
       "1                          0.0           2019               6             2   \n",
       "2                          0.0           2019               6             3   \n",
       "3                          0.0           2019               6             3   \n",
       "4                          0.0           2019               6             3   \n",
       "...                        ...            ...             ...           ...   \n",
       "31883                      0.0           2023               1            29   \n",
       "31884                      0.0           2023               1            29   \n",
       "31885                      0.0           2023               1            29   \n",
       "31886                      0.0           2023               1            29   \n",
       "31887                      0.0           2023               1            29   \n",
       "\n",
       "       forecast_hour  pv_measurement  observed  \n",
       "0                 22            0.00         1  \n",
       "1                 23            0.00         1  \n",
       "2                  0            0.00         1  \n",
       "3                  1            0.00         1  \n",
       "4                  2           19.36         1  \n",
       "...              ...             ...       ...  \n",
       "31883              6            0.00         0  \n",
       "31884              7            0.00         0  \n",
       "31885              8            0.88         0  \n",
       "31886              9           52.80         0  \n",
       "31887             10           66.22         0  \n",
       "\n",
       "[31888 rows x 52 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with validation set equal to half of the estimated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_data, observed_column='observed'):\n",
    "    \"\"\"\n",
    "    Splits the dataset into a training set and a validation set.\n",
    "    The validation set contains the last half of the rows where observed = 0,\n",
    "    and the training set contains the rest.\n",
    "\n",
    "    :param train_data: The original training dataset as a pandas DataFrame.\n",
    "    :param observed_column: The name of the column that indicates if the row is observed.\n",
    "    :return: A tuple (training_set, validation_set)\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter rows where observed = 0\n",
    "    observed_zero = train_data[train_data[observed_column] == 0]\n",
    "\n",
    "    # Split the filtered dataset into two\n",
    "    half_index = len(observed_zero) // 2\n",
    "    validation_set = observed_zero[half_index:]\n",
    "\n",
    "    # Combine the first half of observed_zero with the rest of the data where observed != 0\n",
    "    training_set = pd.concat([train_data[train_data[observed_column] != 0], observed_zero[:half_index]])\n",
    "\n",
    "    return training_set, validation_set\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# train_data_a, val_data_a = split_dataset(train_data_a, 'observed')\n",
    "# train_data_b, val_data_b = split_dataset(train_data_b, 'observed')\n",
    "# train_data_c, val_data_c = split_dataset(train_data_c, 'observed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>forecast_year</th>\n",
       "      <th>forecast_month</th>\n",
       "      <th>forecast_day</th>\n",
       "      <th>forecast_hour</th>\n",
       "      <th>pv_measurement</th>\n",
       "      <th>observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31888</th>\n",
       "      <td>2023-01-29 11:00:00</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1.24575</td>\n",
       "      <td>1226.200</td>\n",
       "      <td>1258656.200</td>\n",
       "      <td>93.950</td>\n",
       "      <td>804.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.700</td>\n",
       "      <td>16.325</td>\n",
       "      <td>...</td>\n",
       "      <td>2.200</td>\n",
       "      <td>0.350</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31889</th>\n",
       "      <td>2023-01-29 12:00:00</td>\n",
       "      <td>5.500</td>\n",
       "      <td>1.24150</td>\n",
       "      <td>1717.325</td>\n",
       "      <td>1315152.800</td>\n",
       "      <td>84.200</td>\n",
       "      <td>946.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.050</td>\n",
       "      <td>11.450</td>\n",
       "      <td>...</td>\n",
       "      <td>2.450</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>37.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31890</th>\n",
       "      <td>2023-01-29 13:00:00</td>\n",
       "      <td>5.650</td>\n",
       "      <td>1.23650</td>\n",
       "      <td>1940.650</td>\n",
       "      <td>997982.700</td>\n",
       "      <td>51.750</td>\n",
       "      <td>922.575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.425</td>\n",
       "      <td>8.675</td>\n",
       "      <td>...</td>\n",
       "      <td>2.475</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>33.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31891</th>\n",
       "      <td>2023-01-29 14:00:00</td>\n",
       "      <td>5.750</td>\n",
       "      <td>1.23175</td>\n",
       "      <td>1281.750</td>\n",
       "      <td>470574.600</td>\n",
       "      <td>14.425</td>\n",
       "      <td>957.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.700</td>\n",
       "      <td>2.200</td>\n",
       "      <td>...</td>\n",
       "      <td>3.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31892</th>\n",
       "      <td>2023-01-29 15:00:00</td>\n",
       "      <td>5.850</td>\n",
       "      <td>1.22725</td>\n",
       "      <td>1558.850</td>\n",
       "      <td>63008.402</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1202.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.725</td>\n",
       "      <td>0.950</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "31888  2023-01-29 11:00:00                     5.375              1.24575   \n",
       "31889  2023-01-29 12:00:00                     5.500              1.24150   \n",
       "31890  2023-01-29 13:00:00                     5.650              1.23650   \n",
       "31891  2023-01-29 14:00:00                     5.750              1.23175   \n",
       "31892  2023-01-29 15:00:00                     5.850              1.22725   \n",
       "\n",
       "       ceiling_height_agl:m  clear_sky_energy_1h:J  clear_sky_rad:W  \\\n",
       "31888              1226.200            1258656.200           93.950   \n",
       "31889              1717.325            1315152.800           84.200   \n",
       "31890              1940.650             997982.700           51.750   \n",
       "31891              1281.750             470574.600           14.425   \n",
       "31892              1558.850              63008.402            0.000   \n",
       "\n",
       "       cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  ...  \\\n",
       "31888           804.000              0.0         274.700         16.325  ...   \n",
       "31889           946.400              0.0         275.050         11.450  ...   \n",
       "31890           922.575              0.0         275.425          8.675  ...   \n",
       "31891           957.025              0.0         275.700          2.200  ...   \n",
       "31892          1202.300              0.0         275.975          0.000  ...   \n",
       "\n",
       "       wind_speed_10m:ms  wind_speed_u_10m:ms  wind_speed_v_10m:ms  \\\n",
       "31888              2.200                0.350                 2.15   \n",
       "31889              2.450               -0.100                 2.45   \n",
       "31890              2.475               -0.475                 2.45   \n",
       "31891              3.100                0.000                 3.05   \n",
       "31892              3.725                0.950                 3.60   \n",
       "\n",
       "       wind_speed_w_1000hPa:ms  forecast_year  forecast_month  forecast_day  \\\n",
       "31888                      0.0           2023               1            29   \n",
       "31889                      0.0           2023               1            29   \n",
       "31890                      0.0           2023               1            29   \n",
       "31891                      0.0           2023               1            29   \n",
       "31892                      0.0           2023               1            29   \n",
       "\n",
       "       forecast_hour  pv_measurement  observed  \n",
       "31888             11           68.20         0  \n",
       "31889             12           37.18         0  \n",
       "31890             13           33.66         0  \n",
       "31891             14            1.54         0  \n",
       "31892             15            0.00         0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#val_data_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231102_153411\\\"\n",
      "Presets specified: ['best_quality']\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 1500s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231102_153411\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   706.87 GB / 1022.87 GB (69.1%)\n",
      "Train Data Rows:    31888\n",
      "Train Data Columns: 51\n",
      "Tuning Data Rows:    2197\n",
      "Tuning Data Columns: 51\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 633.37107, 1165.80106)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:223: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2960.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.09 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\features\\generators\\fillna.py:58: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  X.fillna(self._fillna_feature_map, inplace=True, downcast=False)\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                        :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'observed']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['date_forecast']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                  :  4 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour']\n",
      "\t\t('int', ['bool'])            :  3 | ['elevation:m', 'snow_density:kgm3', 'observed']\n",
      "\t\t('int', ['datetime_as_int']) :  2 | ['date_forecast', 'date_forecast.dayofweek']\n",
      "\t1.0s = Fit runtime\n",
      "\t50 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.19 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 999.04s of the 1498.93s of remaining time.\n",
      "C:\\Users\\holwe\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\holwe\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 217, in _count_physical_cores\n",
      "    raise ValueError(\n",
      "\t-591.5461\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 995.62s of the 1495.51s of remaining time.\n",
      "\t-591.5789\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 994.2s of the 1494.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\holwe\\Documents\\1. Skole\\4. høst\\Maskinlæring\\Prosjekt\\data(1)\\MLprosjekt\\data\\autogluon.ipynb Cell 16\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/holwe/Documents/1.%20Skole/4.%20h%C3%B8st/Maskinl%C3%A6ring/Prosjekt/data%281%29/MLprosjekt/data/autogluon.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictor_a\u001b[39m=\u001b[39m TabularPredictor(label \u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpv_measurement\u001b[39;49m\u001b[39m'\u001b[39;49m,eval_metric\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(train_data \u001b[39m=\u001b[39;49m train_data_a, tuning_data\u001b[39m=\u001b[39;49m val_data_a, use_bag_holdout\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,verbosity \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,presets\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbest_quality\u001b[39;49m\u001b[39m'\u001b[39;49m, time_limit\u001b[39m=\u001b[39;49m \u001b[39m1500\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39mgargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgkwargs)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[0;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[0;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[0;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[0;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[0;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[0;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[0;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[0;32m   1002\u001b[0m )\n\u001b[0;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[0;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m   1013\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39mfit(\n\u001b[0;32m    158\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    159\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39mholdout_frac,\n\u001b[0;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39mtime_limit_trainer,\n\u001b[0;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    167\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    168\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_fit_kwargs,\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[0;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[0;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2371\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_rows_val \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_val)\n\u001b[0;32m   2370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_cols_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m-> 2371\u001b[0m model_names_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_multi_levels(\n\u001b[0;32m   2372\u001b[0m     X,\n\u001b[0;32m   2373\u001b[0m     y,\n\u001b[0;32m   2374\u001b[0m     hyperparameters\u001b[39m=\u001b[39mhyperparameters,\n\u001b[0;32m   2375\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m   2376\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m   2377\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m   2378\u001b[0m     level_start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   2379\u001b[0m     level_end\u001b[39m=\u001b[39mnum_stack_levels \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m   2380\u001b[0m     time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2381\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2382\u001b[0m )\n\u001b[0;32m   2383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_names()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2384\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAutoGluon did not successfully train any models\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:395\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    393\u001b[0m         core_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_core)\n\u001b[0;32m    394\u001b[0m         aux_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_aux)\n\u001b[1;32m--> 395\u001b[0m     base_model_names, aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level(\n\u001b[0;32m    396\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    397\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    398\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    399\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    400\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    401\u001b[0m         models\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    402\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    403\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[0;32m    404\u001b[0m         core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs_level,\n\u001b[0;32m    405\u001b[0m         aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs_level,\n\u001b[0;32m    406\u001b[0m         name_suffix\u001b[39m=\u001b[39;49mname_suffix,\n\u001b[0;32m    407\u001b[0m         infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    408\u001b[0m         infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    410\u001b[0m     model_names_fit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m base_model_names \u001b[39m+\u001b[39m aux_models\n\u001b[0;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_best \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(model_names_fit) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:539\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    537\u001b[0m     core_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[0;32m    538\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[1;32m--> 539\u001b[0m core_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_core(\n\u001b[0;32m    540\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    541\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    542\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    543\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    544\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    545\u001b[0m     models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m    546\u001b[0m     level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m    547\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m    548\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    549\u001b[0m     base_model_names\u001b[39m=\u001b[39mbase_model_names,\n\u001b[0;32m    550\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcore_kwargs,\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    553\u001b[0m \u001b[39mif\u001b[39;00m X_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    554\u001b[0m     aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_aux(\n\u001b[0;32m    555\u001b[0m         X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, base_model_names\u001b[39m=\u001b[39mcore_models, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, infer_limit\u001b[39m=\u001b[39minfer_limit, infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maux_kwargs\n\u001b[0;32m    556\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:673\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m    672\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi(\n\u001b[0;32m    674\u001b[0m     X\u001b[39m=\u001b[39mX_init,\n\u001b[0;32m    675\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    676\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    677\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    678\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    679\u001b[0m     models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m    680\u001b[0m     level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m    681\u001b[0m     stack_name\u001b[39m=\u001b[39mstack_name,\n\u001b[0;32m    682\u001b[0m     compute_score\u001b[39m=\u001b[39mcompute_score,\n\u001b[0;32m    683\u001b[0m     fit_kwargs\u001b[39m=\u001b[39mfit_kwargs,\n\u001b[0;32m    684\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    685\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2321\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2320\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m-> 2321\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi_initial(\n\u001b[0;32m   2322\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   2323\u001b[0m         y\u001b[39m=\u001b[39my,\n\u001b[0;32m   2324\u001b[0m         models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m   2325\u001b[0m         k_fold\u001b[39m=\u001b[39mk_fold,\n\u001b[0;32m   2326\u001b[0m         n_repeats\u001b[39m=\u001b[39mn_repeats_initial,\n\u001b[0;32m   2327\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m   2328\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39mfeature_prune_kwargs,\n\u001b[0;32m   2329\u001b[0m         time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2330\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[0;32m   2333\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2170\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2169\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 2170\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi_fold(\n\u001b[0;32m   2171\u001b[0m         models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m   2172\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m   2173\u001b[0m         k_fold_start\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   2174\u001b[0m         k_fold_end\u001b[39m=\u001b[39mk_fold,\n\u001b[0;32m   2175\u001b[0m         n_repeats\u001b[39m=\u001b[39mn_repeats,\n\u001b[0;32m   2176\u001b[0m         n_repeat_start\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   2177\u001b[0m         time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2178\u001b[0m         time_split\u001b[39m=\u001b[39mtime_split,\n\u001b[0;32m   2179\u001b[0m         time_ratio\u001b[39m=\u001b[39mtime_ratio,\n\u001b[0;32m   2180\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args,\n\u001b[0;32m   2181\u001b[0m     )\n\u001b[0;32m   2183\u001b[0m multi_fold_time_elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m multi_fold_time_start\n\u001b[0;32m   2184\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2278\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2276\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   2277\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[1;32m-> 2278\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single_full(\n\u001b[0;32m   2279\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   2280\u001b[0m )\n\u001b[0;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m   2283\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2051\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[0;32m   2047\u001b[0m         bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[0;32m   2048\u001b[0m             k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[0;32m   2049\u001b[0m         )\n\u001b[0;32m   2050\u001b[0m         model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[1;32m-> 2051\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_and_save(\n\u001b[0;32m   2052\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   2053\u001b[0m         y\u001b[39m=\u001b[39my,\n\u001b[0;32m   2054\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   2055\u001b[0m         X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m   2056\u001b[0m         y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m   2057\u001b[0m         X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m   2058\u001b[0m         stack_name\u001b[39m=\u001b[39mstack_name,\n\u001b[0;32m   2059\u001b[0m         level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m   2060\u001b[0m         compute_score\u001b[39m=\u001b[39mcompute_score,\n\u001b[0;32m   2061\u001b[0m         total_resources\u001b[39m=\u001b[39mtotal_resources,\n\u001b[0;32m   2062\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs,\n\u001b[0;32m   2063\u001b[0m     )\n\u001b[0;32m   2064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m   2065\u001b[0m \u001b[39mreturn\u001b[39;00m model_names_trained\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1733\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[1;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1731\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1732\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1733\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X, y, model, X_val, y_val, total_resources\u001b[39m=\u001b[39mtotal_resources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1735\u001b[0m fit_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_evaluation:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1684\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[1;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_single\u001b[39m(\u001b[39mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, total_resources\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AbstractModel:\n\u001b[0;32m   1680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[39m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[0;32m   1682\u001b[0m \u001b[39m    Returns trained model object.\u001b[39;00m\n\u001b[0;32m   1683\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1684\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, X_val\u001b[39m=\u001b[39mX_val, y_val\u001b[39m=\u001b[39my_val, total_resources\u001b[39m=\u001b[39mtotal_resources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1685\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py:169\u001b[0m, in \u001b[0;36mStackerEnsembleModel._fit\u001b[1;34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     time_limit \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[1;32m--> 169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_fit(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, time_limit\u001b[39m=\u001b[39mtime_limit, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:266\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit\u001b[1;34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[39m# Reserve time for final refit model\u001b[39;00m\n\u001b[0;32m    265\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m folds_to_fit \u001b[39m/\u001b[39m (folds_to_fit \u001b[39m+\u001b[39m \u001b[39m1.2\u001b[39m)\n\u001b[1;32m--> 266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_folds(\n\u001b[0;32m    267\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    268\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    269\u001b[0m     model_base\u001b[39m=\u001b[39mmodel_base,\n\u001b[0;32m    270\u001b[0m     X_pseudo\u001b[39m=\u001b[39mX_pseudo,\n\u001b[0;32m    271\u001b[0m     y_pseudo\u001b[39m=\u001b[39my_pseudo,\n\u001b[0;32m    272\u001b[0m     k_fold\u001b[39m=\u001b[39mk_fold,\n\u001b[0;32m    273\u001b[0m     k_fold_start\u001b[39m=\u001b[39mk_fold_start,\n\u001b[0;32m    274\u001b[0m     k_fold_end\u001b[39m=\u001b[39mk_fold_end,\n\u001b[0;32m    275\u001b[0m     n_repeats\u001b[39m=\u001b[39mn_repeats,\n\u001b[0;32m    276\u001b[0m     n_repeat_start\u001b[39m=\u001b[39mn_repeat_start,\n\u001b[0;32m    277\u001b[0m     save_folds\u001b[39m=\u001b[39msave_bag_folds,\n\u001b[0;32m    278\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    279\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m )\n\u001b[0;32m    281\u001b[0m \u001b[39m# FIXME: Cleanup self\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39m# FIXME: Support `can_refit_full=False` models\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m refit_folds:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:592\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit_folds\u001b[1;34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[39mfor\u001b[39;00m fold_fit_args \u001b[39min\u001b[39;00m fold_fit_args_list:\n\u001b[0;32m    591\u001b[0m     fold_fitting_strategy\u001b[39m.\u001b[39mschedule_fold_model_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfold_fit_args)\n\u001b[1;32m--> 592\u001b[0m fold_fitting_strategy\u001b[39m.\u001b[39;49mafter_all_folds_scheduled()\n\u001b[0;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m    595\u001b[0m     \u001b[39m# No need to add child times or save child here as this already occurred in the fold_fitting_strategy\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_child(model\u001b[39m=\u001b[39mmodel, add_child_times\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:508\u001b[0m, in \u001b[0;36mParallelFoldFittingStrategy.after_all_folds_scheduled\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mray\u001b[39m.\u001b[39mis_initialized():\n\u001b[0;32m    507\u001b[0m     ray_init_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ray_init_args()\n\u001b[1;32m--> 508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mray\u001b[39m.\u001b[39minit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mray_init_args)\n\u001b[0;32m    509\u001b[0m head_node_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mray\u001b[39m.\u001b[39mget_runtime_context()\u001b[39m.\u001b[39mget_node_id()\n\u001b[0;32m    510\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDispatching folds on node \u001b[39m\u001b[39m{\u001b[39;00mhead_node_id\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\worker.py:1451\u001b[0m, in \u001b[0;36minit\u001b[1;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m     ray_params \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39m_private\u001b[39m.\u001b[39mparameter\u001b[39m.\u001b[39mRayParams(\n\u001b[0;32m   1410\u001b[0m         node_ip_address\u001b[39m=\u001b[39mnode_ip_address,\n\u001b[0;32m   1411\u001b[0m         raylet_ip_address\u001b[39m=\u001b[39mraylet_ip_address,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1445\u001b[0m         node_name\u001b[39m=\u001b[39m_node_name,\n\u001b[0;32m   1446\u001b[0m     )\n\u001b[0;32m   1447\u001b[0m     \u001b[39m# Start the Ray processes. We set shutdown_at_exit=False because we\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m     \u001b[39m# shutdown the node in the ray.shutdown call that happens in the atexit\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m     \u001b[39m# handler. We still spawn a reaper process in case the atexit handler\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[39m# isn't called.\u001b[39;00m\n\u001b[1;32m-> 1451\u001b[0m     _global_node \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49m_private\u001b[39m.\u001b[39;49mnode\u001b[39m.\u001b[39;49mNode(\n\u001b[0;32m   1452\u001b[0m         head\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1453\u001b[0m         shutdown_at_exit\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1454\u001b[0m         spawn_reaper\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1455\u001b[0m         ray_params\u001b[39m=\u001b[39;49mray_params,\n\u001b[0;32m   1456\u001b[0m     )\n\u001b[0;32m   1457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1458\u001b[0m     \u001b[39m# In this case, we are connecting to an existing cluster.\u001b[39;00m\n\u001b[0;32m   1459\u001b[0m     \u001b[39mif\u001b[39;00m num_cpus \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_gpus \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\node.py:287\u001b[0m, in \u001b[0;36mNode.__init__\u001b[1;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m# Start processes.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39mif\u001b[39;00m head:\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_head_processes()\n\u001b[0;32m    289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m connect_only:\n\u001b[0;32m    290\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_ray_processes()\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\node.py:1119\u001b[0m, in \u001b[0;36mNode.start_head_processes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ray_params\u001b[39m.\u001b[39mexternal_addresses \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_redis_address \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ray_params\u001b[39m.\u001b[39mexternal_addresses[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1119\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_gcs_server()\n\u001b[0;32m   1120\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gcs_client \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_cluster_info_to_kv()\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\node.py:952\u001b[0m, in \u001b[0;36mNode.start_gcs_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gcs_address \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node_ip_address\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mgcs_server_port\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m \u001b[39m# Initialize gcs client, which also waits for GCS to start running.\u001b[39;00m\n\u001b[1;32m--> 952\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_gcs_client()\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\node.py:585\u001b[0m, in \u001b[0;36mNode.get_gcs_client\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    584\u001b[0m     gcs_address \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgcs_address\n\u001b[1;32m--> 585\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gcs_client \u001b[39m=\u001b[39m GcsClient(address\u001b[39m=\u001b[39;49mgcs_address)\n\u001b[0;32m    586\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\gcs_utils.py:262\u001b[0m, in \u001b[0;36mGcsClient.__init__\u001b[1;34m(self, channel, address, nums_reconnect_retry)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39massert\u001b[39;00m channel\u001b[39m.\u001b[39m_aio \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel \u001b[39m=\u001b[39m channel\n\u001b[1;32m--> 262\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect()\n\u001b[0;32m    263\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nums_reconnect_retry \u001b[39m=\u001b[39m nums_reconnect_retry\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\gcs_utils.py:266\u001b[0m, in \u001b[0;36mGcsClient._connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_connect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_channel\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kv_stub \u001b[39m=\u001b[39m gcs_service_pb2_grpc\u001b[39m.\u001b[39mInternalKVGcsServiceStub(\n\u001b[0;32m    268\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel\u001b[39m.\u001b[39mchannel()\n\u001b[0;32m    269\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_runtime_env_stub \u001b[39m=\u001b[39m gcs_service_pb2_grpc\u001b[39m.\u001b[39mRuntimeEnvGcsServiceStub(\n\u001b[0;32m    271\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel\u001b[39m.\u001b[39mchannel()\n\u001b[0;32m    272\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\gcs_utils.py:234\u001b[0m, in \u001b[0;36mGcsChannel.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    231\u001b[0m     \u001b[39m# GCS server uses a cached port, so it should use the same port after\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39m# restarting. This means GCS address should stay the same for the\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# lifetime of the Ray cluster.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel \u001b[39m=\u001b[39m create_gcs_channel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gcs_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aio)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\gcs_utils.py:99\u001b[0m, in \u001b[0;36mcreate_gcs_channel\u001b[1;34m(address, aio)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a GRPC channel to GCS.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39m    grpc.Channel or grpc.aio.Channel to GCS\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m init_grpc_channel\n\u001b[1;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m init_grpc_channel(address, options\u001b[39m=\u001b[39;49m_GRPC_OPTIONS, asynchronous\u001b[39m=\u001b[39;49maio)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\utils.py:1375\u001b[0m, in \u001b[0;36minit_grpc_channel\u001b[1;34m(address, options, asynchronous)\u001b[0m\n\u001b[0;32m   1373\u001b[0m     channel \u001b[39m=\u001b[39m grpc_module\u001b[39m.\u001b[39msecure_channel(address, credentials, options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m   1374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m     channel \u001b[39m=\u001b[39m grpc_module\u001b[39m.\u001b[39;49minsecure_channel(address, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m   1377\u001b[0m \u001b[39mreturn\u001b[39;00m channel\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\grpc\\__init__.py:1978\u001b[0m, in \u001b[0;36minsecure_channel\u001b[1;34m(target, options, compression)\u001b[0m\n\u001b[0;32m   1963\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates an insecure Channel to a server.\u001b[39;00m\n\u001b[0;32m   1964\u001b[0m \n\u001b[0;32m   1965\u001b[0m \u001b[39mThe returned Channel is thread-safe.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1975\u001b[0m \u001b[39m  A Channel.\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1977\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgrpc\u001b[39;00m \u001b[39mimport\u001b[39;00m _channel  \u001b[39m# pylint: disable=cyclic-import\u001b[39;00m\n\u001b[1;32m-> 1978\u001b[0m \u001b[39mreturn\u001b[39;00m _channel\u001b[39m.\u001b[39;49mChannel(target, () \u001b[39mif\u001b[39;49;00m options \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m options, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1979\u001b[0m                         compression)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\grpc\\_channel.py:1478\u001b[0m, in \u001b[0;36mChannel.__init__\u001b[1;34m(self, target, options, credentials, compression)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_threaded_unary_stream \u001b[39m=\u001b[39m _DEFAULT_SINGLE_THREADED_UNARY_STREAM\n\u001b[0;32m   1477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_python_options(python_options)\n\u001b[1;32m-> 1478\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel \u001b[39m=\u001b[39m cygrpc\u001b[39m.\u001b[39;49mChannel(\n\u001b[0;32m   1479\u001b[0m     _common\u001b[39m.\u001b[39;49mencode(target), _augment_options(core_options, compression),\n\u001b[0;32m   1480\u001b[0m     credentials)\n\u001b[0;32m   1481\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_state \u001b[39m=\u001b[39m _ChannelCallState(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel)\n\u001b[0;32m   1482\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connectivity_state \u001b[39m=\u001b[39m _ChannelConnectivityState(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel)\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/channel.pyx.pxi:448\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.Channel.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/channel.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._ChannelState.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\threading.py:230\u001b[0m, in \u001b[0;36mCondition.__init__\u001b[1;34m(self, lock)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, lock\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m lock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m         lock \u001b[39m=\u001b[39m RLock()\n\u001b[0;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock \u001b[39m=\u001b[39m lock\n\u001b[0;32m    232\u001b[0m     \u001b[39m# Export the lock's acquire() and release() methods\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictor_a= TabularPredictor(label ='pv_measurement',eval_metric= 'mean_absolute_error').fit(train_data = train_data_a,verbosity = 2,presets='best_quality', time_limit= 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231101_115216\\\"\n",
      "Presets specified: ['best_quality']\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 1500s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231101_115216\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   705.97 GB / 1022.87 GB (69.0%)\n",
      "Train Data Rows:    25160\n",
      "Train Data Columns: 51\n",
      "Tuning Data Rows:    1801\n",
      "Tuning Data Columns: 51\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, 0.0, 103.99492, 210.91147)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:223: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3597.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.89 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 45 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  6 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('int', ['bool']) :  3 | ['elevation:m', 'snow_density:kgm3', 'observed']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.43 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 999.56s of the 1499.72s of remaining time.\n",
      "\t-46.5577\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 998.65s of the 1498.81s of remaining time.\n",
      "\t-47.0184\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 997.75s of the 1497.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-28.1614\t = Validation score   (-mean_absolute_error)\n",
      "\t67.87s\t = Training   runtime\n",
      "\t66.58s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 911.89s of the 1412.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.5091\t = Validation score   (-mean_absolute_error)\n",
      "\t83.85s\t = Training   runtime\n",
      "\t64.34s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 811.26s of the 1311.42s of remaining time.\n",
      "\t-29.2709\t = Validation score   (-mean_absolute_error)\n",
      "\t36.11s\t = Training   runtime\n",
      "\t0.96s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 773.52s of the 1273.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.2638\t = Validation score   (-mean_absolute_error)\n",
      "\t503.03s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 267.55s of the 767.71s of remaining time.\n",
      "\t-28.7094\t = Validation score   (-mean_absolute_error)\n",
      "\t7.14s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 258.72s of the 758.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t-34.3909\t = Validation score   (-mean_absolute_error)\n",
      "\t47.65s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 207.63s of the 707.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-29.4589\t = Validation score   (-mean_absolute_error)\n",
      "\t169.88s\t = Training   runtime\n",
      "\t61.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 22.0s of the 522.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-34.5945\t = Validation score   (-mean_absolute_error)\n",
      "\t19.83s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 498.86s of remaining time.\n",
      "\t-27.2288\t = Validation score   (-mean_absolute_error)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 498.54s of the 498.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-27.6729\t = Validation score   (-mean_absolute_error)\n",
      "\t5.82s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 489.35s of the 489.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-28.0503\t = Validation score   (-mean_absolute_error)\n",
      "\t3.77s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 482.01s of the 481.94s of remaining time.\n",
      "\t-28.0934\t = Validation score   (-mean_absolute_error)\n",
      "\t53.99s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 426.25s of the 426.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-28.0908\t = Validation score   (-mean_absolute_error)\n",
      "\t18.45s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 404.77s of the 404.7s of remaining time.\n",
      "\t-28.2314\t = Validation score   (-mean_absolute_error)\n",
      "\t8.71s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 394.28s of the 394.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t-28.0746\t = Validation score   (-mean_absolute_error)\n",
      "\t50.51s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 340.18s of the 340.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-28.0349\t = Validation score   (-mean_absolute_error)\n",
      "\t8.54s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 328.27s of the 328.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-29.2346\t = Validation score   (-mean_absolute_error)\n",
      "\t96.54s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 227.41s of the 227.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-28.5091\t = Validation score   (-mean_absolute_error)\n",
      "\t15.8s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 207.82s of remaining time.\n",
      "\t-27.5538\t = Validation score   (-mean_absolute_error)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1292.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231101_115216\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor_b= TabularPredictor(label ='pv_measurement',eval_metric= 'mean_absolute_error').fit(train_data = train_data_b, verbosity = 2,presets='best_quality', time_limit= 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231101_121349\\\"\n",
      "Presets specified: ['best_quality']\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 1500s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231101_121349\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   702.12 GB / 1022.87 GB (68.6%)\n",
      "Train Data Rows:    20219\n",
      "Train Data Columns: 51\n",
      "Tuning Data Rows:    1465\n",
      "Tuning Data Columns: 51\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 94.68814, 180.05102)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:223: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4298.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.76 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  6 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('int', ['bool']) :  3 | ['elevation:m', 'snow_density:kgm3', 'observed']\n",
      "\t0.4s = Fit runtime\n",
      "\t50 features in original data used to generate 50 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.22 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 999.47s of the 1499.58s of remaining time.\n",
      "\t-42.8888\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 998.84s of the 1498.95s of remaining time.\n",
      "\t-43.0238\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 998.24s of the 1498.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-40.4187\t = Validation score   (-mean_absolute_error)\n",
      "\t62.77s\t = Training   runtime\n",
      "\t66.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 919.37s of the 1419.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-40.8159\t = Validation score   (-mean_absolute_error)\n",
      "\t65.84s\t = Training   runtime\n",
      "\t43.08s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 840.67s of the 1340.78s of remaining time.\n",
      "\t-41.0529\t = Validation score   (-mean_absolute_error)\n",
      "\t26.54s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 812.81s of the 1312.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-41.2021\t = Validation score   (-mean_absolute_error)\n",
      "\t472.15s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 337.44s of the 837.55s of remaining time.\n",
      "\t-41.7568\t = Validation score   (-mean_absolute_error)\n",
      "\t4.62s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 331.59s of the 831.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t-45.8052\t = Validation score   (-mean_absolute_error)\n",
      "\t37.49s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 290.72s of the 790.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-39.695\t = Validation score   (-mean_absolute_error)\n",
      "\t187.68s\t = Training   runtime\n",
      "\t42.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 89.61s of the 589.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-35.0544\t = Validation score   (-mean_absolute_error)\n",
      "\t74.05s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 11.61s of the 511.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7452, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 194, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"C:\\Users\\holwe\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\engine.py\", line 286, in train\n",
      "    cb(callback.CallbackEnv(model=booster,\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 240, in _callback\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 240, in <listcomp>\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "TypeError: _format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7452, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 194, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"C:\\Users\\holwe\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\engine.py\", line 286, in train\n",
      "    cb(callback.CallbackEnv(model=booster,\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 240, in _callback\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "  File \"c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 240, in <listcomp>\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "TypeError: _format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 498.48s of remaining time.\n",
      "2023-11-01 13:30:31,007\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-01 13:30:31,017\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-01 13:30:31,020\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-01 13:30:31,022\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-01 13:30:31,026\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-01 13:30:31,029\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-01 13:30:31,034\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-33.4728\t = Validation score   (-mean_absolute_error)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 498.16s of the 498.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-40.2805\t = Validation score   (-mean_absolute_error)\n",
      "\t6.22s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 488.3s of the 488.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-39.3095\t = Validation score   (-mean_absolute_error)\n",
      "\t4.58s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 479.94s of the 479.88s of remaining time.\n",
      "\t-40.0029\t = Validation score   (-mean_absolute_error)\n",
      "\t46.7s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 431.77s of the 431.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-37.958\t = Validation score   (-mean_absolute_error)\n",
      "\t20.19s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 407.65s of the 407.59s of remaining time.\n",
      "\t-39.7215\t = Validation score   (-mean_absolute_error)\n",
      "\t7.41s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 398.57s of the 398.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t-37.7797\t = Validation score   (-mean_absolute_error)\n",
      "\t47.25s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 347.16s of the 347.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-38.5655\t = Validation score   (-mean_absolute_error)\n",
      "\t6.99s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 336.69s of the 336.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-36.2045\t = Validation score   (-mean_absolute_error)\n",
      "\t59.87s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 273.25s of the 273.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-40.0557\t = Validation score   (-mean_absolute_error)\n",
      "\t13.92s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 256.05s of remaining time.\n",
      "\t-36.2045\t = Validation score   (-mean_absolute_error)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1244.25s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231101_121349\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor_c= TabularPredictor(label ='pv_measurement',eval_metric= 'mean_absolute_error').fit(train_data = train_data_c, verbosity = 2,presets='best_quality', time_limit= 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-178.082495</td>\n",
       "      <td>174.447727</td>\n",
       "      <td>1127.122275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329203</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-178.523082</td>\n",
       "      <td>174.126863</td>\n",
       "      <td>1120.951374</td>\n",
       "      <td>0.628202</td>\n",
       "      <td>128.027010</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-183.667943</td>\n",
       "      <td>173.819525</td>\n",
       "      <td>998.766062</td>\n",
       "      <td>0.320865</td>\n",
       "      <td>5.841698</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-184.475402</td>\n",
       "      <td>172.704435</td>\n",
       "      <td>993.102960</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.238128</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-186.801453</td>\n",
       "      <td>173.552667</td>\n",
       "      <td>1008.368154</td>\n",
       "      <td>0.054006</td>\n",
       "      <td>15.443790</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-186.857859</td>\n",
       "      <td>80.196621</td>\n",
       "      <td>70.830802</td>\n",
       "      <td>80.196621</td>\n",
       "      <td>70.830802</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-187.288225</td>\n",
       "      <td>173.666728</td>\n",
       "      <td>998.581906</td>\n",
       "      <td>0.168068</td>\n",
       "      <td>5.657542</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-188.404671</td>\n",
       "      <td>174.267970</td>\n",
       "      <td>1054.560816</td>\n",
       "      <td>0.769310</td>\n",
       "      <td>61.636452</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-189.213515</td>\n",
       "      <td>173.616261</td>\n",
       "      <td>997.128823</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>4.204460</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-191.091235</td>\n",
       "      <td>173.894806</td>\n",
       "      <td>1006.840367</td>\n",
       "      <td>0.396145</td>\n",
       "      <td>13.916003</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-191.142783</td>\n",
       "      <td>174.920978</td>\n",
       "      <td>1006.891580</td>\n",
       "      <td>1.422317</td>\n",
       "      <td>13.967217</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-192.846055</td>\n",
       "      <td>90.380913</td>\n",
       "      <td>65.549193</td>\n",
       "      <td>90.380913</td>\n",
       "      <td>65.549193</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-194.708514</td>\n",
       "      <td>174.788420</td>\n",
       "      <td>1061.691822</td>\n",
       "      <td>1.289760</td>\n",
       "      <td>68.767458</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-198.428597</td>\n",
       "      <td>1.228816</td>\n",
       "      <td>43.833053</td>\n",
       "      <td>1.228816</td>\n",
       "      <td>43.833053</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-232.790461</td>\n",
       "      <td>0.095864</td>\n",
       "      <td>812.608263</td>\n",
       "      <td>0.095864</td>\n",
       "      <td>812.608263</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-274.850015</td>\n",
       "      <td>0.801221</td>\n",
       "      <td>0.043521</td>\n",
       "      <td>0.801221</td>\n",
       "      <td>0.043521</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-275.298709</td>\n",
       "      <td>0.795226</td>\n",
       "      <td>0.059532</td>\n",
       "      <td>0.795226</td>\n",
       "      <td>0.059532</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model   score_val  pred_time_val     fit_time  \\\n",
       "0      WeightedEnsemble_L3 -178.082495     174.447727  1127.122275   \n",
       "1    NeuralNetTorch_BAG_L2 -178.523082     174.126863  1120.951374   \n",
       "2        LightGBMXT_BAG_L2 -183.667943     173.819525   998.766062   \n",
       "3      WeightedEnsemble_L2 -184.475402     172.704435   993.102960   \n",
       "4          CatBoost_BAG_L2 -186.801453     173.552667  1008.368154   \n",
       "5          LightGBM_BAG_L1 -186.857859      80.196621    70.830802   \n",
       "6           XGBoost_BAG_L2 -187.288225     173.666728   998.581906   \n",
       "7   NeuralNetFastAI_BAG_L2 -188.404671     174.267970  1054.560816   \n",
       "8          LightGBM_BAG_L2 -189.213515     173.616261   997.128823   \n",
       "9     LightGBMLarge_BAG_L2 -191.091235     173.894806  1006.840367   \n",
       "10    ExtraTreesMSE_BAG_L2 -191.142783     174.920978  1006.891580   \n",
       "11       LightGBMXT_BAG_L1 -192.846055      90.380913    65.549193   \n",
       "12  RandomForestMSE_BAG_L2 -194.708514     174.788420  1061.691822   \n",
       "13  RandomForestMSE_BAG_L1 -198.428597       1.228816    43.833053   \n",
       "14         CatBoost_BAG_L1 -232.790461       0.095864   812.608263   \n",
       "15   KNeighborsUnif_BAG_L1 -274.850015       0.801221     0.043521   \n",
       "16   KNeighborsDist_BAG_L1 -275.298709       0.795226     0.059532   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000000           0.329203            3       True   \n",
       "1                 0.628202         128.027010            2       True   \n",
       "2                 0.320865           5.841698            2       True   \n",
       "3                 0.001001           0.238128            2       True   \n",
       "4                 0.054006          15.443790            2       True   \n",
       "5                80.196621          70.830802            1       True   \n",
       "6                 0.168068           5.657542            2       True   \n",
       "7                 0.769310          61.636452            2       True   \n",
       "8                 0.117600           4.204460            2       True   \n",
       "9                 0.396145          13.916003            2       True   \n",
       "10                1.422317          13.967217            2       True   \n",
       "11               90.380913          65.549193            1       True   \n",
       "12                1.289760          68.767458            2       True   \n",
       "13                1.228816          43.833053            1       True   \n",
       "14                0.095864         812.608263            1       True   \n",
       "15                0.801221           0.043521            1       True   \n",
       "16                0.795226           0.059532            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          17  \n",
       "1          15  \n",
       "2           8  \n",
       "3           7  \n",
       "4          11  \n",
       "5           4  \n",
       "6          14  \n",
       "7          13  \n",
       "8           9  \n",
       "9          16  \n",
       "10         12  \n",
       "11          3  \n",
       "12         10  \n",
       "13          5  \n",
       "14          6  \n",
       "15          1  \n",
       "16          2  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_a.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-27.228804</td>\n",
       "      <td>68.250001</td>\n",
       "      <td>122.967029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309280</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-27.553844</td>\n",
       "      <td>199.093395</td>\n",
       "      <td>1046.030706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259099</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-27.672920</td>\n",
       "      <td>197.249926</td>\n",
       "      <td>941.266932</td>\n",
       "      <td>0.293107</td>\n",
       "      <td>5.819569</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-28.034938</td>\n",
       "      <td>197.124955</td>\n",
       "      <td>943.987183</td>\n",
       "      <td>0.168136</td>\n",
       "      <td>8.539820</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-28.050321</td>\n",
       "      <td>197.059256</td>\n",
       "      <td>939.219580</td>\n",
       "      <td>0.102437</td>\n",
       "      <td>3.772217</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-28.074649</td>\n",
       "      <td>197.731210</td>\n",
       "      <td>985.959046</td>\n",
       "      <td>0.774390</td>\n",
       "      <td>50.511683</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-28.090788</td>\n",
       "      <td>197.010667</td>\n",
       "      <td>953.899405</td>\n",
       "      <td>0.053848</td>\n",
       "      <td>18.452042</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-28.093414</td>\n",
       "      <td>198.025898</td>\n",
       "      <td>989.440355</td>\n",
       "      <td>1.069079</td>\n",
       "      <td>53.992992</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-28.161444</td>\n",
       "      <td>66.580985</td>\n",
       "      <td>67.869242</td>\n",
       "      <td>66.580985</td>\n",
       "      <td>67.869242</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-28.231372</td>\n",
       "      <td>198.047545</td>\n",
       "      <td>944.162179</td>\n",
       "      <td>1.090725</td>\n",
       "      <td>8.714816</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-28.509137</td>\n",
       "      <td>197.313621</td>\n",
       "      <td>951.243641</td>\n",
       "      <td>0.356802</td>\n",
       "      <td>15.796278</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-28.709390</td>\n",
       "      <td>0.992985</td>\n",
       "      <td>7.135544</td>\n",
       "      <td>0.992985</td>\n",
       "      <td>7.135544</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-29.234571</td>\n",
       "      <td>197.545380</td>\n",
       "      <td>1031.984873</td>\n",
       "      <td>0.588560</td>\n",
       "      <td>96.537510</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-29.270889</td>\n",
       "      <td>0.955810</td>\n",
       "      <td>36.106755</td>\n",
       "      <td>0.955810</td>\n",
       "      <td>36.106755</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-29.458866</td>\n",
       "      <td>61.493466</td>\n",
       "      <td>169.883634</td>\n",
       "      <td>61.493466</td>\n",
       "      <td>169.883634</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-30.509085</td>\n",
       "      <td>64.343964</td>\n",
       "      <td>83.847716</td>\n",
       "      <td>64.343964</td>\n",
       "      <td>83.847716</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-32.263773</td>\n",
       "      <td>0.071537</td>\n",
       "      <td>503.025290</td>\n",
       "      <td>0.071537</td>\n",
       "      <td>503.025290</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-34.390947</td>\n",
       "      <td>0.676030</td>\n",
       "      <td>47.652962</td>\n",
       "      <td>0.676030</td>\n",
       "      <td>47.652962</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-34.594466</td>\n",
       "      <td>0.431606</td>\n",
       "      <td>19.832701</td>\n",
       "      <td>0.431606</td>\n",
       "      <td>19.832701</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-46.557729</td>\n",
       "      <td>0.717739</td>\n",
       "      <td>0.040513</td>\n",
       "      <td>0.717739</td>\n",
       "      <td>0.040513</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-47.018404</td>\n",
       "      <td>0.692698</td>\n",
       "      <td>0.053005</td>\n",
       "      <td>0.692698</td>\n",
       "      <td>0.053005</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_val  pred_time_val     fit_time  \\\n",
       "0      WeightedEnsemble_L2 -27.228804      68.250001   122.967029   \n",
       "1      WeightedEnsemble_L3 -27.553844     199.093395  1046.030706   \n",
       "2        LightGBMXT_BAG_L2 -27.672920     197.249926   941.266932   \n",
       "3           XGBoost_BAG_L2 -28.034938     197.124955   943.987183   \n",
       "4          LightGBM_BAG_L2 -28.050321     197.059256   939.219580   \n",
       "5   NeuralNetFastAI_BAG_L2 -28.074649     197.731210   985.959046   \n",
       "6          CatBoost_BAG_L2 -28.090788     197.010667   953.899405   \n",
       "7   RandomForestMSE_BAG_L2 -28.093414     198.025898   989.440355   \n",
       "8        LightGBMXT_BAG_L1 -28.161444      66.580985    67.869242   \n",
       "9     ExtraTreesMSE_BAG_L2 -28.231372     198.047545   944.162179   \n",
       "10    LightGBMLarge_BAG_L2 -28.509137     197.313621   951.243641   \n",
       "11    ExtraTreesMSE_BAG_L1 -28.709390       0.992985     7.135544   \n",
       "12   NeuralNetTorch_BAG_L2 -29.234571     197.545380  1031.984873   \n",
       "13  RandomForestMSE_BAG_L1 -29.270889       0.955810    36.106755   \n",
       "14          XGBoost_BAG_L1 -29.458866      61.493466   169.883634   \n",
       "15         LightGBM_BAG_L1 -30.509085      64.343964    83.847716   \n",
       "16         CatBoost_BAG_L1 -32.263773       0.071537   503.025290   \n",
       "17  NeuralNetFastAI_BAG_L1 -34.390947       0.676030    47.652962   \n",
       "18   NeuralNetTorch_BAG_L1 -34.594466       0.431606    19.832701   \n",
       "19   KNeighborsUnif_BAG_L1 -46.557729       0.717739     0.040513   \n",
       "20   KNeighborsDist_BAG_L1 -47.018404       0.692698     0.053005   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000000           0.309280            2       True   \n",
       "1                 0.000000           0.259099            3       True   \n",
       "2                 0.293107           5.819569            2       True   \n",
       "3                 0.168136           8.539820            2       True   \n",
       "4                 0.102437           3.772217            2       True   \n",
       "5                 0.774390          50.511683            2       True   \n",
       "6                 0.053848          18.452042            2       True   \n",
       "7                 1.069079          53.992992            2       True   \n",
       "8                66.580985          67.869242            1       True   \n",
       "9                 1.090725           8.714816            2       True   \n",
       "10                0.356802          15.796278            2       True   \n",
       "11                0.992985           7.135544            1       True   \n",
       "12                0.588560          96.537510            2       True   \n",
       "13                0.955810          36.106755            1       True   \n",
       "14               61.493466         169.883634            1       True   \n",
       "15               64.343964          83.847716            1       True   \n",
       "16                0.071537         503.025290            1       True   \n",
       "17                0.676030          47.652962            1       True   \n",
       "18                0.431606          19.832701            1       True   \n",
       "19                0.717739           0.040513            1       True   \n",
       "20                0.692698           0.053005            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1          21  \n",
       "2          12  \n",
       "3          18  \n",
       "4          13  \n",
       "5          17  \n",
       "6          15  \n",
       "7          14  \n",
       "8           3  \n",
       "9          16  \n",
       "10         20  \n",
       "11          7  \n",
       "12         19  \n",
       "13          5  \n",
       "14          9  \n",
       "15          4  \n",
       "16          6  \n",
       "17          8  \n",
       "18         10  \n",
       "19          1  \n",
       "20          2  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_b.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-33.472780</td>\n",
       "      <td>109.628170</td>\n",
       "      <td>324.913947</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.307574</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-35.054357</td>\n",
       "      <td>0.452867</td>\n",
       "      <td>74.048636</td>\n",
       "      <td>0.452867</td>\n",
       "      <td>74.048636</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-36.204462</td>\n",
       "      <td>155.216634</td>\n",
       "      <td>991.370745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-36.204462</td>\n",
       "      <td>155.216634</td>\n",
       "      <td>991.111705</td>\n",
       "      <td>0.410168</td>\n",
       "      <td>59.868227</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-37.779710</td>\n",
       "      <td>155.406234</td>\n",
       "      <td>978.494639</td>\n",
       "      <td>0.599767</td>\n",
       "      <td>47.251161</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-37.958021</td>\n",
       "      <td>154.849001</td>\n",
       "      <td>951.434585</td>\n",
       "      <td>0.042534</td>\n",
       "      <td>20.191107</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-38.565512</td>\n",
       "      <td>154.930502</td>\n",
       "      <td>938.236235</td>\n",
       "      <td>0.124036</td>\n",
       "      <td>6.992757</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-39.309482</td>\n",
       "      <td>154.907189</td>\n",
       "      <td>935.822145</td>\n",
       "      <td>0.100723</td>\n",
       "      <td>4.578667</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-39.694971</td>\n",
       "      <td>42.065310</td>\n",
       "      <td>187.682290</td>\n",
       "      <td>42.065310</td>\n",
       "      <td>187.682290</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-39.721547</td>\n",
       "      <td>155.906317</td>\n",
       "      <td>938.652058</td>\n",
       "      <td>1.099851</td>\n",
       "      <td>7.408581</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-40.002880</td>\n",
       "      <td>155.714576</td>\n",
       "      <td>977.942944</td>\n",
       "      <td>0.908109</td>\n",
       "      <td>46.699466</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-40.055684</td>\n",
       "      <td>155.059036</td>\n",
       "      <td>945.160835</td>\n",
       "      <td>0.252569</td>\n",
       "      <td>13.917357</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-40.280539</td>\n",
       "      <td>155.018016</td>\n",
       "      <td>937.464556</td>\n",
       "      <td>0.211549</td>\n",
       "      <td>6.221078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-40.418709</td>\n",
       "      <td>66.246153</td>\n",
       "      <td>62.774212</td>\n",
       "      <td>66.246153</td>\n",
       "      <td>62.774212</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-40.815937</td>\n",
       "      <td>43.075757</td>\n",
       "      <td>65.835793</td>\n",
       "      <td>43.075757</td>\n",
       "      <td>65.835793</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-41.052894</td>\n",
       "      <td>0.803160</td>\n",
       "      <td>26.540200</td>\n",
       "      <td>0.803160</td>\n",
       "      <td>26.540200</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-41.202092</td>\n",
       "      <td>0.087792</td>\n",
       "      <td>472.148924</td>\n",
       "      <td>0.087792</td>\n",
       "      <td>472.148924</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-41.756788</td>\n",
       "      <td>0.730597</td>\n",
       "      <td>4.623647</td>\n",
       "      <td>0.730597</td>\n",
       "      <td>4.623647</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-42.888769</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.052127</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.052127</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-43.023782</td>\n",
       "      <td>0.420195</td>\n",
       "      <td>0.049108</td>\n",
       "      <td>0.420195</td>\n",
       "      <td>0.049108</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-45.805184</td>\n",
       "      <td>0.481991</td>\n",
       "      <td>37.488541</td>\n",
       "      <td>0.481991</td>\n",
       "      <td>37.488541</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_val  pred_time_val    fit_time  \\\n",
       "0      WeightedEnsemble_L2 -33.472780     109.628170  324.913947   \n",
       "1    NeuralNetTorch_BAG_L1 -35.054357       0.452867   74.048636   \n",
       "2      WeightedEnsemble_L3 -36.204462     155.216634  991.370745   \n",
       "3    NeuralNetTorch_BAG_L2 -36.204462     155.216634  991.111705   \n",
       "4   NeuralNetFastAI_BAG_L2 -37.779710     155.406234  978.494639   \n",
       "5          CatBoost_BAG_L2 -37.958021     154.849001  951.434585   \n",
       "6           XGBoost_BAG_L2 -38.565512     154.930502  938.236235   \n",
       "7          LightGBM_BAG_L2 -39.309482     154.907189  935.822145   \n",
       "8           XGBoost_BAG_L1 -39.694971      42.065310  187.682290   \n",
       "9     ExtraTreesMSE_BAG_L2 -39.721547     155.906317  938.652058   \n",
       "10  RandomForestMSE_BAG_L2 -40.002880     155.714576  977.942944   \n",
       "11    LightGBMLarge_BAG_L2 -40.055684     155.059036  945.160835   \n",
       "12       LightGBMXT_BAG_L2 -40.280539     155.018016  937.464556   \n",
       "13       LightGBMXT_BAG_L1 -40.418709      66.246153   62.774212   \n",
       "14         LightGBM_BAG_L1 -40.815937      43.075757   65.835793   \n",
       "15  RandomForestMSE_BAG_L1 -41.052894       0.803160   26.540200   \n",
       "16         CatBoost_BAG_L1 -41.202092       0.087792  472.148924   \n",
       "17    ExtraTreesMSE_BAG_L1 -41.756788       0.730597    4.623647   \n",
       "18   KNeighborsUnif_BAG_L1 -42.888769       0.442646    0.052127   \n",
       "19   KNeighborsDist_BAG_L1 -43.023782       0.420195    0.049108   \n",
       "20  NeuralNetFastAI_BAG_L1 -45.805184       0.481991   37.488541   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.001000           0.307574            2       True   \n",
       "1                 0.452867          74.048636            1       True   \n",
       "2                 0.000000           0.259040            3       True   \n",
       "3                 0.410168          59.868227            2       True   \n",
       "4                 0.599767          47.251161            2       True   \n",
       "5                 0.042534          20.191107            2       True   \n",
       "6                 0.124036           6.992757            2       True   \n",
       "7                 0.100723           4.578667            2       True   \n",
       "8                42.065310         187.682290            1       True   \n",
       "9                 1.099851           7.408581            2       True   \n",
       "10                0.908109          46.699466            2       True   \n",
       "11                0.252569          13.917357            2       True   \n",
       "12                0.211549           6.221078            2       True   \n",
       "13               66.246153          62.774212            1       True   \n",
       "14               43.075757          65.835793            1       True   \n",
       "15                0.803160          26.540200            1       True   \n",
       "16                0.087792         472.148924            1       True   \n",
       "17                0.730597           4.623647            1       True   \n",
       "18                0.442646           0.052127            1       True   \n",
       "19                0.420195           0.049108            1       True   \n",
       "20                0.481991          37.488541            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1          10  \n",
       "2          21  \n",
       "3          19  \n",
       "4          17  \n",
       "5          15  \n",
       "6          18  \n",
       "7          13  \n",
       "8           9  \n",
       "9          16  \n",
       "10         14  \n",
       "11         20  \n",
       "12         12  \n",
       "13          3  \n",
       "14          4  \n",
       "15          5  \n",
       "16          6  \n",
       "17          7  \n",
       "18          1  \n",
       "19          2  \n",
       "20          8  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_c.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_forecast                    0\n",
      "absolute_humidity_2m:gm3        24\n",
      "air_density_2m:kgm3             24\n",
      "ceiling_height_agl:m          6151\n",
      "clear_sky_energy_1h:J            0\n",
      "                              ... \n",
      "diffuse_rad_6h_roll_avg         19\n",
      "direct_rad_x_sun_elevation      24\n",
      "time                             0\n",
      "pv_measurement                   0\n",
      "observed                         0\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = x_train_a_combined.isna().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_forecast                    0\n",
      "absolute_humidity_2m:gm3        24\n",
      "air_density_2m:kgm3             24\n",
      "ceiling_height_agl:m          4229\n",
      "clear_sky_energy_1h:J            0\n",
      "                              ... \n",
      "diffuse_rad_6h_roll_avg         19\n",
      "direct_rad_x_sun_elevation      24\n",
      "time                             0\n",
      "pv_measurement                   0\n",
      "observed                         0\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = x_train_b_combined.isna().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_forecast                    0\n",
      "absolute_humidity_2m:gm3        24\n",
      "air_density_2m:kgm3             24\n",
      "ceiling_height_agl:m          4457\n",
      "clear_sky_energy_1h:J            0\n",
      "                              ... \n",
      "diffuse_rad_6h_roll_avg         19\n",
      "direct_rad_x_sun_elevation      24\n",
      "time                             0\n",
      "pv_measurement                   0\n",
      "observed                         0\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = x_train_c_combined.isna().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor_a.feature_importance(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rows(df, value_column='pv_measurement'):\n",
    "    # Determine the number of rows in the dataframe\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Ensure that the number of rows is a multiple of 4\n",
    "    if n_rows % 4 != 0:\n",
    "        print(f\"Warning: Number of rows ({n_rows}) is not a multiple of 4. Truncating to {n_rows // 4 * 4}.\")\n",
    "        df = df.iloc[:n_rows // 4 * 4]\n",
    "\n",
    "    # Group by each set of four rows and sum the values\n",
    "    grouped_values = df[value_column].groupby(df.index // 4).sum()\n",
    "\n",
    "    # Create a new DataFrame with the summed values\n",
    "    df_aggregated = pd.DataFrame(grouped_values).reset_index(drop=True)\n",
    "\n",
    "    return df_aggregated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.233101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>454.940552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>217.218506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>79.877754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>10.130502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.340277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.387682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pv_measurement\n",
       "0          0.181013\n",
       "1          0.160474\n",
       "2          0.147849\n",
       "3         68.233101\n",
       "4        454.940552\n",
       "..              ...\n",
       "715      217.218506\n",
       "716       79.877754\n",
       "717       10.130502\n",
       "718        0.340277\n",
       "719        0.387682\n",
       "\n",
       "[720 rows x 1 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_a = predictor_a.predict(test_data_a)\n",
    "y_pred_a=pd.DataFrame(y_pred_a,columns=['pv_measurement']) \n",
    "y_pred_a #print the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.495047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.596373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.682201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.277022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.522602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>41.507229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>14.737422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2.852947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.810264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>1.262884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pv_measurement\n",
       "0         -0.495047\n",
       "1         -0.596373\n",
       "2         -0.682201\n",
       "3          5.277022\n",
       "4         48.522602\n",
       "..              ...\n",
       "715       41.507229\n",
       "716       14.737422\n",
       "717        2.852947\n",
       "718        0.810264\n",
       "719        1.262884\n",
       "\n",
       "[720 rows x 1 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_b = predictor_b.predict(test_data_b)\n",
    "y_pred_b=pd.DataFrame(y_pred_b,columns=['pv_measurement'])\n",
    "y_pred_b#print the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.703338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.780682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>23.893417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>9.925955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2.743544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.170082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.164730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pv_measurement\n",
       "0          0.023266\n",
       "1          0.014784\n",
       "2          0.034705\n",
       "3          1.703338\n",
       "4         26.780682\n",
       "..              ...\n",
       "715       23.893417\n",
       "716        9.925955\n",
       "717        2.743544\n",
       "718        0.170082\n",
       "719        0.164730\n",
       "\n",
       "[720 rows x 1 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_c = predictor_c.predict(test_data_c)\n",
    "y_pred_c=pd.DataFrame(y_pred_c,columns=['pv_measurement'])\n",
    "y_pred_c #print the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>23.893417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>9.925955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2.743544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>0.170082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>0.164730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pv_measurement\n",
       "2155       23.893417\n",
       "2156        9.925955\n",
       "2157        2.743544\n",
       "2158        0.170082\n",
       "2159        0.164730"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.concat([y_pred_a,y_pred_b, y_pred_c], ignore_index= True)\n",
    "predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.233101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>454.940552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>23.893417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>9.925955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2.743544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>0.170082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>0.164730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction\n",
       "0       0.181013\n",
       "1       0.160474\n",
       "2       0.147849\n",
       "3      68.233101\n",
       "4     454.940552\n",
       "...          ...\n",
       "2155   23.893417\n",
       "2156    9.925955\n",
       "2157    2.743544\n",
       "2158    0.170082\n",
       "2159    0.164730\n",
       "\n",
       "[2160 rows x 1 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = predictions.rename(columns={'pv_measurement': 'prediction'})\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Convert all negative predictions to 0\n",
    "predictions_df.loc[predictions_df['prediction'] < 0, 'prediction'] = 0\n",
    "\n",
    "# Join the 'id' column from sample_submission with the predictions\n",
    "sample_submission['prediction'] = predictions_df['prediction']\n",
    "\n",
    "# Save to CSV\n",
    "sample_submission.to_csv('autogluon_prediction.csv', index=False)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231101_123447\\\"\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231101_123447\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   701.94 GB / 1022.87 GB (68.6%)\n",
      "Train Data Rows:    5685\n",
      "Train Data Columns: 66\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5241.280000000001, 0.0, 572.8555, 1095.882)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5098.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.39 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\features\\generators\\fillna.py:58: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  X.fillna(self._fillna_feature_map, inplace=True, downcast=False)\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 6): ['elevation:m', 'snow_drift:idx', 'calc_year', 'calc_month', 'calc_day', 'calc_hour']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['cloud_base_agl:m']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['cloud_base_agl:m']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 53 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                        :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['date_forecast']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 50 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                  :  4 | ['forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('int', ['bool'])            :  4 | ['is_day:idx', 'is_in_shadow:idx', 'snow_density:kgm3', 'forecast_year']\n",
      "\t\t('int', ['datetime_as_int']) :  3 | ['date_forecast', 'date_forecast.year', 'date_forecast.dayofweek']\n",
      "\t0.5s = Fit runtime\n",
      "\t59 features in original data used to generate 61 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.62 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.57s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 5116, Val Rows: 569\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 899.43s of the 899.43s of remaining time.\n",
      "\t-213.4187\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 899.4s of the 899.4s of remaining time.\n",
      "\t-172.7758\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 899.36s of the 899.36s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 149.482\n",
      "[2000]\tvalid_set's l1: 144.155\n",
      "[3000]\tvalid_set's l1: 141.946\n",
      "[4000]\tvalid_set's l1: 141.201\n",
      "[5000]\tvalid_set's l1: 140.785\n",
      "[6000]\tvalid_set's l1: 140.63\n",
      "[7000]\tvalid_set's l1: 140.503\n",
      "[8000]\tvalid_set's l1: 140.403\n",
      "[9000]\tvalid_set's l1: 140.364\n",
      "[10000]\tvalid_set's l1: 140.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-140.3307\t = Validation score   (-mean_absolute_error)\n",
      "\t7.74s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 891.12s of the 891.12s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 152.851\n",
      "[2000]\tvalid_set's l1: 152.764\n",
      "[3000]\tvalid_set's l1: 152.646\n",
      "[4000]\tvalid_set's l1: 152.628\n",
      "[5000]\tvalid_set's l1: 152.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-152.6241\t = Validation score   (-mean_absolute_error)\n",
      "\t5.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 885.59s of the 885.59s of remaining time.\n",
      "\t-172.3585\t = Validation score   (-mean_absolute_error)\n",
      "\t7.5s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 877.98s of the 877.98s of remaining time.\n",
      "\t-150.9944\t = Validation score   (-mean_absolute_error)\n",
      "\t159.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 718.18s of the 718.18s of remaining time.\n",
      "\t-176.0766\t = Validation score   (-mean_absolute_error)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 716.5s of the 716.49s of remaining time.\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t-192.7455\t = Validation score   (-mean_absolute_error)\n",
      "\t4.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 711.52s of the 711.52s of remaining time.\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "\t-152.896\t = Validation score   (-mean_absolute_error)\n",
      "\t14.43s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 696.92s of the 696.92s of remaining time.\n",
      "\t-190.3023\t = Validation score   (-mean_absolute_error)\n",
      "\t11.99s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 684.89s of the 684.89s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 155.782\n",
      "[2000]\tvalid_set's l1: 155.773\n",
      "[3000]\tvalid_set's l1: 155.772\n",
      "[4000]\tvalid_set's l1: 155.772\n",
      "[5000]\tvalid_set's l1: 155.772\n",
      "[6000]\tvalid_set's l1: 155.772\n",
      "[7000]\tvalid_set's l1: 155.772\n",
      "[8000]\tvalid_set's l1: 155.772\n",
      "[9000]\tvalid_set's l1: 155.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-155.7719\t = Validation score   (-mean_absolute_error)\n",
      "\t36.25s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 647.49s of remaining time.\n",
      "\t-136.6628\t = Validation score   (-mean_absolute_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 252.83s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231101_123447\\\")\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\features\\generators\\fillna.py:58: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  X.fillna(self._fillna_feature_map, inplace=True, downcast=False)\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231101_123901\\\"\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231101_123901\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   701.39 GB / 1022.87 GB (68.6%)\n",
      "Train Data Rows:    11365\n",
      "Train Data Columns: 66\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5524.2, 0.0, 734.08865, 1222.07646)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5118.1 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.77 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\features\\generators\\fillna.py:58: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  X.fillna(self._fillna_feature_map, inplace=True, downcast=False)\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 6): ['elevation:m', 'snow_drift:idx', 'calc_year', 'calc_month', 'calc_day', 'calc_hour']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 54 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                        :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['date_forecast']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 51 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                  :  4 | ['forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('int', ['bool'])            :  4 | ['is_day:idx', 'is_in_shadow:idx', 'snow_density:kgm3', 'forecast_year']\n",
      "\t\t('int', ['datetime_as_int']) :  3 | ['date_forecast', 'date_forecast.year', 'date_forecast.dayofweek']\n",
      "\t0.4s = Fit runtime\n",
      "\t60 features in original data used to generate 62 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.32 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10228, Val Rows: 1137\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 899.54s of the 899.53s of remaining time.\n",
      "\t-257.728\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 899.48s of the 899.48s of remaining time.\n",
      "\t-210.4882\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 899.4s of the 899.4s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 179.576\n",
      "[2000]\tvalid_set's l1: 173.368\n",
      "[3000]\tvalid_set's l1: 170.839\n",
      "[4000]\tvalid_set's l1: 169.639\n",
      "[5000]\tvalid_set's l1: 168.91\n",
      "[6000]\tvalid_set's l1: 168.256\n",
      "[7000]\tvalid_set's l1: 167.971\n",
      "[8000]\tvalid_set's l1: 167.85\n",
      "[9000]\tvalid_set's l1: 167.648\n",
      "[10000]\tvalid_set's l1: 167.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-167.5588\t = Validation score   (-mean_absolute_error)\n",
      "\t8.49s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 890.34s of the 890.34s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 189.45\n",
      "[2000]\tvalid_set's l1: 186.904\n",
      "[3000]\tvalid_set's l1: 186.168\n",
      "[4000]\tvalid_set's l1: 185.93\n",
      "[5000]\tvalid_set's l1: 185.719\n",
      "[6000]\tvalid_set's l1: 185.641\n",
      "[7000]\tvalid_set's l1: 185.603\n",
      "[8000]\tvalid_set's l1: 185.588\n",
      "[9000]\tvalid_set's l1: 185.581\n",
      "[10000]\tvalid_set's l1: 185.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-185.5745\t = Validation score   (-mean_absolute_error)\n",
      "\t11.01s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 878.75s of the 878.75s of remaining time.\n",
      "\t-210.6871\t = Validation score   (-mean_absolute_error)\n",
      "\t18.33s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 860.21s of the 860.21s of remaining time.\n",
      "\t-182.9797\t = Validation score   (-mean_absolute_error)\n",
      "\t173.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 686.69s of the 686.69s of remaining time.\n",
      "\t-207.0986\t = Validation score   (-mean_absolute_error)\n",
      "\t3.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 682.95s of the 682.95s of remaining time.\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t-214.2926\t = Validation score   (-mean_absolute_error)\n",
      "\t10.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 672.68s of the 672.68s of remaining time.\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "\t-184.963\t = Validation score   (-mean_absolute_error)\n",
      "\t30.14s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 642.17s of the 642.17s of remaining time.\n",
      "\t-185.7579\t = Validation score   (-mean_absolute_error)\n",
      "\t52.36s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 589.76s of the 589.76s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 186.55\n",
      "[2000]\tvalid_set's l1: 186.249\n",
      "[3000]\tvalid_set's l1: 186.224\n",
      "[4000]\tvalid_set's l1: 186.221\n",
      "[5000]\tvalid_set's l1: 186.22\n",
      "[6000]\tvalid_set's l1: 186.22\n",
      "[7000]\tvalid_set's l1: 186.22\n",
      "[8000]\tvalid_set's l1: 186.22\n",
      "[9000]\tvalid_set's l1: 186.22\n",
      "[10000]\tvalid_set's l1: 186.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-186.22\t = Validation score   (-mean_absolute_error)\n",
      "\t41.4s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 546.71s of remaining time.\n",
      "\t-160.5852\t = Validation score   (-mean_absolute_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 353.61s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231101_123901\\\")\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\features\\generators\\fillna.py:58: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  X.fillna(self._fillna_feature_map, inplace=True, downcast=False)\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231101_124457\\\"\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231101_124457\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   700.81 GB / 1022.87 GB (68.5%)\n",
      "Train Data Rows:    17045\n",
      "Train Data Columns: 66\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5596.36, 0.0, 620.05934, 1137.76959)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5404.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.16 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\features\\generators\\fillna.py:58: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  X.fillna(self._fillna_feature_map, inplace=True, downcast=False)\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 6): ['elevation:m', 'snow_drift:idx', 'calc_year', 'calc_month', 'calc_day', 'calc_hour']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 54 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                        :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['date_forecast']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 51 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                  :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('int', ['bool'])            :  3 | ['is_day:idx', 'is_in_shadow:idx', 'snow_density:kgm3']\n",
      "\t\t('int', ['datetime_as_int']) :  2 | ['date_forecast', 'date_forecast.dayofweek']\n",
      "\t0.6s = Fit runtime\n",
      "\t60 features in original data used to generate 61 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.96 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.64s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 15340, Val Rows: 1705\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 899.36s of the 899.35s of remaining time.\n",
      "\t-229.5181\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 899.26s of the 899.26s of remaining time.\n",
      "\t-189.758\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 899.17s of the 899.17s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 149.435\n",
      "[2000]\tvalid_set's l1: 144.272\n",
      "[3000]\tvalid_set's l1: 142.703\n",
      "[4000]\tvalid_set's l1: 141.523\n",
      "[5000]\tvalid_set's l1: 140.803\n",
      "[6000]\tvalid_set's l1: 140.576\n",
      "[7000]\tvalid_set's l1: 140.385\n",
      "[8000]\tvalid_set's l1: 140.209\n",
      "[9000]\tvalid_set's l1: 140.077\n",
      "[10000]\tvalid_set's l1: 140.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-140.0313\t = Validation score   (-mean_absolute_error)\n",
      "\t9.95s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 888.57s of the 888.57s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 156.537\n",
      "[2000]\tvalid_set's l1: 154.833\n",
      "[3000]\tvalid_set's l1: 154.458\n",
      "[4000]\tvalid_set's l1: 154.246\n",
      "[5000]\tvalid_set's l1: 154.178\n",
      "[6000]\tvalid_set's l1: 154.081\n",
      "[7000]\tvalid_set's l1: 154.028\n",
      "[8000]\tvalid_set's l1: 154.002\n",
      "[9000]\tvalid_set's l1: 153.973\n",
      "[10000]\tvalid_set's l1: 153.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-153.969\t = Validation score   (-mean_absolute_error)\n",
      "\t12.38s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 875.56s of the 875.55s of remaining time.\n",
      "\t-178.5998\t = Validation score   (-mean_absolute_error)\n",
      "\t26.8s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 848.49s of the 848.48s of remaining time.\n",
      "\t-154.9543\t = Validation score   (-mean_absolute_error)\n",
      "\t179.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 668.6s of the 668.6s of remaining time.\n",
      "\t-177.5205\t = Validation score   (-mean_absolute_error)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 663.52s of the 663.52s of remaining time.\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t-182.1235\t = Validation score   (-mean_absolute_error)\n",
      "\t15.61s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 647.87s of the 647.87s of remaining time.\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "\t-160.4272\t = Validation score   (-mean_absolute_error)\n",
      "\t39.74s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 607.46s of the 607.46s of remaining time.\n",
      "\t-165.5964\t = Validation score   (-mean_absolute_error)\n",
      "\t63.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 544.12s of the 544.11s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 155.442\n",
      "[2000]\tvalid_set's l1: 154.839\n",
      "[3000]\tvalid_set's l1: 154.783\n",
      "[4000]\tvalid_set's l1: 154.766\n",
      "[5000]\tvalid_set's l1: 154.763\n",
      "[6000]\tvalid_set's l1: 154.762\n",
      "[7000]\tvalid_set's l1: 154.761\n",
      "[8000]\tvalid_set's l1: 154.761\n",
      "[9000]\tvalid_set's l1: 154.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-154.7615\t = Validation score   (-mean_absolute_error)\n",
      "\t41.37s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 501.3s of remaining time.\n",
      "\t-137.8463\t = Validation score   (-mean_absolute_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 399.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231101_124457\\\")\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\features\\generators\\fillna.py:58: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  X.fillna(self._fillna_feature_map, inplace=True, downcast=False)\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:190: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231101_125138\\\"\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231101_125138\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   700.15 GB / 1022.87 GB (68.4%)\n",
      "Train Data Rows:    22725\n",
      "Train Data Columns: 66\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:549: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 644.92118, 1175.60516)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5380.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 13.54 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "c:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\features\\generators\\fillna.py:58: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  X.fillna(self._fillna_feature_map, inplace=True, downcast=False)\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 6): ['elevation:m', 'snow_drift:idx', 'calc_year', 'calc_month', 'calc_day', 'calc_hour']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 54 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                        :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['date_forecast']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 51 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                  :  5 | ['forecast_year', 'forecast_month', 'forecast_day', 'forecast_hour', 'day_of_year']\n",
      "\t\t('int', ['bool'])            :  3 | ['is_day:idx', 'is_in_shadow:idx', 'snow_density:kgm3']\n",
      "\t\t('int', ['datetime_as_int']) :  2 | ['date_forecast', 'date_forecast.dayofweek']\n",
      "\t0.7s = Fit runtime\n",
      "\t60 features in original data used to generate 61 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.61 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.71s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 20452, Val Rows: 2273\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 899.29s of the 899.29s of remaining time.\n",
      "\t-240.036\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 899.17s of the 899.17s of remaining time.\n",
      "\t-196.3339\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 899.04s of the 899.04s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 166.693\n",
      "[2000]\tvalid_set's l1: 157.659\n",
      "[3000]\tvalid_set's l1: 154.758\n",
      "[4000]\tvalid_set's l1: 152.936\n",
      "[5000]\tvalid_set's l1: 152.012\n",
      "[6000]\tvalid_set's l1: 151.61\n",
      "[7000]\tvalid_set's l1: 151.103\n",
      "[8000]\tvalid_set's l1: 150.77\n",
      "[9000]\tvalid_set's l1: 150.456\n",
      "[10000]\tvalid_set's l1: 150.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-150.2422\t = Validation score   (-mean_absolute_error)\n",
      "\t11.24s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 887.11s of the 887.11s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 169.592\n",
      "[2000]\tvalid_set's l1: 165.632\n",
      "[3000]\tvalid_set's l1: 164.666\n",
      "[4000]\tvalid_set's l1: 164.109\n",
      "[5000]\tvalid_set's l1: 163.818\n",
      "[6000]\tvalid_set's l1: 163.624\n",
      "[7000]\tvalid_set's l1: 163.502\n",
      "[8000]\tvalid_set's l1: 163.467\n",
      "[9000]\tvalid_set's l1: 163.414\n",
      "[10000]\tvalid_set's l1: 163.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-163.4101\t = Validation score   (-mean_absolute_error)\n",
      "\t13.89s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 872.52s of the 872.52s of remaining time.\n",
      "\t-192.4784\t = Validation score   (-mean_absolute_error)\n",
      "\t36.77s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 835.42s of the 835.42s of remaining time.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\holwe\\Documents\\1. Skole\\4. høst\\Maskinlæring\\Prosjekt\\data(1)\\MLprosjekt\\data\\autogluon.ipynb Cell 32\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/holwe/Documents/1.%20Skole/4.%20h%C3%B8st/Maskinl%C3%A6ring/Prosjekt/data%281%29/MLprosjekt/data/autogluon.ipynb#X40sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Replace with the name of your target column\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/holwe/Documents/1.%20Skole/4.%20h%C3%B8st/Maskinl%C3%A6ring/Prosjekt/data%281%29/MLprosjekt/data/autogluon.ipynb#X40sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/holwe/Documents/1.%20Skole/4.%20h%C3%B8st/Maskinl%C3%A6ring/Prosjekt/data%281%29/MLprosjekt/data/autogluon.ipynb#X40sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m predictor \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39;49mlabel, eval_metric\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(train_data_combined, time_limit\u001b[39m=\u001b[39;49m \u001b[39m900\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/holwe/Documents/1.%20Skole/4.%20h%C3%B8st/Maskinl%C3%A6ring/Prosjekt/data%281%29/MLprosjekt/data/autogluon.ipynb#X40sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Validate the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/holwe/Documents/1.%20Skole/4.%20h%C3%B8st/Maskinl%C3%A6ring/Prosjekt/data%281%29/MLprosjekt/data/autogluon.ipynb#X40sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m predictions \u001b[39m=\u001b[39m predictor\u001b[39m.\u001b[39mpredict(x_valid_fold)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39mgargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgkwargs)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[0;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[0;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[0;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[0;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[0;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[0;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[0;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[0;32m   1002\u001b[0m )\n\u001b[0;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[0;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m   1013\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39mfit(\n\u001b[0;32m    158\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    159\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39mholdout_frac,\n\u001b[0;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39mtime_limit_trainer,\n\u001b[0;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    167\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    168\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_fit_kwargs,\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[0;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[0;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2371\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_rows_val \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_val)\n\u001b[0;32m   2370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_cols_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m-> 2371\u001b[0m model_names_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_multi_levels(\n\u001b[0;32m   2372\u001b[0m     X,\n\u001b[0;32m   2373\u001b[0m     y,\n\u001b[0;32m   2374\u001b[0m     hyperparameters\u001b[39m=\u001b[39mhyperparameters,\n\u001b[0;32m   2375\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m   2376\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m   2377\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m   2378\u001b[0m     level_start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   2379\u001b[0m     level_end\u001b[39m=\u001b[39mnum_stack_levels \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m   2380\u001b[0m     time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2381\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2382\u001b[0m )\n\u001b[0;32m   2383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_names()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2384\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAutoGluon did not successfully train any models\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:395\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    393\u001b[0m         core_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_core)\n\u001b[0;32m    394\u001b[0m         aux_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_aux)\n\u001b[1;32m--> 395\u001b[0m     base_model_names, aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level(\n\u001b[0;32m    396\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    397\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    398\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    399\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    400\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    401\u001b[0m         models\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    402\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    403\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[0;32m    404\u001b[0m         core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs_level,\n\u001b[0;32m    405\u001b[0m         aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs_level,\n\u001b[0;32m    406\u001b[0m         name_suffix\u001b[39m=\u001b[39;49mname_suffix,\n\u001b[0;32m    407\u001b[0m         infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    408\u001b[0m         infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    410\u001b[0m     model_names_fit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m base_model_names \u001b[39m+\u001b[39m aux_models\n\u001b[0;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_best \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(model_names_fit) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:539\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    537\u001b[0m     core_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[0;32m    538\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[1;32m--> 539\u001b[0m core_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_core(\n\u001b[0;32m    540\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    541\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    542\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    543\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    544\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    545\u001b[0m     models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m    546\u001b[0m     level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m    547\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m    548\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    549\u001b[0m     base_model_names\u001b[39m=\u001b[39mbase_model_names,\n\u001b[0;32m    550\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcore_kwargs,\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    553\u001b[0m \u001b[39mif\u001b[39;00m X_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    554\u001b[0m     aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_aux(\n\u001b[0;32m    555\u001b[0m         X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, base_model_names\u001b[39m=\u001b[39mcore_models, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, infer_limit\u001b[39m=\u001b[39minfer_limit, infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maux_kwargs\n\u001b[0;32m    556\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:673\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m    672\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi(\n\u001b[0;32m    674\u001b[0m     X\u001b[39m=\u001b[39mX_init,\n\u001b[0;32m    675\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    676\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    677\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    678\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    679\u001b[0m     models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m    680\u001b[0m     level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m    681\u001b[0m     stack_name\u001b[39m=\u001b[39mstack_name,\n\u001b[0;32m    682\u001b[0m     compute_score\u001b[39m=\u001b[39mcompute_score,\n\u001b[0;32m    683\u001b[0m     fit_kwargs\u001b[39m=\u001b[39mfit_kwargs,\n\u001b[0;32m    684\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    685\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2321\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2320\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m-> 2321\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi_initial(\n\u001b[0;32m   2322\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   2323\u001b[0m         y\u001b[39m=\u001b[39my,\n\u001b[0;32m   2324\u001b[0m         models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m   2325\u001b[0m         k_fold\u001b[39m=\u001b[39mk_fold,\n\u001b[0;32m   2326\u001b[0m         n_repeats\u001b[39m=\u001b[39mn_repeats_initial,\n\u001b[0;32m   2327\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m   2328\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39mfeature_prune_kwargs,\n\u001b[0;32m   2329\u001b[0m         time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2330\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[0;32m   2333\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2160\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m bagged:\n\u001b[0;32m   2159\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 2160\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_multi_fold(\n\u001b[0;32m   2161\u001b[0m         models\u001b[39m=\u001b[39mmodels,\n\u001b[0;32m   2162\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m   2163\u001b[0m         time_limit\u001b[39m=\u001b[39mtime_limit,\n\u001b[0;32m   2164\u001b[0m         time_split\u001b[39m=\u001b[39mtime_split,\n\u001b[0;32m   2165\u001b[0m         time_ratio\u001b[39m=\u001b[39mtime_ratio,\n\u001b[0;32m   2166\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args,\n\u001b[0;32m   2167\u001b[0m     )\n\u001b[0;32m   2168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2169\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2278\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2276\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   2277\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[1;32m-> 2278\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single_full(\n\u001b[0;32m   2279\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   2280\u001b[0m )\n\u001b[0;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m   2283\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2051\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[0;32m   2047\u001b[0m         bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[0;32m   2048\u001b[0m             k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[0;32m   2049\u001b[0m         )\n\u001b[0;32m   2050\u001b[0m         model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[1;32m-> 2051\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_and_save(\n\u001b[0;32m   2052\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   2053\u001b[0m         y\u001b[39m=\u001b[39my,\n\u001b[0;32m   2054\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   2055\u001b[0m         X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m   2056\u001b[0m         y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m   2057\u001b[0m         X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m   2058\u001b[0m         stack_name\u001b[39m=\u001b[39mstack_name,\n\u001b[0;32m   2059\u001b[0m         level\u001b[39m=\u001b[39mlevel,\n\u001b[0;32m   2060\u001b[0m         compute_score\u001b[39m=\u001b[39mcompute_score,\n\u001b[0;32m   2061\u001b[0m         total_resources\u001b[39m=\u001b[39mtotal_resources,\n\u001b[0;32m   2062\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs,\n\u001b[0;32m   2063\u001b[0m     )\n\u001b[0;32m   2064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m   2065\u001b[0m \u001b[39mreturn\u001b[39;00m model_names_trained\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1733\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[1;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1731\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1732\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1733\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X, y, model, X_val, y_val, total_resources\u001b[39m=\u001b[39mtotal_resources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1735\u001b[0m fit_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_evaluation:\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1684\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[1;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_single\u001b[39m(\u001b[39mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, total_resources\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AbstractModel:\n\u001b[0;32m   1680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[39m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[0;32m   1682\u001b[0m \u001b[39m    Returns trained model object.\u001b[39;00m\n\u001b[0;32m   1683\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1684\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, X_val\u001b[39m=\u001b[39mX_val, y_val\u001b[39m=\u001b[39my_val, total_resources\u001b[39m=\u001b[39mtotal_resources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1685\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\autogluon\\tabular\\models\\catboost\\catboost_model.py:211\u001b[0m, in \u001b[0;36mCatBoostModel._fit\u001b[1;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     fit_final_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_best_model\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_final_kwargs)\n\u001b[0;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams_trained[\u001b[39m\"\u001b[39m\u001b[39miterations\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtree_count_\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\catboost\\core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\catboost\\core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2320\u001b[0m         train_pool,\n\u001b[0;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2322\u001b[0m         params,\n\u001b[0;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2325\u001b[0m     )\n\u001b[0;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\holwe\\miniconda3\\lib\\site-packages\\catboost\\core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "performance_metrics = []\n",
    "\n",
    "\n",
    "for train_idx, test_idx in tscv.split(x_train_a):\n",
    "    x_train_fold = x_train_a.iloc[train_idx]\n",
    "    y_train_fold = y_train_a.iloc[train_idx]\n",
    "    x_valid_fold = x_train_a.iloc[test_idx]\n",
    "    y_valid_fold = y_train_a.iloc[test_idx]\n",
    "\n",
    "    # Merge the data on the date\n",
    "    train_data_combined = x_train_fold.merge(y_train_fold, left_on='date_forecast', right_on='time', how='left')\n",
    "    valid_data_combined = x_valid_fold.merge(y_valid_fold, left_on='date_forecast', right_on='time', how='left')\n",
    "\n",
    "    # Drop redundant columns\n",
    "    train_data_combined.drop(columns=['time'], inplace=True)\n",
    "    valid_data_combined.drop(columns=['time'], inplace=True)\n",
    "\n",
    "\n",
    "    # Define the name of the target column\n",
    "    label = 'pv_measurement'  # Replace with the name of your target column\n",
    "    \n",
    "    # Train the model\n",
    "    predictor = TabularPredictor(label=label, eval_metric= 'mean_absolute_error').fit(train_data_combined,tuning_data= valid_data_combined, time_limit= 900)\n",
    "    \n",
    "    # Validate the model\n",
    "    performance = predictor.evaluate(valid_data_combined)\n",
    "    \n",
    "    # Evaluate the performance (you can use any metric of your choice)\n",
    "\n",
    "    performance_metrics.append(performa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231026_153540\\\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 3&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 # Begin with A</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 predictor = TabularPredictor(label=<span style=\"color: #808000; text-decoration-color: #808000\">'pv_measurement'</span>).fit(train_data=x_train, tuning_data     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>predictions = predictor.predict()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Assuming x_test is your test data</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'x_train'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 3>\u001b[0m:\u001b[94m3\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[2m# Begin with A\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 predictor = TabularPredictor(label=\u001b[33m'\u001b[0m\u001b[33mpv_measurement\u001b[0m\u001b[33m'\u001b[0m).fit(train_data=x_train, tuning_data     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0mpredictions = predictor.predict()  \u001b[2m# Assuming x_test is your test data\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'x_train'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
