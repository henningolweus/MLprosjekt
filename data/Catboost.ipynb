{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c788fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6686ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a = pd.read_csv('cleaned_data/A/x_train_a.csv')\n",
    "x_train_b = pd.read_csv('cleaned_data/B/x_train_b.csv')\n",
    "x_train_c = pd.read_csv('cleaned_data/C/x_train_c.csv')\n",
    "\n",
    "x_test_a = pd.read_csv('cleaned_data/A/x_test_a.csv')\n",
    "x_test_b = pd.read_csv('cleaned_data/B/x_test_b.csv')\n",
    "x_test_c = pd.read_csv('cleaned_data/C/x_test_c.csv')\n",
    "\n",
    "train_a = pd.read_csv('cleaned_data/A/train_a.csv')\n",
    "train_b = pd.read_csv('cleaned_data/B/train_b.csv')\n",
    "train_c = pd.read_csv('cleaned_data/C/train_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15168876-f69f-4967-aebe-25abf4551bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx_train_a = pd.read_csv('cleaned_data_Henning/A/x_train_a.csv')\\nx_train_b = pd.read_csv('cleaned_data_Henning/B/x_train_b.csv')\\nx_train_c = pd.read_csv('cleaned_data_Henning/C/x_train_c.csv')\\n\\nx_test_a = pd.read_csv('cleaned_data_Henning/A/x_test_a.csv')\\nx_test_b = pd.read_csv('cleaned_data_Henning/B/x_test_b.csv')\\nx_test_c = pd.read_csv('cleaned_data_Henning/C/x_test_c.csv')\\n\\ntrain_a = pd.read_csv('cleaned_data_Henning/A/train_a.csv')\\ntrain_b = pd.read_csv('cleaned_data_Henning/B/train_b.csv')\\ntrain_c = pd.read_csv('cleaned_data_Henning/C/train_c.csv')\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x_train_a = pd.read_csv('cleaned_data_Henning/A/x_train_a.csv')\n",
    "x_train_b = pd.read_csv('cleaned_data_Henning/B/x_train_b.csv')\n",
    "x_train_c = pd.read_csv('cleaned_data_Henning/C/x_train_c.csv')\n",
    "\n",
    "x_test_a = pd.read_csv('cleaned_data_Henning/A/x_test_a.csv')\n",
    "x_test_b = pd.read_csv('cleaned_data_Henning/B/x_test_b.csv')\n",
    "x_test_c = pd.read_csv('cleaned_data_Henning/C/x_test_c.csv')\n",
    "\n",
    "train_a = pd.read_csv('cleaned_data_Henning/A/train_a.csv')\n",
    "train_b = pd.read_csv('cleaned_data_Henning/B/train_b.csv')\n",
    "train_c = pd.read_csv('cleaned_data_Henning/C/train_c.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad434433-3ded-4a2f-b51a-44977b1004ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_train_a = add_week_feat(x_train_a)\\nx_train_b = add_week_feat(x_train_b)\\nx_train_c = add_week_feat(x_train_c)\\n\\nx_test_a = add_week_feat(x_test_a)\\nx_test_b = add_week_feat(x_test_b)\\nx_test_c = add_week_feat(x_test_c)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_week_feat(df):\n",
    "\n",
    "    df['date_forecast'] = pd.to_datetime(df['date_forecast'])\n",
    "    \n",
    "    # Extract week number\n",
    "    df['week'] = df['date_forecast'].dt.isocalendar().week\n",
    "\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "x_train_a = add_week_feat(x_train_a)\n",
    "x_train_b = add_week_feat(x_train_b)\n",
    "x_train_c = add_week_feat(x_train_c)\n",
    "\n",
    "x_test_a = add_week_feat(x_test_a)\n",
    "x_test_b = add_week_feat(x_test_b)\n",
    "x_test_c = add_week_feat(x_test_c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d43bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a['time'] = pd.to_datetime(train_a['time'])\n",
    "train_b['time'] = pd.to_datetime(train_b['time'])\n",
    "train_c['time'] = pd.to_datetime(train_c['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd9be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a = x_test_a.drop(columns = ['date_forecast'])\n",
    "x_test_b = x_test_b.drop(columns = ['date_forecast'])\n",
    "x_test_c = x_test_c.drop(columns = ['date_forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34e17787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in X_train that has timestamp that does not exist in train_loc, and visa_verca\n",
    "#e.g missing solar power measurements from 2022-10-21 01:00 - 2022-10-28 21:00\n",
    "def align_X_y(x_train,y_train, x_date_column='date_forecast', y_date_column='time'):\n",
    "    \"\"\"\n",
    "    Aligns two dataframes based on the 'date_forecast' column of X and the 'time' column of y,\n",
    "    ensuring that only rows with matching time values are retained.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): The first dataframe with time in the 'date_forecast'\n",
    "    - y (pd.DataFrame): The second dataframe with time in the 'time' column.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the aligned dataframes.\n",
    "    \"\"\"\n",
    "    # Convert date columns to datetime format for easier comparison\n",
    "    x_train[x_date_column] = pd.to_datetime(x_train[x_date_column])\n",
    "    y_train[y_date_column] = pd.to_datetime(y_train[y_date_column])\n",
    "    \n",
    "    # Find common dates\n",
    "    common_dates = x_train[x_date_column][x_train[x_date_column].isin(y_train[y_date_column])]\n",
    "    \n",
    "    # Filter both datasets based on common dates\n",
    "    x_train_synced = x_train[x_train[x_date_column].isin(common_dates)]\n",
    "    y_train_synced = y_train[y_train[y_date_column].isin(common_dates)]\n",
    "    \n",
    "    return x_train_synced, y_train_synced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1a15d",
   "metadata": {},
   "source": [
    "# Analysis of Target variable  - Looking at PV_measurement\n",
    "1. Handle constant measurments over longer periods of time. Likely caused by sensor malfunction, data logging issues, or other external factors.\n",
    "    - Handeled by removing all constant values lasting more than 24 hours \n",
    "2. Add cyclical features \n",
    "2. Handle longer periods of missing data:\n",
    "    - Remove (currently tested)\n",
    "    - Interpolate \n",
    "    - Copy from previous year\n",
    "    - Copy solar production at missing time from another location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89446f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Handle constant PV measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5db23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series plot of PV_measurement \n",
    "\n",
    "def solar_prod_plot(y_train, resolution='year', chunks=5):\n",
    "    df = y_train.copy()\n",
    "    \n",
    "    # Determine the plotting resolution based on the 'resolution' argument\n",
    "    # Chunks = number of year/months/days in each plot\n",
    "    if resolution == 'year':\n",
    "        unique_values = df['time'].dt.year.unique()\n",
    "        label = 'Year'\n",
    "    elif resolution == 'month':\n",
    "        df['year_month'] = df['time'].dt.to_period('M')\n",
    "        unique_values = df['year_month'].unique()\n",
    "        label = 'Month'\n",
    "    elif resolution == 'week':\n",
    "        df['year_week'] = df['time'].dt.to_period('W')\n",
    "        unique_values = df['year_week'].unique()\n",
    "        label = 'Week'\n",
    "    elif resolution == 'day':\n",
    "        df['date'] = df['time'].dt.date\n",
    "        unique_values = df['date'].unique()\n",
    "        label = 'Day'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid resolution. Choose from 'year', 'month', 'week', or 'day'.\")\n",
    "    \n",
    "    # Loop over the unique values in chunks\n",
    "    for i in range(0, len(unique_values), chunks):\n",
    "        subset_values = unique_values[i:i+chunks]\n",
    "        \n",
    "        if resolution == 'year':\n",
    "            subset_df = df[df['time'].dt.year.isin(subset_values)]\n",
    "        elif resolution == 'month':\n",
    "            subset_df = df[df['year_month'].isin(subset_values)]\n",
    "        elif resolution == 'week':\n",
    "            subset_df = df[df['year_week'].isin(subset_values)]\n",
    "        elif resolution == 'day':\n",
    "            subset_df = df[df['date'].isin(subset_values)]\n",
    "        \n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(subset_df['time'], subset_df['pv_measurement'])\n",
    "\n",
    "        title = f\"Solar Power Production for {label}: {subset_values[0]}\"\n",
    "        if len(subset_values) > 1:\n",
    "            title += f\" to {subset_values[-1]}\"\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"PV Measurement\")\n",
    "        plt.show()\n",
    "\n",
    "def remove_constant_intervals(y_train, low_thresh, upp_thresh):\n",
    "    \"\"\"\n",
    "    Identify and remove intervals of constant PV readings that exceed a specified duration. \n",
    "    Constant readings may indicate sensor malfunctions or data logging issues.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_train : pd.DataFrame\n",
    "        Dataframe containing the time-series data of solar power production.\n",
    "    threshold : int\n",
    "        The minimum duration required for an interval to be considered for removal.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The input dataframe with intervals of constant readings (exceeding the duration threshold) removed.\n",
    "    \"\"\"\n",
    "    df = y_train.copy()\n",
    "    \n",
    "    # Calculate the difference in production values\n",
    "    df['diff'] = df['pv_measurement'].diff()\n",
    "\n",
    "    # Identify where the difference is zero\n",
    "    df['zero_diff'] = df['diff'].abs() < 1e-5\n",
    "\n",
    "    # Identify groups of consecutive zero differences\n",
    "    df['group'] = (df['zero_diff'] != df['zero_diff'].shift()).cumsum()\n",
    "\n",
    "    # Filter out only the groups with consecutive zero differences\n",
    "    constant_intervals = df[df['zero_diff']].groupby('group').agg(start=('time', 'min'), \n",
    "                                                                  end=('time', 'max'),\n",
    "                                                                  duration=('time', 'size'))\n",
    "    \n",
    "    # Filter intervals based on the threshold\n",
    "    interval_df_thresh = constant_intervals[(constant_intervals['duration'] > low_thresh) & (constant_intervals['duration'] <upp_thresh)]\n",
    "    \n",
    "    # Remove rows from the main dataframe that fall within these intervals\n",
    "    for _, row in interval_df_thresh.iterrows():\n",
    "        start_time, end_time = row['start'], row['end']\n",
    "        df = df[(df['time'] < start_time) | (df['time'] > end_time)]\n",
    "    \n",
    "    # Drop the added columns used for calculations\n",
    "    df.drop(columns=['diff', 'zero_diff', 'group'], inplace=True)\n",
    "    \n",
    "    return df, constant_intervals\n",
    "\n",
    "\n",
    "def get_time_interval(df, start_time = '2020-08-01 00:00:00', end_time = '2021-01-01 00:00:00'):\n",
    "    # Filter rows based on the time period\n",
    "    filtered_df = df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e1af31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed all constant values with duration > 24 hours\n",
    "\n",
    "train_a, const_interval_a = remove_constant_intervals(train_a,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_a, train_a = align_X_y(x_train_a, train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a90e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2020-01-04 15:00:00</td>\n",
       "      <td>2020-01-06 08:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "434   2020-01-04 15:00:00 2020-01-06 08:00:00        42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed_a = np.sum(const_interval_a[const_interval_a['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed_a}')\n",
    "const_interval_a[const_interval_a['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d4bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in groups of constant values, where duration of constant measurements is > 1 day (24 hours)\n",
    "train_b, const_interval_b = remove_constant_intervals(train_b,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_b, train_b = align_X_y(x_train_b, train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd0cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 6865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-01-14 15:00:00</td>\n",
       "      <td>2019-01-18 11:00:00</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-01-19 13:00:00</td>\n",
       "      <td>2019-01-26 08:00:00</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-01-27 11:00:00</td>\n",
       "      <td>2019-01-28 13:00:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2019-02-10 16:00:00</td>\n",
       "      <td>2019-02-13 07:00:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-03-23 18:00:00</td>\n",
       "      <td>2019-03-26 06:00:00</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2019-05-31 08:00:00</td>\n",
       "      <td>2019-06-03 12:00:00</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2019-10-28 14:00:00</td>\n",
       "      <td>2019-10-30 22:00:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2019-12-01 13:00:00</td>\n",
       "      <td>2019-12-04 08:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>2019-12-07 14:00:00</td>\n",
       "      <td>2019-12-11 08:00:00</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2019-12-18 14:00:00</td>\n",
       "      <td>2019-12-20 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>2019-12-25 14:00:00</td>\n",
       "      <td>2019-12-30 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2020-01-02 14:00:00</td>\n",
       "      <td>2020-01-04 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2020-01-04 14:00:00</td>\n",
       "      <td>2020-01-06 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2020-01-24 12:00:00</td>\n",
       "      <td>2020-01-26 08:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2020-02-05 14:00:00</td>\n",
       "      <td>2020-02-07 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2020-02-23 17:00:00</td>\n",
       "      <td>2020-02-25 09:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>2020-03-26 14:00:00</td>\n",
       "      <td>2020-03-27 21:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2020-04-02 02:00:00</td>\n",
       "      <td>2020-04-16 06:00:00</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2020-07-12 21:00:00</td>\n",
       "      <td>2020-08-25 21:00:00</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2020-09-24 13:00:00</td>\n",
       "      <td>2020-09-25 21:00:00</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>2020-12-16 14:00:00</td>\n",
       "      <td>2020-12-18 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>2020-12-26 14:00:00</td>\n",
       "      <td>2020-12-28 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>2021-01-09 14:00:00</td>\n",
       "      <td>2021-01-13 09:00:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2021-01-19 13:00:00</td>\n",
       "      <td>2021-01-21 09:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>2021-01-22 16:00:00</td>\n",
       "      <td>2021-01-24 08:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>2021-01-28 16:00:00</td>\n",
       "      <td>2021-01-30 08:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>2021-01-30 14:00:00</td>\n",
       "      <td>2021-02-01 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>2021-02-01 11:00:00</td>\n",
       "      <td>2021-02-03 08:00:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2021-02-18 00:00:00</td>\n",
       "      <td>2021-03-08 14:00:00</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2021-03-08 16:00:00</td>\n",
       "      <td>2021-04-19 11:00:00</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>2021-04-28 23:00:00</td>\n",
       "      <td>2021-05-01 21:00:00</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>2021-06-05 02:00:00</td>\n",
       "      <td>2021-06-07 07:00:00</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2021-06-13 02:00:00</td>\n",
       "      <td>2021-06-14 09:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>2021-06-22 02:00:00</td>\n",
       "      <td>2021-06-24 08:00:00</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2021-07-03 13:00:00</td>\n",
       "      <td>2021-07-06 05:00:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2021-08-25 23:00:00</td>\n",
       "      <td>2021-09-03 21:00:00</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>2021-09-08 13:00:00</td>\n",
       "      <td>2021-09-14 13:00:00</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2021-09-19 00:00:00</td>\n",
       "      <td>2021-09-27 08:00:00</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>2021-11-22 15:00:00</td>\n",
       "      <td>2021-11-24 08:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>2021-11-26 12:00:00</td>\n",
       "      <td>2021-12-04 08:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>2021-12-16 14:00:00</td>\n",
       "      <td>2021-12-18 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2021-12-21 14:00:00</td>\n",
       "      <td>2021-12-24 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2021-12-24 12:00:00</td>\n",
       "      <td>2022-01-03 09:00:00</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>2022-01-03 13:00:00</td>\n",
       "      <td>2022-01-11 09:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>2022-01-12 14:00:00</td>\n",
       "      <td>2022-01-14 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>2022-01-30 16:00:00</td>\n",
       "      <td>2022-02-04 09:00:00</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2022-02-10 15:00:00</td>\n",
       "      <td>2022-02-12 11:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>2022-02-14 16:00:00</td>\n",
       "      <td>2022-02-16 09:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2022-02-16 14:00:00</td>\n",
       "      <td>2022-02-18 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2022-02-19 10:00:00</td>\n",
       "      <td>2022-02-24 06:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2022-03-06 11:00:00</td>\n",
       "      <td>2022-03-07 11:00:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2022-03-19 14:00:00</td>\n",
       "      <td>2022-03-28 07:00:00</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2022-03-28 12:00:00</td>\n",
       "      <td>2022-04-05 06:00:00</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2023-01-15 15:00:00</td>\n",
       "      <td>2023-01-17 09:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "32    2019-01-14 15:00:00 2019-01-18 11:00:00        93\n",
       "36    2019-01-19 13:00:00 2019-01-26 08:00:00       164\n",
       "40    2019-01-27 11:00:00 2019-01-28 13:00:00        27\n",
       "74    2019-02-10 16:00:00 2019-02-13 07:00:00        64\n",
       "160   2019-03-23 18:00:00 2019-03-26 06:00:00        61\n",
       "302   2019-05-31 08:00:00 2019-06-03 12:00:00        77\n",
       "606   2019-10-28 14:00:00 2019-10-30 22:00:00        57\n",
       "674   2019-12-01 13:00:00 2019-12-04 08:00:00        68\n",
       "682   2019-12-07 14:00:00 2019-12-11 08:00:00        91\n",
       "700   2019-12-18 14:00:00 2019-12-20 09:00:00        44\n",
       "712   2019-12-25 14:00:00 2019-12-30 09:00:00       116\n",
       "724   2020-01-02 14:00:00 2020-01-04 08:00:00        43\n",
       "726   2020-01-04 14:00:00 2020-01-06 10:00:00        45\n",
       "768   2020-01-24 12:00:00 2020-01-26 08:00:00        45\n",
       "790   2020-02-05 14:00:00 2020-02-07 09:00:00        44\n",
       "824   2020-02-23 17:00:00 2020-02-25 09:00:00        41\n",
       "890   2020-03-26 14:00:00 2020-03-27 21:00:00        32\n",
       "906   2020-04-02 02:00:00 2020-04-16 06:00:00       341\n",
       "1090  2020-07-12 21:00:00 2020-08-25 21:00:00      1057\n",
       "1154  2020-09-24 13:00:00 2020-09-25 21:00:00        33\n",
       "1332  2020-12-16 14:00:00 2020-12-18 08:00:00        43\n",
       "1352  2020-12-26 14:00:00 2020-12-28 08:00:00        43\n",
       "1380  2021-01-09 14:00:00 2021-01-13 09:00:00        92\n",
       "1396  2021-01-19 13:00:00 2021-01-21 09:00:00        45\n",
       "1400  2021-01-22 16:00:00 2021-01-24 08:00:00        41\n",
       "1410  2021-01-28 16:00:00 2021-01-30 08:00:00        41\n",
       "1414  2021-01-30 14:00:00 2021-02-01 08:00:00        43\n",
       "1416  2021-02-01 11:00:00 2021-02-03 08:00:00        46\n",
       "1454  2021-02-18 00:00:00 2021-03-08 14:00:00       447\n",
       "1456  2021-03-08 16:00:00 2021-04-19 11:00:00      1003\n",
       "1478  2021-04-28 23:00:00 2021-05-01 21:00:00        71\n",
       "1550  2021-06-05 02:00:00 2021-06-07 07:00:00        54\n",
       "1564  2021-06-13 02:00:00 2021-06-14 09:00:00        32\n",
       "1582  2021-06-22 02:00:00 2021-06-24 08:00:00        55\n",
       "1602  2021-07-03 13:00:00 2021-07-06 05:00:00        65\n",
       "1710  2021-08-25 23:00:00 2021-09-03 21:00:00       215\n",
       "1722  2021-09-08 13:00:00 2021-09-14 13:00:00       145\n",
       "1734  2021-09-19 00:00:00 2021-09-27 08:00:00       201\n",
       "1858  2021-11-22 15:00:00 2021-11-24 08:00:00        42\n",
       "1864  2021-11-26 12:00:00 2021-12-04 08:00:00       189\n",
       "1894  2021-12-16 14:00:00 2021-12-18 09:00:00        44\n",
       "1902  2021-12-21 14:00:00 2021-12-24 09:00:00        68\n",
       "1904  2021-12-24 12:00:00 2022-01-03 09:00:00       238\n",
       "1906  2022-01-03 13:00:00 2022-01-11 09:00:00       189\n",
       "1910  2022-01-12 14:00:00 2022-01-14 08:00:00        43\n",
       "1948  2022-01-30 16:00:00 2022-02-04 09:00:00       114\n",
       "1966  2022-02-10 15:00:00 2022-02-12 11:00:00        45\n",
       "1972  2022-02-14 16:00:00 2022-02-16 09:00:00        42\n",
       "1974  2022-02-16 14:00:00 2022-02-18 10:00:00        45\n",
       "1978  2022-02-19 10:00:00 2022-02-24 06:00:00       117\n",
       "2004  2022-03-06 11:00:00 2022-03-07 11:00:00        25\n",
       "2032  2022-03-19 14:00:00 2022-03-28 07:00:00       209\n",
       "2034  2022-03-28 12:00:00 2022-04-05 06:00:00       187\n",
       "2196  2023-01-15 15:00:00 2023-01-17 09:00:00        43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed = np.sum(const_interval_b[const_interval_b['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed}')\n",
    "const_interval_b[const_interval_b['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d09483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in groups of constant values, where duration of constant measurements is > 1 day (24 hours)\n",
    "train_c, const_interval_c = remove_constant_intervals(train_c,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_c, train_c = align_X_y(x_train_c, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c619c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 4926\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-04 10:00:00</td>\n",
       "      <td>2019-09-05 12:00:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2019-11-11 12:00:00</td>\n",
       "      <td>2019-11-13 08:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2019-11-28 15:00:00</td>\n",
       "      <td>2019-12-05 09:00:00</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2019-12-07 14:00:00</td>\n",
       "      <td>2019-12-13 09:00:00</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2019-12-16 14:00:00</td>\n",
       "      <td>2019-12-21 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2019-12-25 13:00:00</td>\n",
       "      <td>2019-12-30 09:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2020-01-02 14:00:00</td>\n",
       "      <td>2020-01-07 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2020-01-23 15:00:00</td>\n",
       "      <td>2020-01-26 08:00:00</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2020-02-05 14:00:00</td>\n",
       "      <td>2020-02-10 07:00:00</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2020-02-23 17:00:00</td>\n",
       "      <td>2020-03-08 08:00:00</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2020-03-28 18:00:00</td>\n",
       "      <td>2020-03-31 09:00:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2020-11-18 13:00:00</td>\n",
       "      <td>2020-11-22 08:00:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2020-12-16 14:00:00</td>\n",
       "      <td>2020-12-18 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2020-12-21 14:00:00</td>\n",
       "      <td>2020-12-23 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>2020-12-25 14:00:00</td>\n",
       "      <td>2020-12-28 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2021-01-09 14:00:00</td>\n",
       "      <td>2021-01-22 10:00:00</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2021-01-22 15:00:00</td>\n",
       "      <td>2021-01-24 10:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>2021-01-24 13:00:00</td>\n",
       "      <td>2021-02-19 10:00:00</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>2021-03-03 17:00:00</td>\n",
       "      <td>2021-03-06 07:00:00</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>2021-03-08 14:00:00</td>\n",
       "      <td>2021-03-10 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>2021-03-20 18:00:00</td>\n",
       "      <td>2021-03-22 05:00:00</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2021-04-09 19:00:00</td>\n",
       "      <td>2021-04-11 08:00:00</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2021-11-24 14:00:00</td>\n",
       "      <td>2021-12-14 09:00:00</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2021-12-21 14:00:00</td>\n",
       "      <td>2022-01-16 10:00:00</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>2022-01-16 13:00:00</td>\n",
       "      <td>2022-01-18 10:00:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2022-01-19 14:00:00</td>\n",
       "      <td>2022-01-22 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2022-01-24 16:00:00</td>\n",
       "      <td>2022-01-26 10:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>2022-01-27 16:00:00</td>\n",
       "      <td>2022-01-30 08:00:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2022-01-30 15:00:00</td>\n",
       "      <td>2022-02-07 11:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2022-02-08 14:00:00</td>\n",
       "      <td>2022-03-02 09:00:00</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>2022-04-02 18:00:00</td>\n",
       "      <td>2022-04-04 09:00:00</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>2022-04-05 13:00:00</td>\n",
       "      <td>2022-04-08 09:00:00</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2023-02-19 14:00:00</td>\n",
       "      <td>2023-02-21 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2023-02-21 16:00:00</td>\n",
       "      <td>2023-02-23 09:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "2     2019-09-04 10:00:00 2019-09-05 12:00:00        27\n",
       "180   2019-11-11 12:00:00 2019-11-13 08:00:00        45\n",
       "230   2019-11-28 15:00:00 2019-12-05 09:00:00       163\n",
       "240   2019-12-07 14:00:00 2019-12-13 09:00:00       140\n",
       "256   2019-12-16 14:00:00 2019-12-21 09:00:00       116\n",
       "276   2019-12-25 13:00:00 2019-12-30 09:00:00       117\n",
       "290   2020-01-02 14:00:00 2020-01-07 09:00:00       116\n",
       "340   2020-01-23 15:00:00 2020-01-26 08:00:00        66\n",
       "376   2020-02-05 14:00:00 2020-02-10 07:00:00       114\n",
       "414   2020-02-23 17:00:00 2020-03-08 08:00:00       328\n",
       "484   2020-03-28 18:00:00 2020-03-31 09:00:00        64\n",
       "1150  2020-11-18 13:00:00 2020-11-22 08:00:00        92\n",
       "1238  2020-12-16 14:00:00 2020-12-18 08:00:00        43\n",
       "1252  2020-12-21 14:00:00 2020-12-23 09:00:00        44\n",
       "1264  2020-12-25 14:00:00 2020-12-28 09:00:00        68\n",
       "1312  2021-01-09 14:00:00 2021-01-22 10:00:00       309\n",
       "1316  2021-01-22 15:00:00 2021-01-24 10:00:00        44\n",
       "1318  2021-01-24 13:00:00 2021-02-19 10:00:00       622\n",
       "1358  2021-03-03 17:00:00 2021-03-06 07:00:00        63\n",
       "1374  2021-03-08 14:00:00 2021-03-10 08:00:00        43\n",
       "1408  2021-03-20 18:00:00 2021-03-22 05:00:00        36\n",
       "1458  2021-04-09 19:00:00 2021-04-11 08:00:00        38\n",
       "2122  2021-11-24 14:00:00 2021-12-14 09:00:00       476\n",
       "2146  2021-12-21 14:00:00 2022-01-16 10:00:00       621\n",
       "2148  2022-01-16 13:00:00 2022-01-18 10:00:00        46\n",
       "2152  2022-01-19 14:00:00 2022-01-22 09:00:00        68\n",
       "2164  2022-01-24 16:00:00 2022-01-26 10:00:00        43\n",
       "2168  2022-01-27 16:00:00 2022-01-30 08:00:00        65\n",
       "2172  2022-01-30 15:00:00 2022-02-07 11:00:00       189\n",
       "2178  2022-02-08 14:00:00 2022-03-02 09:00:00       524\n",
       "2284  2022-04-02 18:00:00 2022-04-04 09:00:00        40\n",
       "2290  2022-04-05 13:00:00 2022-04-08 09:00:00        69\n",
       "2486  2023-02-19 14:00:00 2023-02-21 10:00:00        45\n",
       "2490  2023-02-21 16:00:00 2023-02-23 09:00:00        42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed = np.sum(const_interval_c[const_interval_c['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed}')\n",
    "const_interval_c[const_interval_c['duration']>24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295598a-c357-4143-898f-f57bc361c20f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merge x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7084bebc-37bb-4a70-afd6-5d22049f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a = pd.merge(x_train_a, train_a, left_on='date_forecast', right_on='time', how='inner')\n",
    "merged_b = pd.merge(x_train_b, train_b, left_on='date_forecast', right_on='time', how='inner')\n",
    "merged_c = pd.merge(x_train_c, train_c, left_on='date_forecast', right_on='time', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46b11c-5cb0-445c-aa2c-b16a28f93dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are plotting on the modified dataset\n",
    "def time_series_plot(feature,merged_data):\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Solar Power Production', color='tab:blue')\n",
    "    ax1.plot(merged_data['time'], merged_data['pv_measurement'], color='tab:blue', label='Solar Power Production')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel(feature, color='tab:red')  \n",
    "    ax2.plot(merged_data['date_forecast'], merged_data[feature], color='tab:red', label=feature)\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'Time Series Plot of Solar Power Production and {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c9108-c9fe-423c-a2d3-249b198af636",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add avg pv_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25519486-5b0a-40f0-9522-9c8bd35de95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_average_pv_feature(merged_df, test_df,time_group):\n",
    "    df = merged_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    # Group by year, month, date, and hour and calculate the mean PV measurement\n",
    "    average_pv = df.groupby(time_group)['pv_measurement'].mean().reset_index()\n",
    "    average_pv = average_pv.rename(columns={'pv_measurement': 'average_pv_measurement'})\n",
    "\n",
    "    # Print for debugging\n",
    "\n",
    "\n",
    "    # Merge the average PV measurements back into the original dataframe\n",
    "    df = pd.merge(df, average_pv, on=time_group, how='left')\n",
    "    test_df = pd.merge(test_df, average_pv, on= time_group, how='left')\n",
    "    \n",
    "    # Print for debugging\n",
    "    return df,test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3f3b8-8765-4e8c-ab27-edfaa70d4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_group_1 = ['month', 'day', 'hour']\n",
    "time_group_2 = 'week'\n",
    "time_group_3 = 'month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c158542-fd5c-43a4-a308-18ad66b8d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a_avg, x_test_a_avg = add_average_pv_feature(merged_a,x_test_a,time_group_1)\n",
    "merged_b_avg, x_test_b_avg = add_average_pv_feature(merged_b,x_test_b, time_group_1)\n",
    "merged_c_avg, x_test_c_avg = add_average_pv_feature(merged_c,x_test_c,time_group_1)\n",
    "\n",
    "merged_a_avg[(merged_a_avg['month']==6) & (merged_a_avg['day']==4) & (merged_a_avg['hour']==16)][['year','month','week','day','hour','pv_measurement','average_pv_measurement']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedcdb7f-cabb-4695-90ca-ab8a5a283e42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0aae5e-3b81-426d-a165-06f346b3e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_feature(data, lag_hours, column_name='pv_measurement'):\n",
    "    \"\"\"\n",
    "    Add lag features to the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The original dataset.\n",
    "    lag_hours (int): The number of hours to lag.\n",
    "    column_name (str): The name of the column to create the lag feature for.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The dataset with the new lag feature.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the lag feature\n",
    "    df = data.copy()\n",
    "    lag_feature_name = f\"{column_name}_lag_{lag_hours}h\"\n",
    "    df[lag_feature_name] = df[column_name].shift(lag_hours)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6563274-2059-4198-a061-2875448f9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "laged_a = add_lag_feature(merged_a,24)\n",
    "laged_b = add_lag_feature(merged_b,24)\n",
    "laged_c = add_lag_feature(merged_c,24)\n",
    "\n",
    "x_test_a_laged = x_test_a.copy()\n",
    "x_test_b_laged = x_test_b.copy()\n",
    "x_test_c_laged = x_test_c.copy()\n",
    "\n",
    "\n",
    "# You can add an empty column for the lag feature in your test set:\n",
    "x_test_a_laged[f'pv_measurement_lag_{1}h'] = None\n",
    "x_test_b_laged[f'pv_measurement_lag_{1}h'] = None\n",
    "x_test_c_laged[f'pv_measurement_lag_{1}h'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b9338-8fa4-41ed-bd50-584aafeb6421",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Handle NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f652a7-cec9-4c63-83ff-cf45ad74db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a['ceiling_height_agl:m'] = merged_a['ceiling_height_agl:m'].fillna(value = 0)\n",
    "merged_b['ceiling_height_agl:m'] = merged_b['ceiling_height_agl:m'].fillna(value = 0)\n",
    "merged_c['ceiling_height_agl:m'] = merged_c['ceiling_height_agl:m'].fillna(value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d8647",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add Cyclical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cyclical features for hour of the day\n",
    "def cyclic_hourly(x):\n",
    "    train_data = x.copy()\n",
    "    train_data['hour_sin'] = np.sin(2 * np.pi * train_data['hour'] / 24)\n",
    "    train_data['hour_cos'] = np.cos(2 * np.pi * train_data['hour'] / 24)\n",
    "    return train_data\n",
    "\n",
    "\n",
    "# Creating cyclical features for month of the year\n",
    "def cyclic_monthly(x):\n",
    "    train_data = x.copy()\n",
    "    train_data['month_sin'] = np.sin(2 * np.pi * train_data['month'] / 12)\n",
    "    train_data['month_cos'] = np.cos(2 * np.pi * train_data['month'] / 12)\n",
    "    return train_data\n",
    "\n",
    "\"\"\"\n",
    "x_train_a = cyclic_hourly(x_train_a)\n",
    "x_train_a = cyclic_monthly(x_train_a)\n",
    "\n",
    "x_test_a = cyclic_hourly(x_test_a)\n",
    "x_test_a = cyclic_monthly(x_test_a)\n",
    "\n",
    "x_train_b = cyclic_hourly(x_train_b)\n",
    "x_train_b = cyclic_monthly(x_train_b)\n",
    "\n",
    "x_test_b = cyclic_hourly(x_test_b)\n",
    "x_test_b = cyclic_monthly(x_test_b)\n",
    "\n",
    "x_train_c = cyclic_hourly(x_train_c)\n",
    "x_train_c = cyclic_monthly(x_train_c)\n",
    "\n",
    "x_test_c = cyclic_hourly(x_test_c)\n",
    "x_test_c = cyclic_monthly(x_test_c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab20ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Remove outliers during night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hourly_avg(y_train):\n",
    "    # Grouping by hour and calculating the average PV measurement for each hour\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "    hourly_avg = train_data.groupby('hour')['pv_measurement'].mean()\n",
    "\n",
    "    # Plotting the average PV production for each hour\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    hourly_avg.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Average PV Production by Hour')\n",
    "    plt.xlabel('Hour of the Day')\n",
    "    plt.ylabel('Average PV Production')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_dist_hour(y_train, hour):\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "    \n",
    "    # Filtering the data for the given hour\n",
    "    hour_data = train_data[train_data['hour'] == hour]\n",
    "    \n",
    "    # Plotting the distribution of PV measurements for 1 am\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(hour_data['pv_measurement'], bins=50, color='teal', alpha=0.7)\n",
    "    plt.title(f'Distribution of PV Measurements at {hour}')\n",
    "    plt.xlabel('PV Measurement')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(hour_data['pv_measurement'].value_counts())\n",
    "#train_c[(train_c['time'].dt.hour == 2) &(train_c['pv_measurement'] == 9.8)]\n",
    "\n",
    "def get_nighttime_stats(y_train,night_start,night_end):\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "\n",
    "    # Filtering the data for nighttime hours (8 pm to 4 am)\n",
    "    nighttime_data = train_data[(train_data['hour'] >= night_start) | (train_data['hour'] <= night_end)]\n",
    "\n",
    "    # Descriptive statistics for nighttime PV measurements\n",
    "    nighttime_stats = nighttime_data['pv_measurement'].describe()\n",
    "\n",
    "    # Plotting the distribution of nighttime PV measurements\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(nighttime_data['pv_measurement'], bins=50, color='purple', alpha=0.7)\n",
    "    plt.axvline(nighttime_stats['75%'], color='red', linestyle='dashed', label='75th Percentile')\n",
    "    plt.axvline(nighttime_stats['max'], color='green', linestyle='dashed', label='Max Value')\n",
    "    plt.title('Distribution of Nighttime PV Measurements')\n",
    "    plt.xlabel('PV Measurement')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(nighttime_stats)\n",
    "    \n",
    "def set_nighttime_to_zero(y_train, night_start,night_end, thresh):\n",
    "    df = y_train.copy()\n",
    "    df['hour'] = y_train['time'].dt.hour\n",
    "    mask = (df['hour'] >= 23) | (df['hour'] <= 3) & (df['pv_measurement'] > thresh)\n",
    "    df.loc[mask, 'pv_measurement'] = 0\n",
    "    df = df.drop(columns = ['hour'])\n",
    "    return df\n",
    "\n",
    "#train_a[(train_a['time'].dt.hour == 2) &(train_a['pv_measurement'] >0)]\n",
    "#train_a = set_nighttime_to_zero(train_a,23,3,0)\n",
    "#train_b = set_nighttime_to_zero(train_b,23,3,0)\n",
    "#train_c = set_nighttime_to_zero(train_c,23,3,0)\n",
    "#train_a[(train_a['time'].dt.hour == 2) &(train_a['pv_measurement'] >0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fdf4a-51e1-41af-9e08-bd12e50f903a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Remove rows with high rad values and zero PV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ec7f2-9c3f-409b-b024-0f075b1ba9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rad_null(merged_df):\n",
    "    merged_data = merged_df.copy()\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad_1h:J'].fillna(0, inplace=True)\n",
    "    return merged_data\n",
    "\"\"\"\n",
    "m_a = remove_rad_null(merged_a)\n",
    "m_b = remove_rad_null(merged_b)\n",
    "m_c = remove_rad_null(merged_c)\n",
    "\"\"\"\n",
    "\n",
    "def get_percentiles_df(merged_df):\n",
    "    merged_data = merged_df.copy()\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad_1h:J'].fillna(0, inplace=True)\n",
    "\n",
    "    # Calculate and display percentiles\n",
    "    percentiles = [50,60,70,80,85,90,95]\n",
    "    percentile_values_direct_rad= np.percentile(merged_data['direct_rad:W'], percentiles)\n",
    "    percentile_values_direct_rad_1h = np.percentile(merged_data['direct_rad_1h:J'], percentiles)\n",
    "    percentile_values_clear_sky_rad = np.percentile(merged_data['clear_sky_rad:W'], percentiles)\n",
    "    percentile_values_clear_sky_energy = np.percentile(merged_data['clear_sky_energy_1h:J'], percentiles)\n",
    "    percentile_values_df = pd.DataFrame({\n",
    "        'Percentile': percentiles,\n",
    "        'direct_rad:W':percentile_values_direct_rad,\n",
    "        'direct_rad_1h:J': percentile_values_direct_rad_1h,\n",
    "        'clear_sky_rad:W': percentile_values_clear_sky_rad,\n",
    "        'clear_sky_energy_1h:J': percentile_values_clear_sky_energy\n",
    "        })\n",
    "    \n",
    "    return percentile_values_df\n",
    "\n",
    "def get_anomals(merged_data,feature,percentile): \n",
    "    #identify the rows where the \"direct_rad:W\" column in x_train_a is high\n",
    "    #but the PV measurement in train_a is zero -> Indicates wrong\n",
    "    \n",
    "    percentile_df = get_percentiles_df(merged_data)\n",
    "    \n",
    "    # Define a threshold for high solar radiation\n",
    "    threshold = percentile_df[percentile_df['Percentile']==percentile][feature].values[0],\n",
    "\n",
    "    # Find rows where 'direct_rad:W' is high but PV measurement is zero\n",
    "    anomalous_rows = merged_data[(merged_data[feature] > threshold) & (merged_data['pv_measurement'] == 0)]\n",
    "    \n",
    "    \n",
    "    # Display the anomalous rows\n",
    "    return anomalous_rows\n",
    "\"\"\"\n",
    "merged_a1 = merged_a.copy().drop(get_anomals(merged_a,'clear_sky_rad:W',90).index)\n",
    "merged_b1 = merged_b.copy().drop(get_anomals(merged_b,'direct_rad:W',90).index)\n",
    "merged_c1 = merged_c.copy().drop(get_anomals(merged_c,'direct_rad_1h:J',90).index)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5e046-dee0-480b-93eb-1e77befff30a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add avg pv at this time over the past week or month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ac698-54ab-4b43-8c88-42e9620dc386",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = merged_a.resample('7D', on='date_forecast',).mean()\n",
    "resampled_df['pv_measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33dc20-ae6c-4e3a-8be9-4298fb65f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_same_time_average(merged_df, period='7D'):\n",
    "    \n",
    "    df = merged_df.copy()\n",
    "    # Resample the data at the desired frequency\n",
    "    resampled_df = df.resample(period, on='date_forecast',).mean()\n",
    "    \n",
    "    \n",
    "    # Reindex the resampled data to match the original index, filling missing values by interpolation\n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6eeb4b-674d-4e18-90a1-46f390c507b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a['weekly_avg_pv_hourly'] = calculate_rolling_same_time_average(merged_a, '7D')\n",
    "\n",
    "# Calculate the rolling average at the same time over the past month\n",
    "#merged_a['monthly_avg_same_time'] = calculate_rolling_same_time_average(merged_a, '30D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bc698-2fdd-4e18-a8ed-9668d1ee8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7d537-27fa-4d76-b9f5-87a487493050",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add direct_rad * sun_elevation feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5b1dd-5ce5-4af4-8628-820e7bb1bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Did not improve kaggle score\n",
    "def add_rad_x_sun(merged_data):\n",
    "    df = merged_data.copy()\n",
    "    df['rad_x_sun_elevation'] = df['direct_rad:W']*df['sun_elevation:d']\n",
    "    return df\n",
    "\"\"\"\n",
    "mod_a = add_rad_x_sun(merged_a)\n",
    "mod_b = add_rad_x_sun(merged_b)\n",
    "mod_c = add_rad_x_sun(merged_c)\n",
    "\n",
    "x_test_a_mod = add_rad_x_sun(x_test_a)\n",
    "x_test_b_mod = add_rad_x_sun(x_test_b)\n",
    "x_test_c_mod = add_rad_x_sun(x_test_c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f54bf-c4c8-4177-8596-09a6821b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_plot('rad_x_sun_elevation',df.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fbaa3a-6a11-4d6d-8aca-2490ead53649",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Categorical Feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9317f8d-1845-497d-a5ea-def502c3f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_columns_to_cat(merged_data, cat_features):\n",
    "    df = merged_data.copy()\n",
    "    for col in cat_features:\n",
    "        df[col] = df[col].astype(str)\n",
    "    return df\n",
    "cat_features=['estimated','dew_or_rime:idx','is_day:idx','is_in_shadow:idx','precip_type_5min:idx','snow_drift:idx']\n",
    "cat_features1 = ['estimated']\n",
    "best_feat = ['estimated', 'is_in_shadow:idx', 'precip_type_5min:idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96e55f9d-f2ab-48ea-977a-d20ba70f7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a_cat = convert_columns_to_cat(merged_a,cat_features1)\n",
    "merged_b_cat = convert_columns_to_cat(merged_b,cat_features1)\n",
    "merged_c_cat = convert_columns_to_cat(merged_c,cat_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d629cd77-3549-4807-95ca-b5024c2cc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a_cat = convert_columns_to_cat(x_test_a,cat_features1)\n",
    "x_test_b_cat = convert_columns_to_cat(x_test_b,cat_features1)\n",
    "x_test_c_cat = convert_columns_to_cat(x_test_c,cat_features1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd791c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Catboost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f2483-26e8-4997-b6ba-4f4d91048048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_data, val_size=0.1, val = False, estimated_column = 'estimated'):\n",
    "    if val: \n",
    "        estimated_one = train_data[train_data[estimated_column] == 1]\n",
    "\n",
    "        #Split the filtered dataset into two\n",
    "        half_index = len(estimated_one) // 2\n",
    "        validation_set = estimated_one[half_index:]\n",
    "\n",
    "        # Combine the first half of observed_zero with the rest of the data where observed != 0\n",
    "        training_set = pd.concat([train_data[train_data[estimated_column] == 0], estimated_one[:half_index]])\n",
    "    else:\n",
    "        split_index = int(train_data.shape[0] * (1 - val_size))\n",
    "        training_set = train_data.iloc[:split_index]\n",
    "        validation_set = train_data.iloc[split_index:]\n",
    "    return training_set, validation_set\n",
    "\n",
    "\"\"\"\n",
    "  else:\n",
    "        training_set, validation_set = split_dataset(merged_df, val_size, True)\n",
    "        X_train = training_set.drop(columns=['pv_measurement'])\n",
    "        y_train = training_set['pv_measurement']\n",
    "        X_validation = validation_set.drop(columns=['pv_measurement'])\n",
    "        y_validation = validation_set['pv_measurement']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a775a1b-ddaf-4ed2-988e-53856f4c9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_catboost(merged_df):\n",
    "    merged_df = merged_df.drop(columns=['date_forecast','time'])\n",
    "\n",
    "    X = merged_df.drop(columns=['pv_measurement'])\n",
    "    y = merged_df['pv_measurement']\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "  \n",
    "    catboost_model = CatBoostRegressor(\n",
    "        #cat_features=['estimated', 'is_in_shadow:idx', 'precip_type_5min:idx'],\n",
    "        iterations=1000,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        loss_function='MAE',\n",
    "        eval_metric='MAE',\n",
    "        random_seed=42,\n",
    "        verbose=200\n",
    "    )\n",
    "    \n",
    "    catboost_model.fit(X_train, y_train, eval_set=(X_validation, y_validation), use_best_model=True, early_stopping_rounds=200)\n",
    "    return catboost_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd8c67-83a3-4d97-b2d0-a0788c830699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def build_catboost_models_multiple_seed_select_best(merged_df,x_test, n_seeds, select_k):\n",
    "    merged_df = merged_df.drop(columns=['date_forecast', 'time'])\n",
    "    X = merged_df.drop(columns=['pv_measurement'])\n",
    "    y = merged_df['pv_measurement']\n",
    "    \n",
    "    seed_mae_scores = []\n",
    "    models = []\n",
    "    seeds = range(n_seeds)  \n",
    "    \n",
    "    # Train 20 models and track their MAE scores\n",
    "    for seed in seeds:\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "            X, y, train_size=0.8, random_state=seed, shuffle=True)\n",
    "        \n",
    "        catboost_model = CatBoostRegressor(\n",
    "            #cat_features=['estimated', 'is_in_shadow:idx', 'precip_type_5min:idx'],\n",
    "            iterations=1000,\n",
    "            learning_rate=0.1,\n",
    "            depth=6,\n",
    "            loss_function='MAE',\n",
    "            eval_metric='MAE',\n",
    "            random_seed=seed,\n",
    "            verbose=200\n",
    "        )\n",
    "        \n",
    "        catboost_model.fit(X_train, y_train, eval_set=(X_validation, y_validation),\n",
    "                           use_best_model=True, early_stopping_rounds=200)\n",
    "        \n",
    "        # Get the best validation MAE for the current seed\n",
    "        mae_score = catboost_model.get_best_score()['validation']['MAE']\n",
    "        seed_mae_scores.append((seed, mae_score, catboost_model))\n",
    "        \n",
    "        # Print the best validation MAE for the current seed\n",
    "        print(f\"Best validation MAE for seed {seed}: {mae_score}\")\n",
    "    \n",
    "    # Sort models based on MAE scores and select the k best models\n",
    "    seed_mae_scores.sort(key=lambda x: x[1])\n",
    "    best_models = seed_mae_scores[:select_k]\n",
    "    \n",
    "    # Predict using the 10 best models\n",
    "    predictions = []\n",
    "    for seed, mae_score, model in best_models:\n",
    "        preds = model.predict(x_test)\n",
    "        predictions.append(preds)\n",
    "        models.append(model)\n",
    "    \n",
    "    average_best_mae = np.mean([mae_score for seed, mae_score, model in best_models])\n",
    "    # Average the predictions from the k best models\n",
    "    averaged_predictions = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return averaged_predictions,models,average_best_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "683d5454-0d10-4398-a121-e8fe022a38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def build_catboost_multiple_seed(merged_df,x_test):\n",
    "    merged_df = merged_df.drop(columns=['date_forecast', 'time'])\n",
    "    X = merged_df.drop(columns=['pv_measurement'])\n",
    "    y = merged_df['pv_measurement']\n",
    "    \n",
    "    predictions = []\n",
    "    models = []\n",
    "    scores = []\n",
    "    seeds = range(10)  # Random seeds from 0 to 9\n",
    "    \n",
    "    for seed in seeds:\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "            X, y, train_size=0.8, random_state=seed)\n",
    "        \n",
    "        catboost_model = CatBoostRegressor(\n",
    "            cat_features=['estimated'],\n",
    "            iterations=1000,\n",
    "            learning_rate=0.1,\n",
    "            depth=6,\n",
    "            loss_function='MAE',\n",
    "            eval_metric='MAE',\n",
    "            random_seed=seed,\n",
    "            verbose=200\n",
    "        )\n",
    "        \n",
    "        catboost_model.fit(X_train, y_train, eval_set=(X_validation, y_validation),\n",
    "                           use_best_model=True, early_stopping_rounds=200)\n",
    "        \n",
    "        score = catboost_model.get_best_score()['validation']['MAE']\n",
    "        scores.append(score)\n",
    "        # Print the best validation MAE for the current seed\n",
    "        print(f\"Best validation MAE for seed {seed}: {score}\")\n",
    "        \n",
    "        \n",
    "        # Predict using the current model\n",
    "        preds = catboost_model.predict(x_test)\n",
    "        predictions.append(preds)\n",
    "        models.append(catboost_model)\n",
    "    \n",
    "    # Average the predictions from all models\n",
    "    averaged_predictions = np.mean(predictions, axis=0)\n",
    "    average_score = np.mean(scores, axis = 0)\n",
    "    \n",
    "    return averaged_predictions,models, average_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0415b3cb-d879-4d9a-9eda-0d6cce18db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 588.7533830\ttest: 583.6966825\tbest: 583.6966825 (0)\ttotal: 68.8ms\tremaining: 1m 8s\n",
      "200:\tlearn: 185.0011125\ttest: 188.6871105\tbest: 188.6871105 (200)\ttotal: 2s\tremaining: 7.95s\n",
      "400:\tlearn: 169.4644443\ttest: 180.2021583\tbest: 180.2020494 (399)\ttotal: 3.94s\tremaining: 5.89s\n",
      "600:\tlearn: 161.9564237\ttest: 177.4974469\tbest: 177.4974331 (599)\ttotal: 6.29s\tremaining: 4.18s\n",
      "800:\tlearn: 156.7171737\ttest: 176.0762930\tbest: 176.0477410 (792)\ttotal: 8.39s\tremaining: 2.08s\n",
      "999:\tlearn: 151.5563978\ttest: 174.7185543\tbest: 174.7185543 (999)\ttotal: 10.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 174.7185543\n",
      "bestIteration = 999\n",
      "\n",
      "Best validation MAE for seed 0: 174.71855432118673\n",
      "0:\tlearn: 591.9098781\ttest: 607.7925225\tbest: 607.7925225 (0)\ttotal: 14ms\tremaining: 14s\n",
      "200:\tlearn: 182.0137551\ttest: 199.0435156\tbest: 199.0435156 (200)\ttotal: 2.15s\tremaining: 8.55s\n",
      "400:\tlearn: 169.2661852\ttest: 191.5859028\tbest: 191.5859028 (400)\ttotal: 4.1s\tremaining: 6.12s\n",
      "600:\tlearn: 161.5333481\ttest: 188.6365075\tbest: 188.6365075 (600)\ttotal: 5.99s\tremaining: 3.98s\n",
      "800:\tlearn: 157.1529016\ttest: 187.1250049\tbest: 187.0901093 (778)\ttotal: 7.82s\tremaining: 1.94s\n",
      "999:\tlearn: 153.1466995\ttest: 185.9302458\tbest: 185.9268294 (995)\ttotal: 9.64s\tremaining: 0us\n",
      "\n",
      "bestTest = 185.9268294\n",
      "bestIteration = 995\n",
      "\n",
      "Shrink model to first 996 iterations.\n",
      "Best validation MAE for seed 1: 185.9268294281136\n",
      "0:\tlearn: 587.2771190\ttest: 590.0681768\tbest: 590.0681768 (0)\ttotal: 17ms\tremaining: 17s\n",
      "200:\tlearn: 183.9416082\ttest: 192.3970463\tbest: 192.3970463 (200)\ttotal: 2.15s\tremaining: 8.55s\n",
      "400:\tlearn: 169.1560112\ttest: 183.9892807\tbest: 183.9892807 (400)\ttotal: 4.07s\tremaining: 6.08s\n",
      "600:\tlearn: 163.4299292\ttest: 181.5970825\tbest: 181.5970825 (600)\ttotal: 5.97s\tremaining: 3.96s\n",
      "800:\tlearn: 157.2579444\ttest: 180.0271316\tbest: 180.0186094 (797)\ttotal: 7.82s\tremaining: 1.94s\n",
      "999:\tlearn: 153.1056101\ttest: 179.5551478\tbest: 179.4815587 (882)\ttotal: 9.65s\tremaining: 0us\n",
      "\n",
      "bestTest = 179.4815587\n",
      "bestIteration = 882\n",
      "\n",
      "Shrink model to first 883 iterations.\n",
      "Best validation MAE for seed 2: 179.48155874586135\n",
      "0:\tlearn: 604.0147414\ttest: 604.3258197\tbest: 604.3258197 (0)\ttotal: 12.2ms\tremaining: 12.2s\n",
      "200:\tlearn: 189.9613739\ttest: 182.3053622\tbest: 182.3053622 (200)\ttotal: 2.03s\tremaining: 8.06s\n",
      "400:\tlearn: 174.9273967\ttest: 174.2765022\tbest: 174.2764572 (397)\ttotal: 3.96s\tremaining: 5.92s\n",
      "600:\tlearn: 167.0551501\ttest: 171.4416176\tbest: 171.4416176 (600)\ttotal: 6.13s\tremaining: 4.07s\n",
      "800:\tlearn: 161.8863925\ttest: 170.2026809\tbest: 170.1454825 (768)\ttotal: 8.07s\tremaining: 2s\n",
      "999:\tlearn: 156.6961889\ttest: 168.7066272\tbest: 168.7066272 (999)\ttotal: 9.89s\tremaining: 0us\n",
      "\n",
      "bestTest = 168.7066272\n",
      "bestIteration = 999\n",
      "\n",
      "Best validation MAE for seed 3: 168.7066271561145\n",
      "0:\tlearn: 599.4503224\ttest: 574.5523405\tbest: 574.5523405 (0)\ttotal: 13.4ms\tremaining: 13.4s\n",
      "200:\tlearn: 187.0889758\ttest: 184.5517594\tbest: 184.5517594 (200)\ttotal: 1.96s\tremaining: 7.79s\n",
      "400:\tlearn: 170.5349518\ttest: 176.8608877\tbest: 176.8608877 (400)\ttotal: 3.92s\tremaining: 5.85s\n",
      "600:\tlearn: 162.8689512\ttest: 174.4937195\tbest: 174.4937195 (600)\ttotal: 5.81s\tremaining: 3.85s\n",
      "800:\tlearn: 158.0004696\ttest: 172.9234395\tbest: 172.8905447 (798)\ttotal: 7.66s\tremaining: 1.9s\n",
      "999:\tlearn: 153.2247357\ttest: 172.2700682\tbest: 172.2700682 (999)\ttotal: 9.47s\tremaining: 0us\n",
      "\n",
      "bestTest = 172.2700682\n",
      "bestIteration = 999\n",
      "\n",
      "Best validation MAE for seed 4: 172.27006824585496\n",
      "0:\tlearn: 593.5687308\ttest: 583.9804387\tbest: 583.9804387 (0)\ttotal: 16ms\tremaining: 16s\n",
      "200:\tlearn: 184.5904214\ttest: 186.7055170\tbest: 186.7055170 (200)\ttotal: 2.02s\tremaining: 8.04s\n",
      "400:\tlearn: 170.9487549\ttest: 180.2670192\tbest: 180.2663532 (399)\ttotal: 4.01s\tremaining: 6s\n",
      "600:\tlearn: 165.0543273\ttest: 178.5880897\tbest: 178.5841785 (588)\ttotal: 5.9s\tremaining: 3.91s\n",
      "800:\tlearn: 158.3831761\ttest: 176.7260559\tbest: 176.7260559 (800)\ttotal: 7.8s\tremaining: 1.94s\n",
      "999:\tlearn: 153.4155998\ttest: 175.2306962\tbest: 175.2300724 (998)\ttotal: 9.61s\tremaining: 0us\n",
      "\n",
      "bestTest = 175.2300724\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Best validation MAE for seed 5: 175.23007241913945\n",
      "0:\tlearn: 582.5585734\ttest: 590.3861462\tbest: 590.3861462 (0)\ttotal: 12.8ms\tremaining: 12.8s\n",
      "200:\tlearn: 185.3882784\ttest: 190.9669990\tbest: 190.9669990 (200)\ttotal: 1.97s\tremaining: 7.84s\n",
      "400:\tlearn: 171.3055293\ttest: 183.1508899\tbest: 183.1508899 (400)\ttotal: 4.13s\tremaining: 6.17s\n",
      "600:\tlearn: 165.4956685\ttest: 180.9707234\tbest: 180.9683027 (596)\ttotal: 6.53s\tremaining: 4.33s\n",
      "800:\tlearn: 159.6485216\ttest: 178.8247521\tbest: 178.8220704 (798)\ttotal: 8.41s\tremaining: 2.09s\n",
      "999:\tlearn: 154.4310460\ttest: 177.2366439\tbest: 177.2361169 (998)\ttotal: 10.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 177.2361169\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Best validation MAE for seed 6: 177.2361169416664\n",
      "0:\tlearn: 595.5865012\ttest: 578.4178422\tbest: 578.4178422 (0)\ttotal: 14.9ms\tremaining: 14.8s\n",
      "200:\tlearn: 186.0264024\ttest: 193.3571355\tbest: 193.3571355 (200)\ttotal: 1.99s\tremaining: 7.91s\n",
      "400:\tlearn: 169.6183413\ttest: 184.3739821\tbest: 184.3696759 (398)\ttotal: 3.96s\tremaining: 5.92s\n",
      "600:\tlearn: 162.8853055\ttest: 182.0576336\tbest: 182.0574741 (597)\ttotal: 5.88s\tremaining: 3.9s\n",
      "800:\tlearn: 156.9752780\ttest: 180.0353369\tbest: 180.0353369 (800)\ttotal: 7.74s\tremaining: 1.92s\n",
      "999:\tlearn: 152.6841756\ttest: 179.0057905\tbest: 179.0048076 (998)\ttotal: 9.57s\tremaining: 0us\n",
      "\n",
      "bestTest = 179.0048076\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Best validation MAE for seed 7: 179.00480757618783\n",
      "0:\tlearn: 585.3215116\ttest: 598.0053359\tbest: 598.0053359 (0)\ttotal: 17.2ms\tremaining: 17.2s\n",
      "200:\tlearn: 184.1844484\ttest: 185.2891281\tbest: 185.2891281 (200)\ttotal: 2.18s\tremaining: 8.67s\n",
      "400:\tlearn: 169.9612688\ttest: 177.4677221\tbest: 177.4666905 (398)\ttotal: 4.15s\tremaining: 6.2s\n",
      "600:\tlearn: 162.5431285\ttest: 174.9573777\tbest: 174.9484482 (596)\ttotal: 6.08s\tremaining: 4.04s\n",
      "800:\tlearn: 157.8156236\ttest: 173.6122324\tbest: 173.6096067 (797)\ttotal: 7.96s\tremaining: 1.98s\n",
      "999:\tlearn: 153.3864911\ttest: 172.7646630\tbest: 172.7508273 (997)\ttotal: 9.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 172.7508273\n",
      "bestIteration = 997\n",
      "\n",
      "Shrink model to first 998 iterations.\n",
      "Best validation MAE for seed 8: 172.7508273492775\n",
      "0:\tlearn: 590.9311213\ttest: 590.1373033\tbest: 590.1373033 (0)\ttotal: 15.3ms\tremaining: 15.3s\n",
      "200:\tlearn: 185.2531725\ttest: 185.9357161\tbest: 185.9357161 (200)\ttotal: 2.01s\tremaining: 7.98s\n",
      "400:\tlearn: 171.4857101\ttest: 178.4712718\tbest: 178.4712718 (400)\ttotal: 3.95s\tremaining: 5.91s\n",
      "600:\tlearn: 164.7762780\ttest: 176.1046242\tbest: 176.0429517 (592)\ttotal: 5.9s\tremaining: 3.92s\n",
      "800:\tlearn: 159.2857970\ttest: 173.8754390\tbest: 173.8740673 (799)\ttotal: 7.74s\tremaining: 1.92s\n",
      "999:\tlearn: 154.6767510\ttest: 172.7776036\tbest: 172.7213859 (991)\ttotal: 9.56s\tremaining: 0us\n",
      "\n",
      "bestTest = 172.7213859\n",
      "bestIteration = 991\n",
      "\n",
      "Shrink model to first 992 iterations.\n",
      "Best validation MAE for seed 9: 172.72138591964534\n",
      "0:\tlearn: 101.9470008\ttest: 97.7450931\tbest: 97.7450931 (0)\ttotal: 13.7ms\tremaining: 13.7s\n",
      "200:\tlearn: 24.5987565\ttest: 26.0974936\tbest: 26.0974936 (200)\ttotal: 1.78s\tremaining: 7.09s\n",
      "400:\tlearn: 23.1293939\ttest: 25.5368644\tbest: 25.5346301 (385)\ttotal: 3.48s\tremaining: 5.2s\n",
      "600:\tlearn: 22.0280519\ttest: 25.3186009\tbest: 25.3112914 (575)\ttotal: 5.12s\tremaining: 3.4s\n",
      "800:\tlearn: 21.2493340\ttest: 25.1297218\tbest: 25.1297218 (800)\ttotal: 6.77s\tremaining: 1.68s\n",
      "999:\tlearn: 20.4325928\ttest: 24.9192006\tbest: 24.9070524 (995)\ttotal: 8.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 24.90705243\n",
      "bestIteration = 995\n",
      "\n",
      "Shrink model to first 996 iterations.\n",
      "Best validation MAE for seed 0: 24.907052430243866\n",
      "0:\tlearn: 101.3252193\ttest: 100.2193067\tbest: 100.2193067 (0)\ttotal: 10.9ms\tremaining: 10.9s\n",
      "200:\tlearn: 24.8755177\ttest: 25.8397513\tbest: 25.8397513 (200)\ttotal: 1.79s\tremaining: 7.11s\n",
      "400:\tlearn: 23.3516160\ttest: 25.2935415\tbest: 25.2898700 (395)\ttotal: 3.52s\tremaining: 5.27s\n",
      "600:\tlearn: 22.1976465\ttest: 24.9229424\tbest: 24.9229424 (600)\ttotal: 5.25s\tremaining: 3.49s\n",
      "800:\tlearn: 21.3383615\ttest: 24.7736401\tbest: 24.7736401 (800)\ttotal: 6.9s\tremaining: 1.72s\n",
      "999:\tlearn: 20.5538321\ttest: 24.6169004\tbest: 24.6159741 (995)\ttotal: 8.57s\tremaining: 0us\n",
      "\n",
      "bestTest = 24.61597413\n",
      "bestIteration = 995\n",
      "\n",
      "Shrink model to first 996 iterations.\n",
      "Best validation MAE for seed 1: 24.615974127604897\n",
      "0:\tlearn: 101.2099214\ttest: 99.4095435\tbest: 99.4095435 (0)\ttotal: 12.5ms\tremaining: 12.5s\n",
      "200:\tlearn: 25.4886482\ttest: 26.1375523\tbest: 26.1375523 (200)\ttotal: 1.79s\tremaining: 7.14s\n",
      "400:\tlearn: 23.2818492\ttest: 25.2361228\tbest: 25.2361228 (400)\ttotal: 3.56s\tremaining: 5.33s\n",
      "600:\tlearn: 22.5548378\ttest: 25.0051642\tbest: 25.0051642 (600)\ttotal: 5.31s\tremaining: 3.52s\n",
      "800:\tlearn: 21.8292123\ttest: 24.7404922\tbest: 24.7392316 (799)\ttotal: 7.34s\tremaining: 1.82s\n",
      "999:\tlearn: 21.2699172\ttest: 24.6268340\tbest: 24.6267488 (997)\ttotal: 9.26s\tremaining: 0us\n",
      "\n",
      "bestTest = 24.62674879\n",
      "bestIteration = 997\n",
      "\n",
      "Shrink model to first 998 iterations.\n",
      "Best validation MAE for seed 2: 24.626748788339864\n",
      "0:\tlearn: 101.8016955\ttest: 103.2185469\tbest: 103.2185469 (0)\ttotal: 16.1ms\tremaining: 16s\n",
      "200:\tlearn: 24.8805100\ttest: 26.5942626\tbest: 26.5942626 (200)\ttotal: 1.76s\tremaining: 7.01s\n",
      "400:\tlearn: 22.7771206\ttest: 25.6551358\tbest: 25.6549540 (399)\ttotal: 3.51s\tremaining: 5.24s\n",
      "600:\tlearn: 21.7687949\ttest: 25.3750394\tbest: 25.3741488 (599)\ttotal: 5.16s\tremaining: 3.43s\n",
      "800:\tlearn: 20.8777105\ttest: 25.1964131\tbest: 25.1950422 (799)\ttotal: 6.87s\tremaining: 1.71s\n",
      "999:\tlearn: 20.1352014\ttest: 24.9871624\tbest: 24.9871624 (999)\ttotal: 8.48s\tremaining: 0us\n",
      "\n",
      "bestTest = 24.98716243\n",
      "bestIteration = 999\n",
      "\n",
      "Best validation MAE for seed 3: 24.98716242649992\n",
      "0:\tlearn: 102.7453987\ttest: 100.5949957\tbest: 100.5949957 (0)\ttotal: 10.2ms\tremaining: 10.1s\n",
      "200:\tlearn: 24.5405856\ttest: 26.8738735\tbest: 26.8738735 (200)\ttotal: 1.82s\tremaining: 7.25s\n",
      "400:\tlearn: 22.9098687\ttest: 26.1385983\tbest: 26.1385983 (400)\ttotal: 3.55s\tremaining: 5.31s\n",
      "600:\tlearn: 21.7714801\ttest: 25.7126513\tbest: 25.7095273 (595)\ttotal: 5.21s\tremaining: 3.46s\n",
      "800:\tlearn: 20.8421062\ttest: 25.4692226\tbest: 25.4685622 (798)\ttotal: 6.89s\tremaining: 1.71s\n",
      "999:\tlearn: 20.3088516\ttest: 25.2905032\tbest: 25.2892366 (996)\ttotal: 8.53s\tremaining: 0us\n",
      "\n",
      "bestTest = 25.28923656\n",
      "bestIteration = 996\n",
      "\n",
      "Shrink model to first 997 iterations.\n",
      "Best validation MAE for seed 4: 25.289236563192265\n",
      "0:\tlearn: 102.5952681\ttest: 103.1575480\tbest: 103.1575480 (0)\ttotal: 9.89ms\tremaining: 9.88s\n",
      "200:\tlearn: 24.4771426\ttest: 26.1530869\tbest: 26.1530869 (200)\ttotal: 1.79s\tremaining: 7.13s\n",
      "400:\tlearn: 22.8550555\ttest: 25.5020919\tbest: 25.5020919 (400)\ttotal: 3.51s\tremaining: 5.25s\n",
      "600:\tlearn: 21.7305097\ttest: 25.1507003\tbest: 25.1500337 (598)\ttotal: 5.18s\tremaining: 3.44s\n",
      "800:\tlearn: 20.9618708\ttest: 25.0396617\tbest: 25.0354395 (799)\ttotal: 6.82s\tremaining: 1.69s\n",
      "999:\tlearn: 20.2468132\ttest: 24.9178941\tbest: 24.9178819 (998)\ttotal: 8.46s\tremaining: 0us\n",
      "\n",
      "bestTest = 24.91788189\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Best validation MAE for seed 5: 24.917881885029868\n",
      "0:\tlearn: 99.6306081\ttest: 98.0582580\tbest: 98.0582580 (0)\ttotal: 12.4ms\tremaining: 12.4s\n",
      "200:\tlearn: 24.6443651\ttest: 26.0650806\tbest: 26.0650806 (200)\ttotal: 1.93s\tremaining: 7.65s\n",
      "400:\tlearn: 22.9936376\ttest: 25.2492944\tbest: 25.2483815 (399)\ttotal: 3.68s\tremaining: 5.49s\n",
      "600:\tlearn: 22.0819716\ttest: 24.9477786\tbest: 24.9477786 (600)\ttotal: 5.36s\tremaining: 3.56s\n",
      "800:\tlearn: 21.1527402\ttest: 24.6125903\tbest: 24.6125442 (799)\ttotal: 6.98s\tremaining: 1.74s\n",
      "999:\tlearn: 20.5479047\ttest: 24.4108054\tbest: 24.4091499 (998)\ttotal: 8.62s\tremaining: 0us\n",
      "\n",
      "bestTest = 24.40914995\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Best validation MAE for seed 6: 24.409149946891763\n",
      "0:\tlearn: 102.4003735\ttest: 101.8044631\tbest: 101.8044631 (0)\ttotal: 11ms\tremaining: 11s\n",
      "200:\tlearn: 24.5882728\ttest: 26.7728510\tbest: 26.7728510 (200)\ttotal: 1.78s\tremaining: 7.07s\n",
      "400:\tlearn: 22.8786226\ttest: 26.0269748\tbest: 26.0265489 (399)\ttotal: 3.49s\tremaining: 5.21s\n",
      "600:\tlearn: 21.8916066\ttest: 25.6799422\tbest: 25.6799422 (600)\ttotal: 5.14s\tremaining: 3.42s\n",
      "800:\tlearn: 21.0919508\ttest: 25.4323824\tbest: 25.4308170 (798)\ttotal: 6.77s\tremaining: 1.68s\n",
      "999:\tlearn: 20.3036173\ttest: 25.2432413\tbest: 25.2419413 (994)\ttotal: 8.38s\tremaining: 0us\n",
      "\n",
      "bestTest = 25.24194132\n",
      "bestIteration = 994\n",
      "\n",
      "Shrink model to first 995 iterations.\n",
      "Best validation MAE for seed 7: 25.241941320984182\n",
      "0:\tlearn: 101.5830368\ttest: 99.6517587\tbest: 99.6517587 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
      "200:\tlearn: 24.7941934\ttest: 26.6228229\tbest: 26.6228229 (200)\ttotal: 1.79s\tremaining: 7.12s\n",
      "400:\tlearn: 23.4574811\ttest: 26.0343498\tbest: 26.0339648 (399)\ttotal: 3.5s\tremaining: 5.23s\n",
      "600:\tlearn: 22.4159377\ttest: 25.6891117\tbest: 25.6891043 (599)\ttotal: 5.16s\tremaining: 3.42s\n",
      "800:\tlearn: 21.3200632\ttest: 25.4645147\tbest: 25.4637915 (794)\ttotal: 6.8s\tremaining: 1.69s\n",
      "999:\tlearn: 20.5584484\ttest: 25.2703740\tbest: 25.2703740 (999)\ttotal: 8.42s\tremaining: 0us\n",
      "\n",
      "bestTest = 25.270374\n",
      "bestIteration = 999\n",
      "\n",
      "Best validation MAE for seed 8: 25.270374002475606\n",
      "0:\tlearn: 102.2695301\ttest: 100.3468081\tbest: 100.3468081 (0)\ttotal: 10.2ms\tremaining: 10.2s\n",
      "200:\tlearn: 24.3580746\ttest: 25.6886811\tbest: 25.6754146 (195)\ttotal: 1.78s\tremaining: 7.09s\n",
      "400:\tlearn: 22.9250646\ttest: 25.2825140\tbest: 25.2825140 (400)\ttotal: 3.69s\tremaining: 5.52s\n",
      "600:\tlearn: 21.8560638\ttest: 25.0170814\tbest: 25.0170814 (600)\ttotal: 5.72s\tremaining: 3.8s\n",
      "800:\tlearn: 21.2278346\ttest: 24.8358311\tbest: 24.8301541 (793)\ttotal: 7.85s\tremaining: 1.95s\n",
      "999:\tlearn: 20.5901745\ttest: 24.6911677\tbest: 24.6866038 (993)\ttotal: 9.46s\tremaining: 0us\n",
      "\n",
      "bestTest = 24.68660375\n",
      "bestIteration = 993\n",
      "\n",
      "Shrink model to first 994 iterations.\n",
      "Best validation MAE for seed 9: 24.68660375279084\n",
      "0:\tlearn: 88.1452179\ttest: 88.5542875\tbest: 88.5542875 (0)\ttotal: 9.76ms\tremaining: 9.75s\n",
      "200:\tlearn: 21.8480535\ttest: 24.2327003\tbest: 24.2327003 (200)\ttotal: 1.61s\tremaining: 6.4s\n",
      "400:\tlearn: 20.2642402\ttest: 23.5191726\tbest: 23.5190638 (399)\ttotal: 3.18s\tremaining: 4.75s\n",
      "600:\tlearn: 19.0554106\ttest: 23.0701309\tbest: 23.0701309 (600)\ttotal: 4.71s\tremaining: 3.13s\n",
      "800:\tlearn: 18.0936469\ttest: 22.7876654\tbest: 22.7830636 (794)\ttotal: 6.21s\tremaining: 1.54s\n",
      "999:\tlearn: 17.5714366\ttest: 22.6692733\tbest: 22.6688552 (983)\ttotal: 7.71s\tremaining: 0us\n",
      "\n",
      "bestTest = 22.66885516\n",
      "bestIteration = 983\n",
      "\n",
      "Shrink model to first 984 iterations.\n",
      "Best validation MAE for seed 0: 22.668855155779067\n",
      "0:\tlearn: 91.4843434\ttest: 86.1646443\tbest: 86.1646443 (0)\ttotal: 10.6ms\tremaining: 10.6s\n",
      "200:\tlearn: 22.0158964\ttest: 23.8671021\tbest: 23.8671021 (200)\ttotal: 1.59s\tremaining: 6.34s\n",
      "400:\tlearn: 20.4098155\ttest: 23.2346131\tbest: 23.2346131 (400)\ttotal: 3.15s\tremaining: 4.71s\n",
      "600:\tlearn: 19.0440244\ttest: 22.7734697\tbest: 22.7726722 (595)\ttotal: 4.67s\tremaining: 3.1s\n",
      "800:\tlearn: 18.2338159\ttest: 22.5564186\tbest: 22.5494492 (797)\ttotal: 6.18s\tremaining: 1.53s\n",
      "999:\tlearn: 17.5234102\ttest: 22.3947876\tbest: 22.3947454 (998)\ttotal: 7.69s\tremaining: 0us\n",
      "\n",
      "bestTest = 22.3947454\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Best validation MAE for seed 1: 22.394745401755063\n",
      "0:\tlearn: 89.6326633\ttest: 87.0477477\tbest: 87.0477477 (0)\ttotal: 12.7ms\tremaining: 12.7s\n",
      "200:\tlearn: 22.7437421\ttest: 24.0073574\tbest: 24.0073574 (200)\ttotal: 1.68s\tremaining: 6.69s\n",
      "400:\tlearn: 20.8066245\ttest: 23.1773311\tbest: 23.1771615 (398)\ttotal: 3.2s\tremaining: 4.78s\n",
      "600:\tlearn: 19.6845083\ttest: 22.9439340\tbest: 22.9439340 (600)\ttotal: 4.71s\tremaining: 3.13s\n",
      "800:\tlearn: 18.8842630\ttest: 22.7821100\tbest: 22.7806887 (797)\ttotal: 6.21s\tremaining: 1.54s\n",
      "999:\tlearn: 18.1421553\ttest: 22.6115790\tbest: 22.6068517 (973)\ttotal: 7.69s\tremaining: 0us\n",
      "\n",
      "bestTest = 22.60685175\n",
      "bestIteration = 973\n",
      "\n",
      "Shrink model to first 974 iterations.\n",
      "Best validation MAE for seed 2: 22.60685174639618\n",
      "0:\tlearn: 88.0031358\ttest: 92.7486982\tbest: 92.7486982 (0)\ttotal: 14.2ms\tremaining: 14.2s\n",
      "200:\tlearn: 21.7535580\ttest: 23.2830218\tbest: 23.2830218 (200)\ttotal: 1.65s\tremaining: 6.56s\n",
      "400:\tlearn: 20.0543786\ttest: 22.7688146\tbest: 22.7636751 (391)\ttotal: 3.28s\tremaining: 4.9s\n",
      "600:\tlearn: 19.1223291\ttest: 22.5148180\tbest: 22.5092678 (583)\ttotal: 4.85s\tremaining: 3.22s\n",
      "800:\tlearn: 18.3803552\ttest: 22.3867143\tbest: 22.3734452 (788)\ttotal: 6.34s\tremaining: 1.57s\n",
      "999:\tlearn: 17.7032823\ttest: 22.2480234\tbest: 22.2403880 (995)\ttotal: 7.81s\tremaining: 0us\n",
      "\n",
      "bestTest = 22.24038802\n",
      "bestIteration = 995\n",
      "\n",
      "Shrink model to first 996 iterations.\n",
      "Best validation MAE for seed 3: 22.240388015493732\n",
      "0:\tlearn: 88.1594805\ttest: 88.5994528\tbest: 88.5994528 (0)\ttotal: 10.5ms\tremaining: 10.5s\n",
      "200:\tlearn: 21.6151459\ttest: 23.3103293\tbest: 23.3103293 (200)\ttotal: 1.6s\tremaining: 6.38s\n",
      "400:\tlearn: 19.8690076\ttest: 22.8232060\tbest: 22.8134984 (382)\ttotal: 3.15s\tremaining: 4.7s\n",
      "600:\tlearn: 18.9831266\ttest: 22.6589462\tbest: 22.6473853 (594)\ttotal: 4.67s\tremaining: 3.1s\n",
      "800:\tlearn: 18.0174670\ttest: 22.5419356\tbest: 22.5414253 (797)\ttotal: 6.16s\tremaining: 1.53s\n",
      "999:\tlearn: 17.1706185\ttest: 22.3276796\tbest: 22.3250589 (989)\ttotal: 7.64s\tremaining: 0us\n",
      "\n",
      "bestTest = 22.32505886\n",
      "bestIteration = 989\n",
      "\n",
      "Shrink model to first 990 iterations.\n",
      "Best validation MAE for seed 4: 22.32505886313948\n",
      "0:\tlearn: 89.8474531\ttest: 87.9132908\tbest: 87.9132908 (0)\ttotal: 10.6ms\tremaining: 10.6s\n",
      "200:\tlearn: 21.8017499\ttest: 22.6411895\tbest: 22.6411895 (200)\ttotal: 1.61s\tremaining: 6.41s\n",
      "400:\tlearn: 19.8764441\ttest: 21.8334964\tbest: 21.8311069 (397)\ttotal: 3.18s\tremaining: 4.75s\n",
      "600:\tlearn: 19.0123954\ttest: 21.5508312\tbest: 21.5500873 (597)\ttotal: 4.75s\tremaining: 3.15s\n",
      "800:\tlearn: 18.3179052\ttest: 21.3450512\tbest: 21.3450512 (800)\ttotal: 6.32s\tremaining: 1.57s\n",
      "999:\tlearn: 17.5762811\ttest: 21.3012941\tbest: 21.2968022 (926)\ttotal: 7.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 21.29680222\n",
      "bestIteration = 926\n",
      "\n",
      "Shrink model to first 927 iterations.\n",
      "Best validation MAE for seed 5: 21.296802224802207\n",
      "0:\tlearn: 89.5944719\ttest: 86.3730119\tbest: 86.3730119 (0)\ttotal: 12.9ms\tremaining: 12.9s\n",
      "200:\tlearn: 22.3718541\ttest: 22.3438667\tbest: 22.3438667 (200)\ttotal: 1.58s\tremaining: 6.29s\n",
      "400:\tlearn: 21.0523842\ttest: 21.7916072\tbest: 21.7904417 (395)\ttotal: 3.14s\tremaining: 4.69s\n",
      "600:\tlearn: 19.9629872\ttest: 21.5652978\tbest: 21.5635691 (599)\ttotal: 4.68s\tremaining: 3.11s\n",
      "800:\tlearn: 19.2114930\ttest: 21.3826619\tbest: 21.3826619 (800)\ttotal: 6.5s\tremaining: 1.61s\n",
      "999:\tlearn: 18.2154077\ttest: 21.1244389\tbest: 21.1244389 (999)\ttotal: 8.26s\tremaining: 0us\n",
      "\n",
      "bestTest = 21.12443892\n",
      "bestIteration = 999\n",
      "\n",
      "Best validation MAE for seed 6: 21.124438915341234\n",
      "0:\tlearn: 88.2782245\ttest: 90.7400917\tbest: 90.7400917 (0)\ttotal: 9.22ms\tremaining: 9.21s\n",
      "200:\tlearn: 22.5790100\ttest: 23.9015498\tbest: 23.9015498 (200)\ttotal: 1.63s\tremaining: 6.48s\n",
      "400:\tlearn: 20.8294128\ttest: 23.1144426\tbest: 23.1138344 (398)\ttotal: 3.17s\tremaining: 4.73s\n",
      "600:\tlearn: 19.5687941\ttest: 22.6389805\tbest: 22.6372957 (595)\ttotal: 4.66s\tremaining: 3.1s\n",
      "800:\tlearn: 18.5870659\ttest: 22.4040206\tbest: 22.4027603 (797)\ttotal: 6.17s\tremaining: 1.53s\n",
      "999:\tlearn: 17.9061853\ttest: 22.1492962\tbest: 22.1491046 (998)\ttotal: 7.65s\tremaining: 0us\n",
      "\n",
      "bestTest = 22.14910464\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Best validation MAE for seed 7: 22.149104643487313\n",
      "0:\tlearn: 88.7977217\ttest: 89.3785921\tbest: 89.3785921 (0)\ttotal: 10.2ms\tremaining: 10.2s\n",
      "200:\tlearn: 22.3991573\ttest: 24.6049110\tbest: 24.6024897 (199)\ttotal: 1.59s\tremaining: 6.33s\n",
      "400:\tlearn: 20.2717313\ttest: 23.6728796\tbest: 23.6728796 (400)\ttotal: 3.17s\tremaining: 4.74s\n",
      "600:\tlearn: 19.0320643\ttest: 23.3124614\tbest: 23.3075767 (592)\ttotal: 4.7s\tremaining: 3.12s\n",
      "800:\tlearn: 18.1507733\ttest: 23.0148925\tbest: 23.0147522 (799)\ttotal: 6.24s\tremaining: 1.55s\n",
      "999:\tlearn: 17.4763140\ttest: 22.8638141\tbest: 22.8637804 (998)\ttotal: 7.74s\tremaining: 0us\n",
      "\n",
      "bestTest = 22.8637804\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "Best validation MAE for seed 8: 22.863780399962483\n",
      "0:\tlearn: 88.7231739\ttest: 90.6256118\tbest: 90.6256118 (0)\ttotal: 11.8ms\tremaining: 11.8s\n",
      "200:\tlearn: 22.6662476\ttest: 25.1206413\tbest: 25.1206413 (200)\ttotal: 1.56s\tremaining: 6.19s\n",
      "400:\tlearn: 20.4827762\ttest: 24.1251017\tbest: 24.1251017 (400)\ttotal: 3.12s\tremaining: 4.66s\n",
      "600:\tlearn: 19.2408642\ttest: 23.7955787\tbest: 23.7955787 (600)\ttotal: 4.62s\tremaining: 3.07s\n",
      "800:\tlearn: 18.2783300\ttest: 23.5552230\tbest: 23.5552230 (800)\ttotal: 6.14s\tremaining: 1.52s\n",
      "999:\tlearn: 17.5664721\ttest: 23.4011403\tbest: 23.3834379 (986)\ttotal: 7.63s\tremaining: 0us\n",
      "\n",
      "bestTest = 23.38343792\n",
      "bestIteration = 986\n",
      "\n",
      "Shrink model to first 987 iterations.\n",
      "Best validation MAE for seed 9: 23.38343792127809\n"
     ]
    }
   ],
   "source": [
    "pred_a, models_a, avg_a = build_catboost_multiple_seed(merged_a_cat,x_test_a_cat)\n",
    "pred_b, models_b, avg_b = build_catboost_multiple_seed(merged_b_cat,x_test_b_cat)\n",
    "pred_c, models_c, avg_c= build_catboost_multiple_seed(merged_c_cat,x_test_c_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a43dbc-c364-4c42-a2c8-3e3e3113b4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.80468481030476 24.895212524405306 22.305346328743486\n"
     ]
    }
   ],
   "source": [
    "print(avg_a, avg_b, avg_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e4e08-c99a-4c1b-8e7f-aaf9deeece46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = build_catboost(merged_a)\n",
    "model_b = build_catboost(merged_b)\n",
    "model_c = build_catboost(merged_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8599a46-e0fd-44c5-80b7-269315fa8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = build_catboost(merged_a_avg,0.2, True)\n",
    "model_b = build_catboost(merged_b_avg,0.2, True)\n",
    "model_c = build_catboost(merged_c_avg,0.125, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318564e-878f-41b2-93a1-1c14ca270856",
   "metadata": {},
   "outputs": [],
   "source": [
    "laged_model_a = build_catboost(laged_a,0.2, True)\n",
    "laged_model_b = build_catboost(laged_b,0.2, True)\n",
    "laged_model_c = build_catboost(laged_c,0.125, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9609ca-e2a7-45c8-b3d5-8818baed82b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Predict Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415dee63-822a-42ff-b91c-acce4ef6fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict_with_lag(model, test_data, initial_lag_value, lag_hours=1, column_name='pv_measurement'):\n",
    "    \"\"\"\n",
    "    Predict using a model that requires a lag feature, updating the test set iteratively.\n",
    "\n",
    "    Parameters:\n",
    "    model (model object): The trained model used for prediction.\n",
    "    test_data (pd.DataFrame): The test dataset without the target column.\n",
    "    initial_lag_value (float): The last known value of the target variable from the training set.\n",
    "    lag_hours (int): The number of hours to lag.\n",
    "    column_name (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series of predictions for the test dataset.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    lag_feature_name = f\"{column_name}_lag_{lag_hours}h\"\n",
    "    current_lag_value = initial_lag_value\n",
    "    \n",
    "    for index, row in test_data.iterrows():\n",
    "        # Set the current lag value\n",
    "        row[lag_feature_name] = current_lag_value\n",
    "        \n",
    "        # Make a prediction\n",
    "        prediction = model.predict(row.to_frame().transpose())[0]\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # Update the lag value with the current prediction\n",
    "        current_lag_value = prediction\n",
    "    \n",
    "    return pd.Series(predictions, index=test_data.index)\n",
    "\n",
    "initial_lag_val_a = merged_a.tail(24).iloc[0,52]\n",
    "initial_lag_val_b = merged_b.tail(24).iloc[0,52]\n",
    "initial_lag_val_c = merged_c.tail(24).iloc[0,52]\n",
    "\n",
    "# Then, use the function to make predictions:\n",
    "laged_pred_a = np.array(predict_with_lag(model=laged_model_a, test_data=x_test_a_laged, \n",
    "                               initial_lag_value=initial_lag_val_a, lag_hours=24))\n",
    "laged_pred_b = np.array(predict_with_lag(model=laged_model_b, test_data=x_test_b_laged, \n",
    "                               initial_lag_value=initial_lag_val_a, lag_hours=24))\n",
    "laged_pred_c = np.array(predict_with_lag(model=laged_model_c, test_data=x_test_c_laged, \n",
    "                               initial_lag_value=initial_lag_val_a, lag_hours=24))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67684c52-a72c-492b-9428-ac0a64049be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predict and Submit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b63a33-669f-4e43-beb5-ee8a5e5df1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_a = model_a.predict(x_test_a_avg)\n",
    "pred_b = model_b.predict(x_test_b_avg)\n",
    "pred_c = model_c.predict(x_test_c_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9604ef-d4e2-4b91-8159-be5b62cd37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_a = model_a.predict(x_test_a_cat)\n",
    "pred_b = model_b.predict(x_test_b_cat)\n",
    "pred_c = model_c.predict(x_test_c_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98989635-e755-4cb3-808e-fcaffbce7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub(pred_a,pred_b,pred_c):\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    submission['prediction'] = np.concatenate([pred_a,pred_b,pred_c])\n",
    "    submission.loc[submission['prediction'] < 0, 'prediction'] = 0\n",
    "    return submission\n",
    "\n",
    "sub = create_sub(pred_a,pred_b,pred_c)\n",
    "#sub = create_sub(laged_pred_a,laged_pred_b,laged_pred_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d456bf31-9668-4eb2-98a9-7097c3679b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f'Submissions/10seedsaverage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24076d9-b911-498d-87ea-23c55b6691e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,model_name,location):\n",
    "    save_directory = 'Saved_models/'+ location.upper()\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    # Define the path to save the model\n",
    "    model_file_path = os.path.join(save_directory, f'{model_name}.cbm')\n",
    "\n",
    "    # Save the model\n",
    "    model.save_model(model_file_path)\n",
    "\n",
    "    print(f\"Model successfully saved at {model_file_path}\")\n",
    "    \n",
    "save_model(model_a,'base_catBoost','A')\n",
    "save_model(model_b,'base_catBoost','B')\n",
    "save_model(model_c,'base_catBoost','C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754cbdf-96c1-464c-8234-6b2e4ff37ab0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea45b7-a8fc-4c20-b887-b3ad124e0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_importance(model):\n",
    "    feats = {'feature':merged_a.drop(columns =['date_forecast','time','pv_measurement']).columns,\n",
    "         'importance':model.get_feature_importance()}\n",
    "    df = pd.DataFrame(feats).sort_values('importance',ascending = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231c4d3-d6ce-4ad3-8b7c-a7b1985c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feat_importance(model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf40fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_preds(pred1,pred2):\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Scatter plot\n",
    "    plt.scatter(pred1['prediction'], pred2['prediction'], alpha=0.5)\n",
    "\n",
    "    # Line of equality (for reference)\n",
    "    plt.plot([pred1['prediction'].min(), pred1['prediction'].max()],\n",
    "             [pred2['prediction'].min(), pred2['prediction'].max()],\n",
    "             color='red', linestyle='--')\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Predictions from First Model')\n",
    "    plt.ylabel('Predictions from New model')\n",
    "    plt.title('Comparison of Predictions from Two Models')\n",
    "\n",
    "    # Show plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471709c6-c455-48b0-b3b9-ff1d0eba5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_two_preds(sub,sub_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(preds):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    predictions= preds['predict'].as_data_frame()\n",
    "    predictions['time'] = test['time'].unique()\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Prediction', color='tab:blue')\n",
    "    ax1.plot(predictions['time'], predictions['predict'], color='tab:blue', label='Solar Power Production')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'Time Series Plot of prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8937d-fd7d-478c-9dae-77c249bf96d6",
   "metadata": {},
   "source": [
    "### Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1282dc2-ab41-4e86-a742-869ce7a9d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_average2.csv')\n",
    "df.loc[df['prediction'] < 8, 'prediction'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eba965-56c9-46bd-8310-64a3c19d8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'Submissions/merged_models3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34416f8d-98d7-475e-b7f7-4d9b27b49dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "maks = max([train_a['pv_measurement'].max(),train_b['pv_measurement'].max(),train_c['pv_measurement'].max()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd01df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"\"\"# Plot the distribution of \"direct_rad:W\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['direct_rad:W'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"direct_rad:W\"')\n",
    "    plt.xlabel('Direct Radiation (W)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['clear_sky_rad:W'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"clear_sky_rad:W\"')\n",
    "    plt.xlabel('Direct Radiation (W)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['direct_rad_1h:J'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"direct_rad_1h:J\"')\n",
    "    plt.xlabel('Radiation 1h(J)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['clear_sky_energy_1h:J'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"clear_sky_energy_1h:J\"')\n",
    "    plt.xlabel('Radiation 1h(J)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3b9cf-df7d-46de-a185-2a062e092aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
