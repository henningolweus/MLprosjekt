{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c788fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6686ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a = pd.read_csv('cleaned_data/A/x_train_a.csv')\n",
    "x_train_b = pd.read_csv('cleaned_data/B/x_train_b.csv')\n",
    "x_train_c = pd.read_csv('cleaned_data/C/x_train_c.csv')\n",
    "\n",
    "x_test_a = pd.read_csv('cleaned_data/A/x_test_a.csv')\n",
    "x_test_b = pd.read_csv('cleaned_data/B/x_test_b.csv')\n",
    "x_test_c = pd.read_csv('cleaned_data/C/x_test_c.csv')\n",
    "\n",
    "train_a = pd.read_csv('cleaned_data/A/train_a.csv')\n",
    "train_b = pd.read_csv('cleaned_data/B/train_b.csv')\n",
    "train_c = pd.read_csv('cleaned_data/C/train_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d43bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a['time'] = pd.to_datetime(train_a['time'])\n",
    "train_b['time'] = pd.to_datetime(train_b['time'])\n",
    "train_c['time'] = pd.to_datetime(train_c['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd9be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a = x_test_a.drop(columns = ['date_forecast'])\n",
    "x_test_b = x_test_b.drop(columns = ['date_forecast'])\n",
    "x_test_c = x_test_c.drop(columns = ['date_forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34e17787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in X_train that has timestamp that does not exist in train_loc, and visa_verca\n",
    "#e.g missing solar power measurements from 2022-10-21 01:00 - 2022-10-28 21:00\n",
    "def align_X_y(x_train,y_train, x_date_column='date_forecast', y_date_column='time'):\n",
    "    \"\"\"\n",
    "    Aligns two dataframes based on the 'date_forecast' column of X and the 'time' column of y,\n",
    "    ensuring that only rows with matching time values are retained.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): The first dataframe with time in the 'date_forecast'\n",
    "    - y (pd.DataFrame): The second dataframe with time in the 'time' column.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the aligned dataframes.\n",
    "    \"\"\"\n",
    "    # Convert date columns to datetime format for easier comparison\n",
    "    x_train[x_date_column] = pd.to_datetime(x_train[x_date_column])\n",
    "    y_train[y_date_column] = pd.to_datetime(y_train[y_date_column])\n",
    "    \n",
    "    # Find common dates\n",
    "    common_dates = x_train[x_date_column][x_train[x_date_column].isin(y_train[y_date_column])]\n",
    "    \n",
    "    # Filter both datasets based on common dates\n",
    "    x_train_synced = x_train[x_train[x_date_column].isin(common_dates)]\n",
    "    y_train_synced = y_train[y_train[y_date_column].isin(common_dates)]\n",
    "    \n",
    "    return x_train_synced, y_train_synced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1a15d",
   "metadata": {},
   "source": [
    "# Analysis of Target variable  - Looking at PV_measurement\n",
    "1. Handle constant measurments over longer periods of time. Likely caused by sensor malfunction, data logging issues, or other external factors.\n",
    "    - Handeled by removing all constant values lasting more than 24 hours \n",
    "2. Add cyclical features \n",
    "2. Handle longer periods of missing data:\n",
    "    - Remove (currently tested)\n",
    "    - Interpolate \n",
    "    - Copy from previous year\n",
    "    - Copy solar production at missing time from another location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89446f1",
   "metadata": {},
   "source": [
    "### 1. Handle constant PV measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5db23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series plot of PV_measurement \n",
    "\n",
    "def solar_prod_plot(y_train, resolution='year', chunks=5):\n",
    "    df = y_train.copy()\n",
    "    \n",
    "    # Determine the plotting resolution based on the 'resolution' argument\n",
    "    # Chunks = number of year/months/days in each plot\n",
    "    if resolution == 'year':\n",
    "        unique_values = df['time'].dt.year.unique()\n",
    "        label = 'Year'\n",
    "    elif resolution == 'month':\n",
    "        df['year_month'] = df['time'].dt.to_period('M')\n",
    "        unique_values = df['year_month'].unique()\n",
    "        label = 'Month'\n",
    "    elif resolution == 'week':\n",
    "        df['year_week'] = df['time'].dt.to_period('W')\n",
    "        unique_values = df['year_week'].unique()\n",
    "        label = 'Week'\n",
    "    elif resolution == 'day':\n",
    "        df['date'] = df['time'].dt.date\n",
    "        unique_values = df['date'].unique()\n",
    "        label = 'Day'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid resolution. Choose from 'year', 'month', 'week', or 'day'.\")\n",
    "    \n",
    "    # Loop over the unique values in chunks\n",
    "    for i in range(0, len(unique_values), chunks):\n",
    "        subset_values = unique_values[i:i+chunks]\n",
    "        \n",
    "        if resolution == 'year':\n",
    "            subset_df = df[df['time'].dt.year.isin(subset_values)]\n",
    "        elif resolution == 'month':\n",
    "            subset_df = df[df['year_month'].isin(subset_values)]\n",
    "        elif resolution == 'week':\n",
    "            subset_df = df[df['year_week'].isin(subset_values)]\n",
    "        elif resolution == 'day':\n",
    "            subset_df = df[df['date'].isin(subset_values)]\n",
    "        \n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(subset_df['time'], subset_df['pv_measurement'])\n",
    "\n",
    "        title = f\"Solar Power Production for {label}: {subset_values[0]}\"\n",
    "        if len(subset_values) > 1:\n",
    "            title += f\" to {subset_values[-1]}\"\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"PV Measurement\")\n",
    "        plt.show()\n",
    "\n",
    "def remove_constant_intervals(y_train, low_thresh, upp_thresh):\n",
    "    \"\"\"\n",
    "    Identify and remove intervals of constant PV readings that exceed a specified duration. \n",
    "    Constant readings may indicate sensor malfunctions or data logging issues.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_train : pd.DataFrame\n",
    "        Dataframe containing the time-series data of solar power production.\n",
    "    threshold : int\n",
    "        The minimum duration required for an interval to be considered for removal.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The input dataframe with intervals of constant readings (exceeding the duration threshold) removed.\n",
    "    \"\"\"\n",
    "    df = y_train.copy()\n",
    "    \n",
    "    # Calculate the difference in production values\n",
    "    df['diff'] = df['pv_measurement'].diff()\n",
    "\n",
    "    # Identify where the difference is zero\n",
    "    df['zero_diff'] = df['diff'].abs() < 1e-5\n",
    "\n",
    "    # Identify groups of consecutive zero differences\n",
    "    df['group'] = (df['zero_diff'] != df['zero_diff'].shift()).cumsum()\n",
    "\n",
    "    # Filter out only the groups with consecutive zero differences\n",
    "    constant_intervals = df[df['zero_diff']].groupby('group').agg(start=('time', 'min'), \n",
    "                                                                  end=('time', 'max'),\n",
    "                                                                  duration=('time', 'size'))\n",
    "    \n",
    "    # Filter intervals based on the threshold\n",
    "    interval_df_thresh = constant_intervals[(constant_intervals['duration'] > low_thresh) & (constant_intervals['duration'] <upp_thresh)]\n",
    "    \n",
    "    # Remove rows from the main dataframe that fall within these intervals\n",
    "    for _, row in interval_df_thresh.iterrows():\n",
    "        start_time, end_time = row['start'], row['end']\n",
    "        df = df[(df['time'] < start_time) | (df['time'] > end_time)]\n",
    "    \n",
    "    # Drop the added columns used for calculations\n",
    "    df.drop(columns=['diff', 'zero_diff', 'group'], inplace=True)\n",
    "    \n",
    "    return df, constant_intervals\n",
    "\n",
    "\n",
    "def get_time_interval(df, start_time = '2020-08-01 00:00:00', end_time = '2021-01-01 00:00:00'):\n",
    "    # Filter rows based on the time period\n",
    "    filtered_df = df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1af31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed all constant values with duration > 24 hours\n",
    "\n",
    "train_a, const_interval_a = remove_constant_intervals(train_a,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_a, train_a = align_X_y(x_train_a, train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a90e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2020-01-04 15:00:00</td>\n",
       "      <td>2020-01-06 08:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "434   2020-01-04 15:00:00 2020-01-06 08:00:00        42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed_a = np.sum(const_interval_a[const_interval_a['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed_a}')\n",
    "const_interval_a[const_interval_a['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d4bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in groups of constant values, where duration of constant measurements is > 1 day (24 hours)\n",
    "train_b, const_interval_b = remove_constant_intervals(train_b,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_b, train_b = align_X_y(x_train_b, train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd0cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 6865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-01-14 15:00:00</td>\n",
       "      <td>2019-01-18 11:00:00</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-01-19 13:00:00</td>\n",
       "      <td>2019-01-26 08:00:00</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-01-27 11:00:00</td>\n",
       "      <td>2019-01-28 13:00:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2019-02-10 16:00:00</td>\n",
       "      <td>2019-02-13 07:00:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-03-23 18:00:00</td>\n",
       "      <td>2019-03-26 06:00:00</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2019-05-31 08:00:00</td>\n",
       "      <td>2019-06-03 12:00:00</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2019-10-28 14:00:00</td>\n",
       "      <td>2019-10-30 22:00:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2019-12-01 13:00:00</td>\n",
       "      <td>2019-12-04 08:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>2019-12-07 14:00:00</td>\n",
       "      <td>2019-12-11 08:00:00</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2019-12-18 14:00:00</td>\n",
       "      <td>2019-12-20 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>2019-12-25 14:00:00</td>\n",
       "      <td>2019-12-30 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2020-01-02 14:00:00</td>\n",
       "      <td>2020-01-04 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2020-01-04 14:00:00</td>\n",
       "      <td>2020-01-06 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2020-01-24 12:00:00</td>\n",
       "      <td>2020-01-26 08:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2020-02-05 14:00:00</td>\n",
       "      <td>2020-02-07 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2020-02-23 17:00:00</td>\n",
       "      <td>2020-02-25 09:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>2020-03-26 14:00:00</td>\n",
       "      <td>2020-03-27 21:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2020-04-02 02:00:00</td>\n",
       "      <td>2020-04-16 06:00:00</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2020-07-12 21:00:00</td>\n",
       "      <td>2020-08-25 21:00:00</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2020-09-24 13:00:00</td>\n",
       "      <td>2020-09-25 21:00:00</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>2020-12-16 14:00:00</td>\n",
       "      <td>2020-12-18 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>2020-12-26 14:00:00</td>\n",
       "      <td>2020-12-28 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>2021-01-09 14:00:00</td>\n",
       "      <td>2021-01-13 09:00:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2021-01-19 13:00:00</td>\n",
       "      <td>2021-01-21 09:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>2021-01-22 16:00:00</td>\n",
       "      <td>2021-01-24 08:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>2021-01-28 16:00:00</td>\n",
       "      <td>2021-01-30 08:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>2021-01-30 14:00:00</td>\n",
       "      <td>2021-02-01 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>2021-02-01 11:00:00</td>\n",
       "      <td>2021-02-03 08:00:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2021-02-18 00:00:00</td>\n",
       "      <td>2021-03-08 14:00:00</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2021-03-08 16:00:00</td>\n",
       "      <td>2021-04-19 11:00:00</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>2021-04-28 23:00:00</td>\n",
       "      <td>2021-05-01 21:00:00</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>2021-06-05 02:00:00</td>\n",
       "      <td>2021-06-07 07:00:00</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2021-06-13 02:00:00</td>\n",
       "      <td>2021-06-14 09:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>2021-06-22 02:00:00</td>\n",
       "      <td>2021-06-24 08:00:00</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2021-07-03 13:00:00</td>\n",
       "      <td>2021-07-06 05:00:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2021-08-25 23:00:00</td>\n",
       "      <td>2021-09-03 21:00:00</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>2021-09-08 13:00:00</td>\n",
       "      <td>2021-09-14 13:00:00</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2021-09-19 00:00:00</td>\n",
       "      <td>2021-09-27 08:00:00</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>2021-11-22 15:00:00</td>\n",
       "      <td>2021-11-24 08:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>2021-11-26 12:00:00</td>\n",
       "      <td>2021-12-04 08:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>2021-12-16 14:00:00</td>\n",
       "      <td>2021-12-18 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2021-12-21 14:00:00</td>\n",
       "      <td>2021-12-24 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2021-12-24 12:00:00</td>\n",
       "      <td>2022-01-03 09:00:00</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>2022-01-03 13:00:00</td>\n",
       "      <td>2022-01-11 09:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>2022-01-12 14:00:00</td>\n",
       "      <td>2022-01-14 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>2022-01-30 16:00:00</td>\n",
       "      <td>2022-02-04 09:00:00</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2022-02-10 15:00:00</td>\n",
       "      <td>2022-02-12 11:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>2022-02-14 16:00:00</td>\n",
       "      <td>2022-02-16 09:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2022-02-16 14:00:00</td>\n",
       "      <td>2022-02-18 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2022-02-19 10:00:00</td>\n",
       "      <td>2022-02-24 06:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2022-03-06 11:00:00</td>\n",
       "      <td>2022-03-07 11:00:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2022-03-19 14:00:00</td>\n",
       "      <td>2022-03-28 07:00:00</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2022-03-28 12:00:00</td>\n",
       "      <td>2022-04-05 06:00:00</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2023-01-15 15:00:00</td>\n",
       "      <td>2023-01-17 09:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "32    2019-01-14 15:00:00 2019-01-18 11:00:00        93\n",
       "36    2019-01-19 13:00:00 2019-01-26 08:00:00       164\n",
       "40    2019-01-27 11:00:00 2019-01-28 13:00:00        27\n",
       "74    2019-02-10 16:00:00 2019-02-13 07:00:00        64\n",
       "160   2019-03-23 18:00:00 2019-03-26 06:00:00        61\n",
       "302   2019-05-31 08:00:00 2019-06-03 12:00:00        77\n",
       "606   2019-10-28 14:00:00 2019-10-30 22:00:00        57\n",
       "674   2019-12-01 13:00:00 2019-12-04 08:00:00        68\n",
       "682   2019-12-07 14:00:00 2019-12-11 08:00:00        91\n",
       "700   2019-12-18 14:00:00 2019-12-20 09:00:00        44\n",
       "712   2019-12-25 14:00:00 2019-12-30 09:00:00       116\n",
       "724   2020-01-02 14:00:00 2020-01-04 08:00:00        43\n",
       "726   2020-01-04 14:00:00 2020-01-06 10:00:00        45\n",
       "768   2020-01-24 12:00:00 2020-01-26 08:00:00        45\n",
       "790   2020-02-05 14:00:00 2020-02-07 09:00:00        44\n",
       "824   2020-02-23 17:00:00 2020-02-25 09:00:00        41\n",
       "890   2020-03-26 14:00:00 2020-03-27 21:00:00        32\n",
       "906   2020-04-02 02:00:00 2020-04-16 06:00:00       341\n",
       "1090  2020-07-12 21:00:00 2020-08-25 21:00:00      1057\n",
       "1154  2020-09-24 13:00:00 2020-09-25 21:00:00        33\n",
       "1332  2020-12-16 14:00:00 2020-12-18 08:00:00        43\n",
       "1352  2020-12-26 14:00:00 2020-12-28 08:00:00        43\n",
       "1380  2021-01-09 14:00:00 2021-01-13 09:00:00        92\n",
       "1396  2021-01-19 13:00:00 2021-01-21 09:00:00        45\n",
       "1400  2021-01-22 16:00:00 2021-01-24 08:00:00        41\n",
       "1410  2021-01-28 16:00:00 2021-01-30 08:00:00        41\n",
       "1414  2021-01-30 14:00:00 2021-02-01 08:00:00        43\n",
       "1416  2021-02-01 11:00:00 2021-02-03 08:00:00        46\n",
       "1454  2021-02-18 00:00:00 2021-03-08 14:00:00       447\n",
       "1456  2021-03-08 16:00:00 2021-04-19 11:00:00      1003\n",
       "1478  2021-04-28 23:00:00 2021-05-01 21:00:00        71\n",
       "1550  2021-06-05 02:00:00 2021-06-07 07:00:00        54\n",
       "1564  2021-06-13 02:00:00 2021-06-14 09:00:00        32\n",
       "1582  2021-06-22 02:00:00 2021-06-24 08:00:00        55\n",
       "1602  2021-07-03 13:00:00 2021-07-06 05:00:00        65\n",
       "1710  2021-08-25 23:00:00 2021-09-03 21:00:00       215\n",
       "1722  2021-09-08 13:00:00 2021-09-14 13:00:00       145\n",
       "1734  2021-09-19 00:00:00 2021-09-27 08:00:00       201\n",
       "1858  2021-11-22 15:00:00 2021-11-24 08:00:00        42\n",
       "1864  2021-11-26 12:00:00 2021-12-04 08:00:00       189\n",
       "1894  2021-12-16 14:00:00 2021-12-18 09:00:00        44\n",
       "1902  2021-12-21 14:00:00 2021-12-24 09:00:00        68\n",
       "1904  2021-12-24 12:00:00 2022-01-03 09:00:00       238\n",
       "1906  2022-01-03 13:00:00 2022-01-11 09:00:00       189\n",
       "1910  2022-01-12 14:00:00 2022-01-14 08:00:00        43\n",
       "1948  2022-01-30 16:00:00 2022-02-04 09:00:00       114\n",
       "1966  2022-02-10 15:00:00 2022-02-12 11:00:00        45\n",
       "1972  2022-02-14 16:00:00 2022-02-16 09:00:00        42\n",
       "1974  2022-02-16 14:00:00 2022-02-18 10:00:00        45\n",
       "1978  2022-02-19 10:00:00 2022-02-24 06:00:00       117\n",
       "2004  2022-03-06 11:00:00 2022-03-07 11:00:00        25\n",
       "2032  2022-03-19 14:00:00 2022-03-28 07:00:00       209\n",
       "2034  2022-03-28 12:00:00 2022-04-05 06:00:00       187\n",
       "2196  2023-01-15 15:00:00 2023-01-17 09:00:00        43"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed = np.sum(const_interval_b[const_interval_b['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed}')\n",
    "const_interval_b[const_interval_b['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d09483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in groups of constant values, where duration of constant measurements is > 1 day (24 hours)\n",
    "train_c, const_interval_c = remove_constant_intervals(train_c,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_c, train_c = align_X_y(x_train_c, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c619c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 4926\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-04 10:00:00</td>\n",
       "      <td>2019-09-05 12:00:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2019-11-11 12:00:00</td>\n",
       "      <td>2019-11-13 08:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2019-11-28 15:00:00</td>\n",
       "      <td>2019-12-05 09:00:00</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2019-12-07 14:00:00</td>\n",
       "      <td>2019-12-13 09:00:00</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2019-12-16 14:00:00</td>\n",
       "      <td>2019-12-21 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2019-12-25 13:00:00</td>\n",
       "      <td>2019-12-30 09:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2020-01-02 14:00:00</td>\n",
       "      <td>2020-01-07 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2020-01-23 15:00:00</td>\n",
       "      <td>2020-01-26 08:00:00</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2020-02-05 14:00:00</td>\n",
       "      <td>2020-02-10 07:00:00</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2020-02-23 17:00:00</td>\n",
       "      <td>2020-03-08 08:00:00</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2020-03-28 18:00:00</td>\n",
       "      <td>2020-03-31 09:00:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2020-11-18 13:00:00</td>\n",
       "      <td>2020-11-22 08:00:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2020-12-16 14:00:00</td>\n",
       "      <td>2020-12-18 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2020-12-21 14:00:00</td>\n",
       "      <td>2020-12-23 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>2020-12-25 14:00:00</td>\n",
       "      <td>2020-12-28 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2021-01-09 14:00:00</td>\n",
       "      <td>2021-01-22 10:00:00</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2021-01-22 15:00:00</td>\n",
       "      <td>2021-01-24 10:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>2021-01-24 13:00:00</td>\n",
       "      <td>2021-02-19 10:00:00</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>2021-03-03 17:00:00</td>\n",
       "      <td>2021-03-06 07:00:00</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>2021-03-08 14:00:00</td>\n",
       "      <td>2021-03-10 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>2021-03-20 18:00:00</td>\n",
       "      <td>2021-03-22 05:00:00</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2021-04-09 19:00:00</td>\n",
       "      <td>2021-04-11 08:00:00</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2021-11-24 14:00:00</td>\n",
       "      <td>2021-12-14 09:00:00</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2021-12-21 14:00:00</td>\n",
       "      <td>2022-01-16 10:00:00</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>2022-01-16 13:00:00</td>\n",
       "      <td>2022-01-18 10:00:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2022-01-19 14:00:00</td>\n",
       "      <td>2022-01-22 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2022-01-24 16:00:00</td>\n",
       "      <td>2022-01-26 10:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>2022-01-27 16:00:00</td>\n",
       "      <td>2022-01-30 08:00:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2022-01-30 15:00:00</td>\n",
       "      <td>2022-02-07 11:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2022-02-08 14:00:00</td>\n",
       "      <td>2022-03-02 09:00:00</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>2022-04-02 18:00:00</td>\n",
       "      <td>2022-04-04 09:00:00</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>2022-04-05 13:00:00</td>\n",
       "      <td>2022-04-08 09:00:00</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2023-02-19 14:00:00</td>\n",
       "      <td>2023-02-21 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2023-02-21 16:00:00</td>\n",
       "      <td>2023-02-23 09:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "2     2019-09-04 10:00:00 2019-09-05 12:00:00        27\n",
       "180   2019-11-11 12:00:00 2019-11-13 08:00:00        45\n",
       "230   2019-11-28 15:00:00 2019-12-05 09:00:00       163\n",
       "240   2019-12-07 14:00:00 2019-12-13 09:00:00       140\n",
       "256   2019-12-16 14:00:00 2019-12-21 09:00:00       116\n",
       "276   2019-12-25 13:00:00 2019-12-30 09:00:00       117\n",
       "290   2020-01-02 14:00:00 2020-01-07 09:00:00       116\n",
       "340   2020-01-23 15:00:00 2020-01-26 08:00:00        66\n",
       "376   2020-02-05 14:00:00 2020-02-10 07:00:00       114\n",
       "414   2020-02-23 17:00:00 2020-03-08 08:00:00       328\n",
       "484   2020-03-28 18:00:00 2020-03-31 09:00:00        64\n",
       "1150  2020-11-18 13:00:00 2020-11-22 08:00:00        92\n",
       "1238  2020-12-16 14:00:00 2020-12-18 08:00:00        43\n",
       "1252  2020-12-21 14:00:00 2020-12-23 09:00:00        44\n",
       "1264  2020-12-25 14:00:00 2020-12-28 09:00:00        68\n",
       "1312  2021-01-09 14:00:00 2021-01-22 10:00:00       309\n",
       "1316  2021-01-22 15:00:00 2021-01-24 10:00:00        44\n",
       "1318  2021-01-24 13:00:00 2021-02-19 10:00:00       622\n",
       "1358  2021-03-03 17:00:00 2021-03-06 07:00:00        63\n",
       "1374  2021-03-08 14:00:00 2021-03-10 08:00:00        43\n",
       "1408  2021-03-20 18:00:00 2021-03-22 05:00:00        36\n",
       "1458  2021-04-09 19:00:00 2021-04-11 08:00:00        38\n",
       "2122  2021-11-24 14:00:00 2021-12-14 09:00:00       476\n",
       "2146  2021-12-21 14:00:00 2022-01-16 10:00:00       621\n",
       "2148  2022-01-16 13:00:00 2022-01-18 10:00:00        46\n",
       "2152  2022-01-19 14:00:00 2022-01-22 09:00:00        68\n",
       "2164  2022-01-24 16:00:00 2022-01-26 10:00:00        43\n",
       "2168  2022-01-27 16:00:00 2022-01-30 08:00:00        65\n",
       "2172  2022-01-30 15:00:00 2022-02-07 11:00:00       189\n",
       "2178  2022-02-08 14:00:00 2022-03-02 09:00:00       524\n",
       "2284  2022-04-02 18:00:00 2022-04-04 09:00:00        40\n",
       "2290  2022-04-05 13:00:00 2022-04-08 09:00:00        69\n",
       "2486  2023-02-19 14:00:00 2023-02-21 10:00:00        45\n",
       "2490  2023-02-21 16:00:00 2023-02-23 09:00:00        42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed = np.sum(const_interval_c[const_interval_c['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed}')\n",
    "const_interval_c[const_interval_c['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7084bebc-37bb-4a70-afd6-5d22049f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a = pd.merge(x_train_a, train_a, left_on='date_forecast', right_on='time', how='inner')\n",
    "merged_b = pd.merge(x_train_b, train_b, left_on='date_forecast', right_on='time', how='inner')\n",
    "merged_c = pd.merge(x_train_c, train_c, left_on='date_forecast', right_on='time', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d8647",
   "metadata": {},
   "source": [
    "### Add Cyclical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cyclical features for hour of the day\n",
    "def cyclic_hourly(x):\n",
    "    train_data = x.copy()\n",
    "    train_data['hour_sin'] = np.sin(2 * np.pi * train_data['hour'] / 24)\n",
    "    train_data['hour_cos'] = np.cos(2 * np.pi * train_data['hour'] / 24)\n",
    "    return train_data\n",
    "\n",
    "\n",
    "# Creating cyclical features for month of the year\n",
    "def cyclic_monthly(x):\n",
    "    train_data = x.copy()\n",
    "    train_data['month_sin'] = np.sin(2 * np.pi * train_data['month'] / 12)\n",
    "    train_data['month_cos'] = np.cos(2 * np.pi * train_data['month'] / 12)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e407ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_a = cyclic_hourly(x_train_a)\n",
    "x_train_a = cyclic_monthly(x_train_a)\n",
    "\n",
    "x_test_a = cyclic_hourly(x_test_a)\n",
    "x_test_a = cyclic_monthly(x_test_a)\n",
    "\n",
    "x_train_b = cyclic_hourly(x_train_b)\n",
    "x_train_b = cyclic_monthly(x_train_b)\n",
    "\n",
    "x_test_b = cyclic_hourly(x_test_b)\n",
    "x_test_b = cyclic_monthly(x_test_b)\n",
    "\n",
    "x_train_c = cyclic_hourly(x_train_c)\n",
    "x_train_c = cyclic_monthly(x_train_c)\n",
    "\n",
    "x_test_c = cyclic_hourly(x_test_c)\n",
    "x_test_c = cyclic_monthly(x_test_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab20ed",
   "metadata": {},
   "source": [
    "### Remove outliers during night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hourly_avg(y_train):\n",
    "    # Grouping by hour and calculating the average PV measurement for each hour\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "    hourly_avg = train_data.groupby('hour')['pv_measurement'].mean()\n",
    "\n",
    "    # Plotting the average PV production for each hour\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    hourly_avg.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Average PV Production by Hour')\n",
    "    plt.xlabel('Hour of the Day')\n",
    "    plt.ylabel('Average PV Production')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_dist_hour(y_train, hour):\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "    \n",
    "    # Filtering the data for the given hour\n",
    "    hour_data = train_data[train_data['hour'] == hour]\n",
    "    \n",
    "    # Plotting the distribution of PV measurements for 1 am\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(hour_data['pv_measurement'], bins=50, color='teal', alpha=0.7)\n",
    "    plt.title(f'Distribution of PV Measurements at {hour}')\n",
    "    plt.xlabel('PV Measurement')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(hour_data['pv_measurement'].value_counts())\n",
    "#train_c[(train_c['time'].dt.hour == 2) &(train_c['pv_measurement'] == 9.8)]\n",
    "\n",
    "def get_nighttime_stats(y_train,night_start,night_end):\n",
    "    train_data = y_train.copy()\n",
    "    train_data['hour'] = y_train['time'].dt.hour\n",
    "\n",
    "    # Filtering the data for nighttime hours (8 pm to 4 am)\n",
    "    nighttime_data = train_data[(train_data['hour'] >= night_start) | (train_data['hour'] <= night_end)]\n",
    "\n",
    "    # Descriptive statistics for nighttime PV measurements\n",
    "    nighttime_stats = nighttime_data['pv_measurement'].describe()\n",
    "\n",
    "    # Plotting the distribution of nighttime PV measurements\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(nighttime_data['pv_measurement'], bins=50, color='purple', alpha=0.7)\n",
    "    plt.axvline(nighttime_stats['75%'], color='red', linestyle='dashed', label='75th Percentile')\n",
    "    plt.axvline(nighttime_stats['max'], color='green', linestyle='dashed', label='Max Value')\n",
    "    plt.title('Distribution of Nighttime PV Measurements')\n",
    "    plt.xlabel('PV Measurement')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(nighttime_stats)\n",
    "    \n",
    "def set_nighttime_to_zero(y_train, night_start,night_end, thresh):\n",
    "    df = y_train.copy()\n",
    "    df['hour'] = y_train['time'].dt.hour\n",
    "    mask = (df['hour'] >= 23) | (df['hour'] <= 3) & (df['pv_measurement'] > thresh)\n",
    "    df.loc[mask, 'pv_measurement'] = 0\n",
    "    df = df.drop(columns = ['hour'])\n",
    "    return df\n",
    "\n",
    "#train_a[(train_a['time'].dt.hour == 2) &(train_a['pv_measurement'] >0)]\n",
    "#train_a = set_nighttime_to_zero(train_a,23,3,0)\n",
    "#train_b = set_nighttime_to_zero(train_b,23,3,0)\n",
    "#train_c = set_nighttime_to_zero(train_c,23,3,0)\n",
    "#train_a[(train_a['time'].dt.hour == 2) &(train_a['pv_measurement'] >0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29988c-1251-4411-8292-d50ff846844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rad_null(merged_df):\n",
    "    merged_data = merged_df.copy()\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad_1h:J'].fillna(0, inplace=True)\n",
    "    return merged_data\n",
    "\"\"\"\n",
    "m_a = remove_rad_null(merged_a)\n",
    "m_b = remove_rad_null(merged_b)\n",
    "m_c = remove_rad_null(merged_c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ec7f2-9c3f-409b-b024-0f075b1ba9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentiles_df(merged_df):\n",
    "    merged_data = merged_df.copy()\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['clear_sky_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad:W'].fillna(0, inplace=True)\n",
    "    merged_data['direct_rad_1h:J'].fillna(0, inplace=True)\n",
    "\n",
    "    # Calculate and display percentiles\n",
    "    percentiles = [50,60,70,80,85,90,95]\n",
    "    percentile_values_direct_rad= np.percentile(merged_data['direct_rad:W'], percentiles)\n",
    "    percentile_values_direct_rad_1h = np.percentile(merged_data['direct_rad_1h:J'], percentiles)\n",
    "    percentile_values_clear_sky_rad = np.percentile(merged_data['clear_sky_rad:W'], percentiles)\n",
    "    percentile_values_clear_sky_energy = np.percentile(merged_data['clear_sky_energy_1h:J'], percentiles)\n",
    "    percentile_values_df = pd.DataFrame({\n",
    "        'Percentile': percentiles,\n",
    "        'direct_rad:W':percentile_values_direct_rad,\n",
    "        'direct_rad_1h:J': percentile_values_direct_rad_1h,\n",
    "        'clear_sky_rad:W': percentile_values_clear_sky_rad,\n",
    "        'clear_sky_energy_1h:J': percentile_values_clear_sky_energy\n",
    "        })\n",
    "    \n",
    "    return percentile_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf8824-1c01-4e0a-88c4-e04f497674b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_a = get_percentiles_df(merged_a)\n",
    "percentile_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b40a3f-1b72-4489-ae17-723920e1724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomals(merged_data,feature,percentile): \n",
    "    #identify the rows where the \"direct_rad:W\" column in x_train_a is high\n",
    "    #but the PV measurement in train_a is zero -> Indicates wrong\n",
    "    \n",
    "    percentile_df = get_percentiles_df(merged_data)\n",
    "    \n",
    "    # Define a threshold for high solar radiation\n",
    "    threshold = percentile_df[percentile_df['Percentile']==percentile][feature].values[0],\n",
    "\n",
    "    # Find rows where 'direct_rad:W' is high but PV measurement is zero\n",
    "    anomalous_rows = merged_data[(merged_data[feature] > threshold) & (merged_data['pv_measurement'] == 0)]\n",
    "    \n",
    "    \n",
    "    # Display the anomalous rows\n",
    "    return anomalous_rows\n",
    "\n",
    "get_anomals(merged_c,'direct_rad:W',90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6a95c-d022-4eee-a2d3-93e65dcb0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a1 = merged_a.copy().drop(get_anomals(merged_a,'clear_sky_rad:W',90).index)\n",
    "merged_b1 = merged_b.copy().drop(get_anomals(merged_b,'direct_rad:W',90).index)\n",
    "merged_c1 = merged_c.copy().drop(get_anomals(merged_c,'direct_rad_1h:J',90).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5415d0f-67fe-4978-9c6e-58b11f04c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_data, estimated_column='estimated',val_size = 0.1,val = False):\n",
    "    \"\"\"\n",
    "    Splits the dataset into a training set and a validation set.\n",
    "    The validation set contains the last half of the rows where observed = 0,\n",
    "    and the training set contains the rest.\n",
    "\n",
    "    :param train_data: The original training dataset as a pandas DataFrame.\n",
    "    :param observed_column: The name of the column that indicates if the row is observed.\n",
    "    :return: A tuple (training_set, validation_set)\n",
    "    \"\"\"\n",
    "    \n",
    "    if val: \n",
    "        estimated_one = train_data[train_data[estimated_column] == 1]\n",
    "\n",
    "        #Split the filtered dataset into two\n",
    "        half_index = len(estimated_one) // 2\n",
    "        validation_set = estimated_one[half_index:]\n",
    "\n",
    "        # Combine the first half of observed_zero with the rest of the data where observed != 0\n",
    "        training_set = pd.concat([train_data[train_data[estimated_column] == 0], estimated_one[:half_index]])\n",
    "    else:\n",
    "        split_index = int(train_data.shape[0] * (1-val_size))\n",
    "\n",
    "        # Split the data\n",
    "        training_set = train_data.iloc[:split_index]\n",
    "        validation_set = train_data.iloc[split_index:]\n",
    "\n",
    "    # Filter rows where observed = 0\n",
    "   \n",
    "    return training_set, validation_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bdaca-10a0-4c7f-967f-2cd62511a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, validation_set = split_dataset(merged_b)\n",
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd791c",
   "metadata": {},
   "source": [
    "# Build Catboost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a775a1b-ddaf-4ed2-988e-53856f4c9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_data, val_size=0.1, val = False, estimated_column = 'estimated'):\n",
    "    if val: \n",
    "        estimated_one = train_data[train_data[estimated_column] == 1]\n",
    "\n",
    "        #Split the filtered dataset into two\n",
    "        half_index = len(estimated_one) // 2\n",
    "        validation_set = estimated_one[half_index:]\n",
    "\n",
    "        # Combine the first half of observed_zero with the rest of the data where observed != 0\n",
    "        training_set = pd.concat([train_data[train_data[estimated_column] == 0], estimated_one[:half_index]])\n",
    "    else:\n",
    "        split_index = int(train_data.shape[0] * (1 - val_size))\n",
    "        training_set = train_data.iloc[:split_index]\n",
    "        validation_set = train_data.iloc[split_index:]\n",
    "    return training_set, validation_set\n",
    "\n",
    "def build_catboost(merged_df, val_size=0.1, randomized=False):\n",
    "    merged_df = merged_df.drop(columns=['date_forecast','time'])\n",
    "    if randomized:\n",
    "        X = merged_df.drop(columns=['pv_measurement'])\n",
    "        y = merged_df['pv_measurement']\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "    else:\n",
    "        training_set, validation_set = split_dataset(merged_df, val_size, True)\n",
    "        X_train = training_set.drop(columns=['pv_measurement'])\n",
    "        y_train = training_set['pv_measurement']\n",
    "        X_validation = validation_set.drop(columns=['pv_measurement'])\n",
    "        y_validation = validation_set['pv_measurement']\n",
    "    \n",
    "    catboost_model = CatBoostRegressor(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        loss_function='MAE',\n",
    "        eval_metric='MAE',\n",
    "        random_seed=42,\n",
    "        verbose=200\n",
    "    )\n",
    "    \n",
    "    catboost_model.fit(X_train, y_train, eval_set=(X_validation, y_validation), use_best_model=True)\n",
    "    return catboost_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8599a46-e0fd-44c5-80b7-269315fa8eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 600.5894516\ttest: 558.0483834\tbest: 558.0483834 (0)\ttotal: 67.2ms\tremaining: 1m 7s\n",
      "200:\tlearn: 185.5510441\ttest: 173.5042243\tbest: 173.5042243 (200)\ttotal: 2.22s\tremaining: 8.82s\n",
      "400:\tlearn: 173.2445959\ttest: 168.7063903\tbest: 168.6684925 (388)\ttotal: 4.34s\tremaining: 6.49s\n",
      "600:\tlearn: 166.1482163\ttest: 167.5894432\tbest: 166.5839045 (435)\ttotal: 6.4s\tremaining: 4.25s\n",
      "800:\tlearn: 159.1514533\ttest: 167.1701680\tbest: 166.5839045 (435)\ttotal: 8.42s\tremaining: 2.09s\n",
      "999:\tlearn: 154.7516374\ttest: 167.3482256\tbest: 166.5839045 (435)\ttotal: 10.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 166.5839045\n",
      "bestIteration = 435\n",
      "\n",
      "Shrink model to first 436 iterations.\n"
     ]
    }
   ],
   "source": [
    "model_a = build_catboost(merged_a,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e318564e-878f-41b2-93a1-1c14ca270856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 101.0737028\ttest: 91.9392713\tbest: 91.9392713 (0)\ttotal: 15.1ms\tremaining: 15.1s\n",
      "200:\tlearn: 25.2960206\ttest: 29.8616912\tbest: 29.7580680 (196)\ttotal: 1.91s\tremaining: 7.58s\n",
      "400:\tlearn: 23.6623041\ttest: 30.1180718\tbest: 29.7580680 (196)\ttotal: 3.74s\tremaining: 5.59s\n",
      "600:\tlearn: 22.7529511\ttest: 30.1512024\tbest: 29.7580680 (196)\ttotal: 5.56s\tremaining: 3.69s\n",
      "800:\tlearn: 22.0695991\ttest: 30.3945765\tbest: 29.7580680 (196)\ttotal: 7.4s\tremaining: 1.84s\n",
      "999:\tlearn: 21.2544385\ttest: 30.4785549\tbest: 29.7580680 (196)\ttotal: 9.14s\tremaining: 0us\n",
      "\n",
      "bestTest = 29.75806801\n",
      "bestIteration = 196\n",
      "\n",
      "Shrink model to first 197 iterations.\n"
     ]
    }
   ],
   "source": [
    "model_b = build_catboost(merged_b,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b22fb09-4678-41ac-824d-f538fc343dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 91.5728187\ttest: 74.2043316\tbest: 74.2043316 (0)\ttotal: 16.2ms\tremaining: 16.2s\n",
      "200:\tlearn: 21.8707706\ttest: 35.5554436\tbest: 34.3911878 (19)\ttotal: 1.75s\tremaining: 6.94s\n",
      "400:\tlearn: 20.2638081\ttest: 35.7763126\tbest: 34.3911878 (19)\ttotal: 3.38s\tremaining: 5.04s\n",
      "600:\tlearn: 19.3393926\ttest: 35.5532212\tbest: 34.3911878 (19)\ttotal: 5.01s\tremaining: 3.33s\n",
      "800:\tlearn: 18.4469416\ttest: 35.8884802\tbest: 34.3911878 (19)\ttotal: 6.61s\tremaining: 1.64s\n",
      "999:\tlearn: 17.6737007\ttest: 35.9224432\tbest: 34.3911878 (19)\ttotal: 8.19s\tremaining: 0us\n",
      "\n",
      "bestTest = 34.39118778\n",
      "bestIteration = 19\n",
      "\n",
      "Shrink model to first 20 iterations.\n"
     ]
    }
   ],
   "source": [
    "model_c = build_catboost(merged_c,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea45b7-a8fc-4c20-b887-b3ad124e0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_importance(model):\n",
    "    feats = {'feature':merged_a.drop(columns =['pv_measurement']).columns,\n",
    "         'importance':model.get_feature_importance()}\n",
    "    df = pd.DataFrame(feats).sort_values('importance',ascending = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8210d-d681-47e3-9056-0e7f9fb04125",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feat_importance(model_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c16deabc-3c3e-4e1b-990a-c32f5f019235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>elevation:m</th>\n",
       "      <th>fresh_snow_12h:cm</th>\n",
       "      <th>fresh_snow_1h:cm</th>\n",
       "      <th>fresh_snow_24h:cm</th>\n",
       "      <th>fresh_snow_3h:cm</th>\n",
       "      <th>fresh_snow_6h:cm</th>\n",
       "      <th>is_day:idx</th>\n",
       "      <th>is_in_shadow:idx</th>\n",
       "      <th>msl_pressure:hPa</th>\n",
       "      <th>precip_5min:mm</th>\n",
       "      <th>precip_type_5min:idx</th>\n",
       "      <th>pressure_100m:hPa</th>\n",
       "      <th>pressure_50m:hPa</th>\n",
       "      <th>prob_rime:p</th>\n",
       "      <th>rain_water:kgm2</th>\n",
       "      <th>relative_humidity_1000hPa:p</th>\n",
       "      <th>sfc_pressure:hPa</th>\n",
       "      <th>snow_density:kgm3</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>snow_drift:idx</th>\n",
       "      <th>snow_melt_10min:mm</th>\n",
       "      <th>snow_water:kgm2</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.325</td>\n",
       "      <td>1.28675</td>\n",
       "      <td>912.7000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1061.5500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.65002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.950</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1013.675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.550</td>\n",
       "      <td>1006.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.275</td>\n",
       "      <td>1013.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.02650</td>\n",
       "      <td>-10.54100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>273.80000</td>\n",
       "      <td>74.950</td>\n",
       "      <td>29907.500</td>\n",
       "      <td>3.950</td>\n",
       "      <td>2.100</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.275</td>\n",
       "      <td>1.28600</td>\n",
       "      <td>1482.1000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1075.1001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.45000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.475</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1013.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.050</td>\n",
       "      <td>1006.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.825</td>\n",
       "      <td>1012.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.49725</td>\n",
       "      <td>-7.89450</td>\n",
       "      <td>0.000</td>\n",
       "      <td>273.80000</td>\n",
       "      <td>77.475</td>\n",
       "      <td>29519.074</td>\n",
       "      <td>3.825</td>\n",
       "      <td>1.925</td>\n",
       "      <td>3.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.150</td>\n",
       "      <td>1.28375</td>\n",
       "      <td>1791.3000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1200.4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.05000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.100</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1012.675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.500</td>\n",
       "      <td>1005.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.000</td>\n",
       "      <td>1012.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.51725</td>\n",
       "      <td>-3.81550</td>\n",
       "      <td>0.000</td>\n",
       "      <td>273.84998</td>\n",
       "      <td>88.100</td>\n",
       "      <td>31009.125</td>\n",
       "      <td>3.650</td>\n",
       "      <td>1.750</td>\n",
       "      <td>3.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.025</td>\n",
       "      <td>1.28200</td>\n",
       "      <td>2312.8750</td>\n",
       "      <td>40497.70</td>\n",
       "      <td>11.675</td>\n",
       "      <td>1179.8500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.65000</td>\n",
       "      <td>9.375</td>\n",
       "      <td>67380.91</td>\n",
       "      <td>2.100</td>\n",
       "      <td>15061.4</td>\n",
       "      <td>68.600</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1012.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>998.975</td>\n",
       "      <td>1005.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.625</td>\n",
       "      <td>1011.525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.08300</td>\n",
       "      <td>1.41250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>273.90000</td>\n",
       "      <td>68.600</td>\n",
       "      <td>34552.500</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.450</td>\n",
       "      <td>3.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.900</td>\n",
       "      <td>1.28100</td>\n",
       "      <td>2198.2998</td>\n",
       "      <td>566994.40</td>\n",
       "      <td>76.875</td>\n",
       "      <td>920.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.37500</td>\n",
       "      <td>47.400</td>\n",
       "      <td>408838.80</td>\n",
       "      <td>25.450</td>\n",
       "      <td>198284.8</td>\n",
       "      <td>66.300</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1011.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>998.550</td>\n",
       "      <td>1004.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.225</td>\n",
       "      <td>1011.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.34100</td>\n",
       "      <td>7.46850</td>\n",
       "      <td>0.000</td>\n",
       "      <td>273.92500</td>\n",
       "      <td>66.300</td>\n",
       "      <td>35483.875</td>\n",
       "      <td>3.325</td>\n",
       "      <td>1.300</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>8.350</td>\n",
       "      <td>1.19725</td>\n",
       "      <td>3638.9000</td>\n",
       "      <td>1908372.80</td>\n",
       "      <td>85.100</td>\n",
       "      <td>2013.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.57500</td>\n",
       "      <td>33.625</td>\n",
       "      <td>675098.20</td>\n",
       "      <td>13.425</td>\n",
       "      <td>203853.0</td>\n",
       "      <td>85.575</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>992.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>979.600</td>\n",
       "      <td>985.425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.325</td>\n",
       "      <td>991.325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.68700</td>\n",
       "      <td>8.15300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>287.02500</td>\n",
       "      <td>86.150</td>\n",
       "      <td>44056.375</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.075</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>8.525</td>\n",
       "      <td>1.20050</td>\n",
       "      <td>3552.1000</td>\n",
       "      <td>737342.70</td>\n",
       "      <td>24.800</td>\n",
       "      <td>1610.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.85000</td>\n",
       "      <td>14.325</td>\n",
       "      <td>345284.50</td>\n",
       "      <td>3.550</td>\n",
       "      <td>122263.5</td>\n",
       "      <td>74.600</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>992.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>980.025</td>\n",
       "      <td>985.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.900</td>\n",
       "      <td>991.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.70400</td>\n",
       "      <td>3.26800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>286.60000</td>\n",
       "      <td>75.325</td>\n",
       "      <td>44017.176</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.100</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>8.825</td>\n",
       "      <td>1.20450</td>\n",
       "      <td>2315.0000</td>\n",
       "      <td>149717.31</td>\n",
       "      <td>1.275</td>\n",
       "      <td>1622.8000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.32500</td>\n",
       "      <td>1.300</td>\n",
       "      <td>112676.60</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25639.6</td>\n",
       "      <td>76.125</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>992.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>980.350</td>\n",
       "      <td>986.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.050</td>\n",
       "      <td>992.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333.04000</td>\n",
       "      <td>-0.44325</td>\n",
       "      <td>0.000</td>\n",
       "      <td>286.10000</td>\n",
       "      <td>76.850</td>\n",
       "      <td>43302.050</td>\n",
       "      <td>2.575</td>\n",
       "      <td>2.150</td>\n",
       "      <td>-1.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>9.025</td>\n",
       "      <td>1.20700</td>\n",
       "      <td>2202.8000</td>\n",
       "      <td>1440.20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1767.5500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.67502</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9402.90</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.225</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>993.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>980.700</td>\n",
       "      <td>986.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.750</td>\n",
       "      <td>992.525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346.68600</td>\n",
       "      <td>-2.75050</td>\n",
       "      <td>0.075</td>\n",
       "      <td>285.55000</td>\n",
       "      <td>98.325</td>\n",
       "      <td>40505.850</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.800</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>9.050</td>\n",
       "      <td>1.20775</td>\n",
       "      <td>2015.6750</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1438.4500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.67502</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>993.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.000</td>\n",
       "      <td>986.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.000</td>\n",
       "      <td>992.825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.51850</td>\n",
       "      <td>-3.49750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>285.25000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>39665.523</td>\n",
       "      <td>1.975</td>\n",
       "      <td>1.600</td>\n",
       "      <td>-1.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     absolute_humidity_2m:gm3  air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
       "0                       4.325              1.28675              912.7000   \n",
       "1                       4.275              1.28600             1482.1000   \n",
       "2                       4.150              1.28375             1791.3000   \n",
       "3                       4.025              1.28200             2312.8750   \n",
       "4                       3.900              1.28100             2198.2998   \n",
       "..                        ...                  ...                   ...   \n",
       "715                     8.350              1.19725             3638.9000   \n",
       "716                     8.525              1.20050             3552.1000   \n",
       "717                     8.825              1.20450             2315.0000   \n",
       "718                     9.025              1.20700             2202.8000   \n",
       "719                     9.050              1.20775             2015.6750   \n",
       "\n",
       "     clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  \\\n",
       "0                     0.00            0.000         1061.5500   \n",
       "1                     0.00            0.000         1075.1001   \n",
       "2                     0.00            0.000         1200.4000   \n",
       "3                 40497.70           11.675         1179.8500   \n",
       "4                566994.40           76.875          920.0500   \n",
       "..                     ...              ...               ...   \n",
       "715             1908372.80           85.100         2013.7500   \n",
       "716              737342.70           24.800         1610.9000   \n",
       "717              149717.31            1.275         1622.8000   \n",
       "718                1440.20            0.000         1767.5500   \n",
       "719                   0.00            0.000         1438.4500   \n",
       "\n",
       "     dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  diffuse_rad_1h:J  \\\n",
       "0                0.0       271.65002          0.000              0.00   \n",
       "1                0.0       271.45000          0.000              0.00   \n",
       "2                0.0       271.05000          0.000              0.00   \n",
       "3                0.0       270.65000          9.375          67380.91   \n",
       "4                0.0       270.37500         47.400         408838.80   \n",
       "..               ...             ...            ...               ...   \n",
       "715              0.0       281.57500         33.625         675098.20   \n",
       "716              0.0       281.85000         14.325         345284.50   \n",
       "717              0.0       282.32500          1.300         112676.60   \n",
       "718              0.0       282.67502          0.000           9402.90   \n",
       "719              0.0       282.67502          0.000              0.00   \n",
       "\n",
       "     direct_rad:W  direct_rad_1h:J  effective_cloud_cover:p  elevation:m  \\\n",
       "0           0.000              0.0                   74.950          6.0   \n",
       "1           0.000              0.0                   77.475          6.0   \n",
       "2           0.000              0.0                   88.100          6.0   \n",
       "3           2.100          15061.4                   68.600          6.0   \n",
       "4          25.450         198284.8                   66.300          6.0   \n",
       "..            ...              ...                      ...          ...   \n",
       "715        13.425         203853.0                   85.575          6.0   \n",
       "716         3.550         122263.5                   74.600          6.0   \n",
       "717         0.000          25639.6                   76.125          6.0   \n",
       "718         0.000              0.0                   98.225          6.0   \n",
       "719         0.000              0.0                  100.000          6.0   \n",
       "\n",
       "     fresh_snow_12h:cm  fresh_snow_1h:cm  fresh_snow_24h:cm  fresh_snow_3h:cm  \\\n",
       "0                  0.0               0.0                0.0               0.0   \n",
       "1                  0.0               0.0                0.0               0.0   \n",
       "2                  0.0               0.0                0.0               0.0   \n",
       "3                  0.0               0.0                0.0               0.0   \n",
       "4                  0.0               0.0                0.0               0.0   \n",
       "..                 ...               ...                ...               ...   \n",
       "715                0.0               0.0                0.0               0.0   \n",
       "716                0.0               0.0                0.0               0.0   \n",
       "717                0.0               0.0                0.0               0.0   \n",
       "718                0.0               0.0                0.0               0.0   \n",
       "719                0.0               0.0                0.0               0.0   \n",
       "\n",
       "     fresh_snow_6h:cm  is_day:idx  is_in_shadow:idx  msl_pressure:hPa  \\\n",
       "0                 0.0         0.0               1.0          1013.675   \n",
       "1                 0.0         0.0               1.0          1013.150   \n",
       "2                 0.0         0.0               1.0          1012.675   \n",
       "3                 0.0         1.0               1.0          1012.175   \n",
       "4                 0.0         1.0               0.0          1011.725   \n",
       "..                ...         ...               ...               ...   \n",
       "715               0.0         1.0               0.0           992.100   \n",
       "716               0.0         1.0               0.0           992.550   \n",
       "717               0.0         1.0               1.0           992.900   \n",
       "718               0.0         0.0               1.0           993.225   \n",
       "719               0.0         0.0               1.0           993.550   \n",
       "\n",
       "     precip_5min:mm  precip_type_5min:idx  pressure_100m:hPa  \\\n",
       "0               0.0                   0.0           1000.550   \n",
       "1               0.0                   0.0           1000.050   \n",
       "2               0.0                   0.0            999.500   \n",
       "3               0.0                   0.0            998.975   \n",
       "4               0.0                   0.0            998.550   \n",
       "..              ...                   ...                ...   \n",
       "715             0.0                   0.0            979.600   \n",
       "716             0.0                   0.0            980.025   \n",
       "717             0.0                   0.0            980.350   \n",
       "718             0.0                   0.0            980.700   \n",
       "719             0.0                   0.0            981.000   \n",
       "\n",
       "     pressure_50m:hPa  prob_rime:p  rain_water:kgm2  \\\n",
       "0            1006.800          0.0              0.0   \n",
       "1            1006.300          0.0              0.0   \n",
       "2            1005.800          0.0              0.0   \n",
       "3            1005.225          0.0              0.0   \n",
       "4            1004.750          0.0              0.0   \n",
       "..                ...          ...              ...   \n",
       "715           985.425          0.0              0.0   \n",
       "716           985.900          0.0              0.0   \n",
       "717           986.250          0.0              0.0   \n",
       "718           986.600          0.0              0.0   \n",
       "719           986.900          0.0              0.0   \n",
       "\n",
       "     relative_humidity_1000hPa:p  sfc_pressure:hPa  snow_density:kgm3  \\\n",
       "0                         80.275          1013.100                NaN   \n",
       "1                         79.825          1012.600                NaN   \n",
       "2                         78.000          1012.050                NaN   \n",
       "3                         75.625          1011.525                NaN   \n",
       "4                         74.225          1011.050                NaN   \n",
       "..                           ...               ...                ...   \n",
       "715                       69.325           991.325                NaN   \n",
       "716                       72.900           991.800                NaN   \n",
       "717                       78.050           992.150                NaN   \n",
       "718                       81.750           992.525                NaN   \n",
       "719                       83.000           992.825                NaN   \n",
       "\n",
       "     snow_depth:cm  snow_drift:idx  snow_melt_10min:mm  snow_water:kgm2  \\\n",
       "0              0.0             0.0                 0.0              0.0   \n",
       "1              0.0             0.0                 0.0              0.0   \n",
       "2              0.0             0.0                 0.0              0.0   \n",
       "3              0.0             0.0                 0.0              0.0   \n",
       "4              0.0             0.0                 0.0              0.0   \n",
       "..             ...             ...                 ...              ...   \n",
       "715            0.0             0.0                 0.0              0.0   \n",
       "716            0.0             0.0                 0.0              0.0   \n",
       "717            0.0             0.0                 0.0              0.0   \n",
       "718            0.0             0.0                 0.0              0.0   \n",
       "719            0.0             0.0                 0.0              0.0   \n",
       "\n",
       "     sun_azimuth:d  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "0         16.02650        -10.54100                           0.000   \n",
       "1         30.49725         -7.89450                           0.000   \n",
       "2         44.51725         -3.81550                           0.000   \n",
       "3         58.08300          1.41250                           0.000   \n",
       "4         71.34100          7.46850                           0.000   \n",
       "..             ...              ...                             ...   \n",
       "715      306.68700          8.15300                           0.100   \n",
       "716      319.70400          3.26800                           0.000   \n",
       "717      333.04000         -0.44325                           0.000   \n",
       "718      346.68600         -2.75050                           0.075   \n",
       "719      180.51850         -3.49750                           0.125   \n",
       "\n",
       "     t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0      273.80000               74.950     29907.500              3.950   \n",
       "1      273.80000               77.475     29519.074              3.825   \n",
       "2      273.84998               88.100     31009.125              3.650   \n",
       "3      273.90000               68.600     34552.500              3.500   \n",
       "4      273.92500               66.300     35483.875              3.325   \n",
       "..           ...                  ...           ...                ...   \n",
       "715    287.02500               86.150     44056.375              2.450   \n",
       "716    286.60000               75.325     44017.176              2.450   \n",
       "717    286.10000               76.850     43302.050              2.575   \n",
       "718    285.55000               98.325     40505.850              2.250   \n",
       "719    285.25000              100.000     39665.523              1.975   \n",
       "\n",
       "     wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  year  \\\n",
       "0                  2.100                3.350                      0.0  2023   \n",
       "1                  1.925                3.300                      0.0  2023   \n",
       "2                  1.750                3.200                      0.0  2023   \n",
       "3                  1.450                3.150                      0.0  2023   \n",
       "4                  1.300                3.050                      0.0  2023   \n",
       "..                   ...                  ...                      ...   ...   \n",
       "715                2.075               -1.350                      0.0  2023   \n",
       "716                2.100               -1.250                      0.0  2023   \n",
       "717                2.150               -1.400                      0.0  2023   \n",
       "718                1.800               -1.350                      0.0  2023   \n",
       "719                1.600               -1.175                      0.0  2023   \n",
       "\n",
       "     month  day  hour  estimated  \n",
       "0        5    1     0          1  \n",
       "1        5    1     1          1  \n",
       "2        5    1     2          1  \n",
       "3        5    1     3          1  \n",
       "4        5    1     4          1  \n",
       "..     ...  ...   ...        ...  \n",
       "715      7    3    19          1  \n",
       "716      7    3    20          1  \n",
       "717      7    3    21          1  \n",
       "718      7    3    22          1  \n",
       "719      7    3    23          1  \n",
       "\n",
       "[720 rows x 50 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ff8e1b7-a98d-446a-9112-0d4e3c1f88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_a = model_a.predict(x_test_a)\n",
    "pred_b = model_b.predict(x_test_b)\n",
    "pred_c = model_c.predict(x_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "281e39d8-69f2-47db-adae-b84f43511964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub(pred_a,pred_b,pred_c):\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    submission['prediction'] = np.concatenate([pred_a,pred_b,pred_c])\n",
    "    submission.loc[submission['prediction'] < 0, 'prediction'] = 0\n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d225154d-bfaf-46a9-93c5-6418185ab709",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = create_sub(pred_a,pred_b,pred_c)\n",
    "sub.to_csv(f'Submissions/fifthCatboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def build_model(X_train,y_train,location):\n",
    "    \n",
    "    merged_data = X_train.copy()\n",
    "    merged_data['pv_measurement'] = y_train['pv_measurement'].values\n",
    "    \n",
    "    y = 'pv_measurement'\n",
    "    x = list(X_train.columns)\n",
    "    train = h2o.H2OFrame(merged_data)\n",
    "    \n",
    "    aml = H2OAutoML(\n",
    "        max_models = 10,\n",
    "        max_runtime_secs = 60,\n",
    "        exclude_algos =['DeepLearning'],\n",
    "        seed = 1,\n",
    "        # stopping_metric ='logloss',\n",
    "        sort_metric ='mae',\n",
    "        balance_classes = False,\n",
    "        project_name = location\n",
    "    )\n",
    "\n",
    "    aml.train(x=x, y=y, training_frame=train)\n",
    "    \n",
    "    lb = aml.leaderboard\n",
    "    leader = aml.leader\n",
    "    print(lb.head(rows=lb.nrows))\n",
    "    \n",
    "    h2o.save_model(leader, path=f'Saved_models/{location.upper()}', force = True)\n",
    "\n",
    "    return lb,leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_a,model_a = build_model(x_train_a,train_a,'A')\n",
    "lb_b,model_b = build_model(x_train_b,train_b,'B')\n",
    "lb_c,model_c = build_model(x_train_c,train_c,'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model_a.predict(h2o.H2OFrame(x_test_a))\n",
    "preds_b = model_b.predict(h2o.H2OFrame(x_test_b))\n",
    "preds_c = model_c.predict(h2o.H2OFrame(x_test_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_first = h2o.load_model('Saved_models/A/GBM_4_AutoML_1_20231020_170352')\n",
    "model_b_first = h2o.load_model('Saved_models/B/GBM_8_AutoML_2_20231020_170654')\n",
    "model_c_first = h2o.load_model('Saved_models/C/GBM_8_AutoML_2_20231020_170654')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a_original = model_a_first.predict(h2o.H2OFrame(X_test_a))\n",
    "preds_b_original = model_b_first.predict(h2o.H2OFrame(X_test_b))\n",
    "preds_c_original = model_c_first.predict(h2o.H2OFrame(X_test_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf40fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_preds(pred1,pred2):\n",
    "    pred1 = preds_a_original.as_data_frame()\n",
    "    pred2 = preds_a2.as_data_frame()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Scatter plot\n",
    "    plt.scatter(y_pred1['predict'], y_pred2['predict'], alpha=0.5)\n",
    "\n",
    "    # Line of equality (for reference)\n",
    "    plt.plot([y_pred1['predict'].min(), y_pred1['predict'].max()],\n",
    "             [y_pred2['predict'].min(), y_pred2['predict'].max()],\n",
    "             color='red', linestyle='--')\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Predictions from First Model')\n",
    "    plt.ylabel('Predictions from New model')\n",
    "    plt.title('Comparison of Predictions from Two Models')\n",
    "\n",
    "    # Show plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_two_preds(preds_a,preds_a_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cf15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Importance\n",
    "def feat_importance(model, n_feats):\n",
    "    feature_importance = model.varimp(use_pandas=True)\n",
    "    n_top_feats = feature_importance.iloc[:n_feats,:]\n",
    "    return n_top_feats\n",
    "\n",
    "print(feat_importance(model_a, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(preds):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    predictions= preds['predict'].as_data_frame()\n",
    "    predictions['time'] = test['time'].unique()\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Prediction', color='tab:blue')\n",
    "    ax1.plot(predictions['time'], predictions['predict'], color='tab:blue', label='Solar Power Production')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'Time Series Plot of prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48550864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(preds_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0562ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(preds_c_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub(preds_a,preds_b,preds_c):\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    predictions = preds_a.rbind(preds_b).rbind(preds_c)\n",
    "    predictions_df = predictions['predict'].as_data_frame()\n",
    "    predictions_df.loc[predictions_df['predict'] < 0, 'predict'] = 0\n",
    "    submission['prediction'] = predictions_df['predict']\n",
    "    return submission \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = create_sub(preds_a,preds_b,preds_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1.to_csv(f'Submissions/removedOutliersNight.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd01df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"\"\"# Plot the distribution of \"direct_rad:W\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['direct_rad:W'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"direct_rad:W\"')\n",
    "    plt.xlabel('Direct Radiation (W)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['clear_sky_rad:W'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"clear_sky_rad:W\"')\n",
    "    plt.xlabel('Direct Radiation (W)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['direct_rad_1h:J'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"direct_rad_1h:J\"')\n",
    "    plt.xlabel('Radiation 1h(J)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(merged_data['clear_sky_energy_1h:J'], bins=50, kde=True)\n",
    "    plt.title('Distribution of \"clear_sky_energy_1h:J\"')\n",
    "    plt.xlabel('Radiation 1h(J)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
