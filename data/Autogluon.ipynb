{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9a774-8fc5-42c4-bcd5-c038740e4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c788fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6686ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a = pd.read_csv('cleaned_data/A/x_train_a.csv')\n",
    "x_train_b = pd.read_csv('cleaned_data/B/x_train_b.csv')\n",
    "x_train_c = pd.read_csv('cleaned_data/C/x_train_c.csv')\n",
    "\n",
    "x_test_a = pd.read_csv('cleaned_data/A/x_test_a.csv')\n",
    "x_test_b = pd.read_csv('cleaned_data/B/x_test_b.csv')\n",
    "x_test_c = pd.read_csv('cleaned_data/C/x_test_c.csv')\n",
    "\n",
    "train_a = pd.read_csv('cleaned_data/A/train_a.csv')\n",
    "train_b = pd.read_csv('cleaned_data/B/train_b.csv')\n",
    "train_c = pd.read_csv('cleaned_data/C/train_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d43bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a['time'] = pd.to_datetime(train_a['time'])\n",
    "train_b['time'] = pd.to_datetime(train_b['time'])\n",
    "train_c['time'] = pd.to_datetime(train_c['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd9be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a = x_test_a.drop(columns = ['date_forecast'])\n",
    "x_test_b = x_test_b.drop(columns = ['date_forecast'])\n",
    "x_test_c = x_test_c.drop(columns = ['date_forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5110836d-15df-41c6-8ae5-c95a38d4e954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>elevation:m</th>\n",
       "      <th>fresh_snow_12h:cm</th>\n",
       "      <th>fresh_snow_1h:cm</th>\n",
       "      <th>fresh_snow_24h:cm</th>\n",
       "      <th>fresh_snow_3h:cm</th>\n",
       "      <th>fresh_snow_6h:cm</th>\n",
       "      <th>is_day:idx</th>\n",
       "      <th>is_in_shadow:idx</th>\n",
       "      <th>msl_pressure:hPa</th>\n",
       "      <th>precip_5min:mm</th>\n",
       "      <th>precip_type_5min:idx</th>\n",
       "      <th>pressure_100m:hPa</th>\n",
       "      <th>pressure_50m:hPa</th>\n",
       "      <th>prob_rime:p</th>\n",
       "      <th>rain_water:kgm2</th>\n",
       "      <th>relative_humidity_1000hPa:p</th>\n",
       "      <th>sfc_pressure:hPa</th>\n",
       "      <th>snow_density:kgm3</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>snow_drift:idx</th>\n",
       "      <th>snow_melt_10min:mm</th>\n",
       "      <th>snow_water:kgm2</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-02 22:00:00</td>\n",
       "      <td>7.700</td>\n",
       "      <td>1.22825</td>\n",
       "      <td>1728.950</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1728.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.075</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1006.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>993.75000</td>\n",
       "      <td>999.77500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>71.674995</td>\n",
       "      <td>1005.80000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175</td>\n",
       "      <td>348.03674</td>\n",
       "      <td>-3.77425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>286.22500</td>\n",
       "      <td>100.000</td>\n",
       "      <td>40386.477</td>\n",
       "      <td>3.600</td>\n",
       "      <td>-3.575</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-02 23:00:00</td>\n",
       "      <td>7.700</td>\n",
       "      <td>1.22350</td>\n",
       "      <td>1689.825</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1689.825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.750</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1005.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>992.67500</td>\n",
       "      <td>998.65000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1004.65000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>91.98075</td>\n",
       "      <td>-4.35725</td>\n",
       "      <td>0.000</td>\n",
       "      <td>286.90000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>33770.650</td>\n",
       "      <td>3.350</td>\n",
       "      <td>-3.350</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-03 00:00:00</td>\n",
       "      <td>7.875</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1563.225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1563.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1004.525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>992.00000</td>\n",
       "      <td>997.97500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>67.950000</td>\n",
       "      <td>1003.95000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>14.93475</td>\n",
       "      <td>-3.30950</td>\n",
       "      <td>0.000</td>\n",
       "      <td>286.95000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>13595.500</td>\n",
       "      <td>3.050</td>\n",
       "      <td>-2.950</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-03 01:00:00</td>\n",
       "      <td>8.425</td>\n",
       "      <td>1.21800</td>\n",
       "      <td>1283.425</td>\n",
       "      <td>208.650</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1283.425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.675</td>\n",
       "      <td>0.300</td>\n",
       "      <td>526.775</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1004.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>991.50000</td>\n",
       "      <td>997.44995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>1003.44995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>28.63025</td>\n",
       "      <td>-0.82250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>286.75000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2321.850</td>\n",
       "      <td>2.725</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-03 02:00:00</td>\n",
       "      <td>8.950</td>\n",
       "      <td>1.21800</td>\n",
       "      <td>1003.500</td>\n",
       "      <td>32468.150</td>\n",
       "      <td>23.100</td>\n",
       "      <td>1003.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.500</td>\n",
       "      <td>11.975</td>\n",
       "      <td>22068.950</td>\n",
       "      <td>0.15</td>\n",
       "      <td>282.975</td>\n",
       "      <td>84.875</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1003.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990.55005</td>\n",
       "      <td>996.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>79.925000</td>\n",
       "      <td>1002.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>41.99750</td>\n",
       "      <td>3.05125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>286.45000</td>\n",
       "      <td>99.225</td>\n",
       "      <td>11634.800</td>\n",
       "      <td>2.550</td>\n",
       "      <td>-2.350</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34080</th>\n",
       "      <td>2023-04-30 19:00:00</td>\n",
       "      <td>4.550</td>\n",
       "      <td>1.27650</td>\n",
       "      <td>1674.200</td>\n",
       "      <td>84464.945</td>\n",
       "      <td>4.225</td>\n",
       "      <td>542.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.425</td>\n",
       "      <td>2.825</td>\n",
       "      <td>56431.050</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13230.649</td>\n",
       "      <td>96.700</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1014.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.57495</td>\n",
       "      <td>1007.80000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>74.625000</td>\n",
       "      <td>1014.05000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>304.93924</td>\n",
       "      <td>-0.18050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>275.02500</td>\n",
       "      <td>96.700</td>\n",
       "      <td>23417.074</td>\n",
       "      <td>5.175</td>\n",
       "      <td>4.800</td>\n",
       "      <td>1.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34081</th>\n",
       "      <td>2023-04-30 20:00:00</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.27975</td>\n",
       "      <td>1762.400</td>\n",
       "      <td>2270.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>546.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5067.875</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176.350</td>\n",
       "      <td>94.225</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.55000</td>\n",
       "      <td>1007.80000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>76.875000</td>\n",
       "      <td>1014.05000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>318.62576</td>\n",
       "      <td>-5.17600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>274.65002</td>\n",
       "      <td>94.525</td>\n",
       "      <td>21084.050</td>\n",
       "      <td>4.650</td>\n",
       "      <td>4.025</td>\n",
       "      <td>2.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34082</th>\n",
       "      <td>2023-04-30 21:00:00</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.28100</td>\n",
       "      <td>1696.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>548.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>94.325</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.40000</td>\n",
       "      <td>1007.67500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>77.775000</td>\n",
       "      <td>1013.92505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>332.78574</td>\n",
       "      <td>-8.95075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>274.52500</td>\n",
       "      <td>95.675</td>\n",
       "      <td>20792.500</td>\n",
       "      <td>4.450</td>\n",
       "      <td>3.575</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34083</th>\n",
       "      <td>2023-04-30 22:00:00</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.28100</td>\n",
       "      <td>1353.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>527.775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97.775</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.25000</td>\n",
       "      <td>1007.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1013.80000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>347.37800</td>\n",
       "      <td>-11.23325</td>\n",
       "      <td>0.100</td>\n",
       "      <td>274.32500</td>\n",
       "      <td>98.875</td>\n",
       "      <td>14158.100</td>\n",
       "      <td>4.100</td>\n",
       "      <td>3.175</td>\n",
       "      <td>2.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34084</th>\n",
       "      <td>2023-04-30 23:00:00</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.28100</td>\n",
       "      <td>1626.575</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>526.525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.425</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.87500</td>\n",
       "      <td>1007.10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>79.850000</td>\n",
       "      <td>1013.40000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>92.20950</td>\n",
       "      <td>-11.84150</td>\n",
       "      <td>0.075</td>\n",
       "      <td>274.22500</td>\n",
       "      <td>99.700</td>\n",
       "      <td>11872.300</td>\n",
       "      <td>3.750</td>\n",
       "      <td>2.725</td>\n",
       "      <td>2.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34085 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "0      2019-06-02 22:00:00                     7.700              1.22825   \n",
       "1      2019-06-02 23:00:00                     7.700              1.22350   \n",
       "2      2019-06-03 00:00:00                     7.875              1.21975   \n",
       "3      2019-06-03 01:00:00                     8.425              1.21800   \n",
       "4      2019-06-03 02:00:00                     8.950              1.21800   \n",
       "...                    ...                       ...                  ...   \n",
       "34080  2023-04-30 19:00:00                     4.550              1.27650   \n",
       "34081  2023-04-30 20:00:00                     4.500              1.27975   \n",
       "34082  2023-04-30 21:00:00                     4.500              1.28100   \n",
       "34083  2023-04-30 22:00:00                     4.500              1.28100   \n",
       "34084  2023-04-30 23:00:00                     4.500              1.28100   \n",
       "\n",
       "       ceiling_height_agl:m  clear_sky_energy_1h:J  clear_sky_rad:W  \\\n",
       "0                  1728.950                  0.000            0.000   \n",
       "1                  1689.825                  0.000            0.000   \n",
       "2                  1563.225                  0.000            0.000   \n",
       "3                  1283.425                208.650            0.750   \n",
       "4                  1003.500              32468.150           23.100   \n",
       "...                     ...                    ...              ...   \n",
       "34080              1674.200              84464.945            4.225   \n",
       "34081              1762.400               2270.875            0.000   \n",
       "34082              1696.650                  0.000            0.000   \n",
       "34083              1353.400                  0.000            0.000   \n",
       "34084              1626.575                  0.000            0.000   \n",
       "\n",
       "       cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  \\\n",
       "0              1728.950              0.0         280.300          0.000   \n",
       "1              1689.825              0.0         280.300          0.000   \n",
       "2              1563.225              0.0         280.650          0.000   \n",
       "3              1283.425              0.0         281.675          0.300   \n",
       "4              1003.500              0.0         282.500         11.975   \n",
       "...                 ...              ...             ...            ...   \n",
       "34080           542.700              0.0         272.425          2.825   \n",
       "34081           546.400              0.0         272.300          0.000   \n",
       "34082           548.350              0.0         272.300          0.000   \n",
       "34083           527.775              0.0         272.300          0.000   \n",
       "34084           526.525              0.0         272.275          0.000   \n",
       "\n",
       "       diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  \\\n",
       "0                 0.000          0.00            0.000   \n",
       "1                 0.000          0.00            0.000   \n",
       "2                 0.000          0.00            0.000   \n",
       "3               526.775          0.00            0.000   \n",
       "4             22068.950          0.15          282.975   \n",
       "...                 ...           ...              ...   \n",
       "34080         56431.050          0.10        13230.649   \n",
       "34081          5067.875          0.00          176.350   \n",
       "34082             0.000          0.00            0.000   \n",
       "34083             0.000          0.00            0.000   \n",
       "34084             0.000          0.00            0.000   \n",
       "\n",
       "       effective_cloud_cover:p  elevation:m  fresh_snow_12h:cm  \\\n",
       "0                       99.075          6.0                0.0   \n",
       "1                       99.750          6.0                0.0   \n",
       "2                      100.000          6.0                0.0   \n",
       "3                      100.000          6.0                0.0   \n",
       "4                       84.875          6.0                0.0   \n",
       "...                        ...          ...                ...   \n",
       "34080                   96.700          6.0                0.0   \n",
       "34081                   94.225          6.0                0.0   \n",
       "34082                   94.325          6.0                0.0   \n",
       "34083                   97.775          6.0                0.0   \n",
       "34084                   98.425          6.0                0.0   \n",
       "\n",
       "       fresh_snow_1h:cm  fresh_snow_24h:cm  fresh_snow_3h:cm  \\\n",
       "0                   0.0                0.0               0.0   \n",
       "1                   0.0                0.0               0.0   \n",
       "2                   0.0                0.0               0.0   \n",
       "3                   0.0                0.0               0.0   \n",
       "4                   0.0                0.0               0.0   \n",
       "...                 ...                ...               ...   \n",
       "34080               0.0                0.0               0.0   \n",
       "34081               0.0                0.0               0.0   \n",
       "34082               0.0                0.0               0.0   \n",
       "34083               0.0                0.0               0.0   \n",
       "34084               0.0                0.0               0.0   \n",
       "\n",
       "       fresh_snow_6h:cm  is_day:idx  is_in_shadow:idx  msl_pressure:hPa  \\\n",
       "0                   0.0        0.00              1.00          1006.300   \n",
       "1                   0.0        0.00              1.00          1005.200   \n",
       "2                   0.0        0.00              1.00          1004.525   \n",
       "3                   0.0        0.25              1.00          1004.025   \n",
       "4                   0.0        1.00              0.00          1003.100   \n",
       "...                 ...         ...               ...               ...   \n",
       "34080               0.0        0.50              0.75          1014.750   \n",
       "34081               0.0        0.00              1.00          1014.700   \n",
       "34082               0.0        0.00              1.00          1014.550   \n",
       "34083               0.0        0.00              1.00          1014.400   \n",
       "34084               0.0        0.00              1.00          1014.050   \n",
       "\n",
       "       precip_5min:mm  precip_type_5min:idx  pressure_100m:hPa  \\\n",
       "0                 0.0                   0.0          993.75000   \n",
       "1                 0.0                   0.0          992.67500   \n",
       "2                 0.0                   0.0          992.00000   \n",
       "3                 0.0                   0.0          991.50000   \n",
       "4                 0.0                   0.0          990.55005   \n",
       "...               ...                   ...                ...   \n",
       "34080             0.0                   0.0         1001.57495   \n",
       "34081             0.0                   0.0         1001.55000   \n",
       "34082             0.0                   0.0         1001.40000   \n",
       "34083             0.0                   0.0         1001.25000   \n",
       "34084             0.0                   0.0         1000.87500   \n",
       "\n",
       "       pressure_50m:hPa  prob_rime:p  rain_water:kgm2  \\\n",
       "0             999.77500          0.0            0.000   \n",
       "1             998.65000          0.0            0.025   \n",
       "2             997.97500          0.0            0.100   \n",
       "3             997.44995          0.0            0.125   \n",
       "4             996.50000          0.0            0.100   \n",
       "...                 ...          ...              ...   \n",
       "34080        1007.80000          0.0            0.000   \n",
       "34081        1007.80000          0.0            0.000   \n",
       "34082        1007.67500          0.0            0.000   \n",
       "34083        1007.50000          0.0            0.000   \n",
       "34084        1007.10000          0.0            0.000   \n",
       "\n",
       "       relative_humidity_1000hPa:p  sfc_pressure:hPa  snow_density:kgm3  \\\n",
       "0                        71.674995        1005.80000                NaN   \n",
       "1                        68.000000        1004.65000                NaN   \n",
       "2                        67.950000        1003.95000                NaN   \n",
       "3                        73.875000        1003.44995                NaN   \n",
       "4                        79.925000        1002.50000                NaN   \n",
       "...                            ...               ...                ...   \n",
       "34080                    74.625000        1014.05000                NaN   \n",
       "34081                    76.875000        1014.05000                NaN   \n",
       "34082                    77.775000        1013.92505                NaN   \n",
       "34083                    79.000000        1013.80000                NaN   \n",
       "34084                    79.850000        1013.40000                NaN   \n",
       "\n",
       "       snow_depth:cm  snow_drift:idx  snow_melt_10min:mm  snow_water:kgm2  \\\n",
       "0                0.0             0.0                 0.0            0.175   \n",
       "1                0.0             0.0                 0.0            0.200   \n",
       "2                0.0             0.0                 0.0            0.400   \n",
       "3                0.0             0.0                 0.0            0.550   \n",
       "4                0.0             0.0                 0.0            0.250   \n",
       "...              ...             ...                 ...              ...   \n",
       "34080            0.0             0.0                 0.0            0.000   \n",
       "34081            0.0             0.0                 0.0            0.000   \n",
       "34082            0.0             0.0                 0.0            0.000   \n",
       "34083            0.0             0.0                 0.0            0.025   \n",
       "34084            0.0             0.0                 0.0            0.050   \n",
       "\n",
       "       sun_azimuth:d  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "0          348.03674         -3.77425                           0.000   \n",
       "1           91.98075         -4.35725                           0.000   \n",
       "2           14.93475         -3.30950                           0.000   \n",
       "3           28.63025         -0.82250                           0.000   \n",
       "4           41.99750          3.05125                           0.000   \n",
       "...              ...              ...                             ...   \n",
       "34080      304.93924         -0.18050                           0.000   \n",
       "34081      318.62576         -5.17600                           0.000   \n",
       "34082      332.78574         -8.95075                           0.000   \n",
       "34083      347.37800        -11.23325                           0.100   \n",
       "34084       92.20950        -11.84150                           0.075   \n",
       "\n",
       "       t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0        286.22500              100.000     40386.477              3.600   \n",
       "1        286.90000              100.000     33770.650              3.350   \n",
       "2        286.95000              100.000     13595.500              3.050   \n",
       "3        286.75000              100.000      2321.850              2.725   \n",
       "4        286.45000               99.225     11634.800              2.550   \n",
       "...            ...                  ...           ...                ...   \n",
       "34080    275.02500               96.700     23417.074              5.175   \n",
       "34081    274.65002               94.525     21084.050              4.650   \n",
       "34082    274.52500               95.675     20792.500              4.450   \n",
       "34083    274.32500               98.875     14158.100              4.100   \n",
       "34084    274.22500               99.700     11872.300              3.750   \n",
       "\n",
       "       wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \\\n",
       "0                   -3.575               -0.500                      0.0   \n",
       "1                   -3.350                0.275                      0.0   \n",
       "2                   -2.950                0.750                      0.0   \n",
       "3                   -2.600                0.875                      0.0   \n",
       "4                   -2.350                0.925                      0.0   \n",
       "...                    ...                  ...                      ...   \n",
       "34080                4.800                1.925                      0.0   \n",
       "34081                4.025                2.300                      0.0   \n",
       "34082                3.575                2.600                      0.0   \n",
       "34083                3.175                2.550                      0.0   \n",
       "34084                2.725                2.550                      0.0   \n",
       "\n",
       "       year  month  day  hour  estimated  \n",
       "0      2019      6    2    22          0  \n",
       "1      2019      6    2    23          0  \n",
       "2      2019      6    3     0          0  \n",
       "3      2019      6    3     1          0  \n",
       "4      2019      6    3     2          0  \n",
       "...     ...    ...  ...   ...        ...  \n",
       "34080  2023      4   30    19          1  \n",
       "34081  2023      4   30    20          1  \n",
       "34082  2023      4   30    21          1  \n",
       "34083  2023      4   30    22          1  \n",
       "34084  2023      4   30    23          1  \n",
       "\n",
       "[34085 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e17787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in X_train that has timestamp that does not exist in train_loc, and visa_verca\n",
    "#e.g missing solar power measurements from 2022-10-21 01:00 - 2022-10-28 21:00\n",
    "def align_X_y(x_train,y_train, x_date_column='date_forecast', y_date_column='time'):\n",
    "    \"\"\"\n",
    "    Aligns two dataframes based on the 'date_forecast' column of X and the 'time' column of y,\n",
    "    ensuring that only rows with matching time values are retained.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): The first dataframe with time in the 'date_forecast'\n",
    "    - y (pd.DataFrame): The second dataframe with time in the 'time' column.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the aligned dataframes.\n",
    "    \"\"\"\n",
    "    # Convert date columns to datetime format for easier comparison\n",
    "    x_train[x_date_column] = pd.to_datetime(x_train[x_date_column])\n",
    "    y_train[y_date_column] = pd.to_datetime(y_train[y_date_column])\n",
    "    \n",
    "    # Find common dates\n",
    "    common_dates = x_train[x_date_column][x_train[x_date_column].isin(y_train[y_date_column])]\n",
    "    \n",
    "    # Filter both datasets based on common dates\n",
    "    x_train_synced = x_train[x_train[x_date_column].isin(common_dates)]\n",
    "    y_train_synced = y_train[y_train[y_date_column].isin(common_dates)]\n",
    "    \n",
    "    return x_train_synced, y_train_synced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1a15d",
   "metadata": {},
   "source": [
    "# Analysis of Target variable  - Looking at PV_measurement\n",
    "1. Handle constant measurments over longer periods of time. Likely caused by sensor malfunction, data logging issues, or other external factors.\n",
    "    - Handeled by removing all constant values lasting more than 24 hours \n",
    "2. Add cyclical features \n",
    "2. Handle longer periods of missing data:\n",
    "    - Remove (currently tested)\n",
    "    - Interpolate \n",
    "    - Copy from previous year\n",
    "    - Copy solar production at missing time from another location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89446f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Handle constant PV measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5db23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series plot of PV_measurement \n",
    "\n",
    "def solar_prod_plot(y_train, resolution='year', chunks=5):\n",
    "    df = y_train.copy()\n",
    "    \n",
    "    # Determine the plotting resolution based on the 'resolution' argument\n",
    "    # Chunks = number of year/months/days in each plot\n",
    "    if resolution == 'year':\n",
    "        unique_values = df['time'].dt.year.unique()\n",
    "        label = 'Year'\n",
    "    elif resolution == 'month':\n",
    "        df['year_month'] = df['time'].dt.to_period('M')\n",
    "        unique_values = df['year_month'].unique()\n",
    "        label = 'Month'\n",
    "    elif resolution == 'week':\n",
    "        df['year_week'] = df['time'].dt.to_period('W')\n",
    "        unique_values = df['year_week'].unique()\n",
    "        label = 'Week'\n",
    "    elif resolution == 'day':\n",
    "        df['date'] = df['time'].dt.date\n",
    "        unique_values = df['date'].unique()\n",
    "        label = 'Day'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid resolution. Choose from 'year', 'month', 'week', or 'day'.\")\n",
    "    \n",
    "    # Loop over the unique values in chunks\n",
    "    for i in range(0, len(unique_values), chunks):\n",
    "        subset_values = unique_values[i:i+chunks]\n",
    "        \n",
    "        if resolution == 'year':\n",
    "            subset_df = df[df['time'].dt.year.isin(subset_values)]\n",
    "        elif resolution == 'month':\n",
    "            subset_df = df[df['year_month'].isin(subset_values)]\n",
    "        elif resolution == 'week':\n",
    "            subset_df = df[df['year_week'].isin(subset_values)]\n",
    "        elif resolution == 'day':\n",
    "            subset_df = df[df['date'].isin(subset_values)]\n",
    "        \n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(subset_df['time'], subset_df['pv_measurement'])\n",
    "\n",
    "        title = f\"Solar Power Production for {label}: {subset_values[0]}\"\n",
    "        if len(subset_values) > 1:\n",
    "            title += f\" to {subset_values[-1]}\"\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"PV Measurement\")\n",
    "        plt.show()\n",
    "\n",
    "def remove_constant_intervals(y_train, low_thresh, upp_thresh):\n",
    "    \"\"\"\n",
    "    Identify and remove intervals of constant PV readings that exceed a specified duration. \n",
    "    Constant readings may indicate sensor malfunctions or data logging issues.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_train : pd.DataFrame\n",
    "        Dataframe containing the time-series data of solar power production.\n",
    "    threshold : int\n",
    "        The minimum duration required for an interval to be considered for removal.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The input dataframe with intervals of constant readings (exceeding the duration threshold) removed.\n",
    "    \"\"\"\n",
    "    df = y_train.copy()\n",
    "    \n",
    "    # Calculate the difference in production values\n",
    "    df['diff'] = df['pv_measurement'].diff()\n",
    "\n",
    "    # Identify where the difference is zero\n",
    "    df['zero_diff'] = df['diff'].abs() < 1e-5\n",
    "\n",
    "    # Identify groups of consecutive zero differences\n",
    "    df['group'] = (df['zero_diff'] != df['zero_diff'].shift()).cumsum()\n",
    "\n",
    "    # Filter out only the groups with consecutive zero differences\n",
    "    constant_intervals = df[df['zero_diff']].groupby('group').agg(start=('time', 'min'), \n",
    "                                                                  end=('time', 'max'),\n",
    "                                                                  duration=('time', 'size'))\n",
    "    \n",
    "    # Filter intervals based on the threshold\n",
    "    interval_df_thresh = constant_intervals[(constant_intervals['duration'] > low_thresh) & (constant_intervals['duration'] <upp_thresh)]\n",
    "    \n",
    "    # Remove rows from the main dataframe that fall within these intervals\n",
    "    for _, row in interval_df_thresh.iterrows():\n",
    "        start_time, end_time = row['start'], row['end']\n",
    "        df = df[(df['time'] < start_time) | (df['time'] > end_time)]\n",
    "    \n",
    "    # Drop the added columns used for calculations\n",
    "    df.drop(columns=['diff', 'zero_diff', 'group'], inplace=True)\n",
    "    \n",
    "    return df, constant_intervals\n",
    "\n",
    "\n",
    "def get_time_interval(df, start_time = '2020-08-01 00:00:00', end_time = '2021-01-01 00:00:00'):\n",
    "    # Filter rows based on the time period\n",
    "    filtered_df = df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e1af31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed all constant values with duration > 24 hours\n",
    "\n",
    "train_a, const_interval_a = remove_constant_intervals(train_a,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_a, train_a = align_X_y(x_train_a, train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a90e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2020-01-04 15:00:00</td>\n",
       "      <td>2020-01-06 08:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "434   2020-01-04 15:00:00 2020-01-06 08:00:00        42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed_a = np.sum(const_interval_a[const_interval_a['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed_a}')\n",
    "const_interval_a[const_interval_a['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d4bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in groups of constant values, where duration of constant measurements is > 1 day (24 hours)\n",
    "train_b, const_interval_b = remove_constant_intervals(train_b,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_b, train_b = align_X_y(x_train_b, train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd0cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 6865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-01-14 15:00:00</td>\n",
       "      <td>2019-01-18 11:00:00</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-01-19 13:00:00</td>\n",
       "      <td>2019-01-26 08:00:00</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-01-27 11:00:00</td>\n",
       "      <td>2019-01-28 13:00:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2019-02-10 16:00:00</td>\n",
       "      <td>2019-02-13 07:00:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-03-23 18:00:00</td>\n",
       "      <td>2019-03-26 06:00:00</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2019-05-31 08:00:00</td>\n",
       "      <td>2019-06-03 12:00:00</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2019-10-28 14:00:00</td>\n",
       "      <td>2019-10-30 22:00:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2019-12-01 13:00:00</td>\n",
       "      <td>2019-12-04 08:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>2019-12-07 14:00:00</td>\n",
       "      <td>2019-12-11 08:00:00</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2019-12-18 14:00:00</td>\n",
       "      <td>2019-12-20 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>2019-12-25 14:00:00</td>\n",
       "      <td>2019-12-30 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2020-01-02 14:00:00</td>\n",
       "      <td>2020-01-04 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2020-01-04 14:00:00</td>\n",
       "      <td>2020-01-06 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2020-01-24 12:00:00</td>\n",
       "      <td>2020-01-26 08:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2020-02-05 14:00:00</td>\n",
       "      <td>2020-02-07 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2020-02-23 17:00:00</td>\n",
       "      <td>2020-02-25 09:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>2020-03-26 14:00:00</td>\n",
       "      <td>2020-03-27 21:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2020-04-02 02:00:00</td>\n",
       "      <td>2020-04-16 06:00:00</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2020-07-12 21:00:00</td>\n",
       "      <td>2020-08-25 21:00:00</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2020-09-24 13:00:00</td>\n",
       "      <td>2020-09-25 21:00:00</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>2020-12-16 14:00:00</td>\n",
       "      <td>2020-12-18 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>2020-12-26 14:00:00</td>\n",
       "      <td>2020-12-28 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>2021-01-09 14:00:00</td>\n",
       "      <td>2021-01-13 09:00:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2021-01-19 13:00:00</td>\n",
       "      <td>2021-01-21 09:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>2021-01-22 16:00:00</td>\n",
       "      <td>2021-01-24 08:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>2021-01-28 16:00:00</td>\n",
       "      <td>2021-01-30 08:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>2021-01-30 14:00:00</td>\n",
       "      <td>2021-02-01 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>2021-02-01 11:00:00</td>\n",
       "      <td>2021-02-03 08:00:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2021-02-18 00:00:00</td>\n",
       "      <td>2021-03-08 14:00:00</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2021-03-08 16:00:00</td>\n",
       "      <td>2021-04-19 11:00:00</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>2021-04-28 23:00:00</td>\n",
       "      <td>2021-05-01 21:00:00</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>2021-06-05 02:00:00</td>\n",
       "      <td>2021-06-07 07:00:00</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2021-06-13 02:00:00</td>\n",
       "      <td>2021-06-14 09:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>2021-06-22 02:00:00</td>\n",
       "      <td>2021-06-24 08:00:00</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2021-07-03 13:00:00</td>\n",
       "      <td>2021-07-06 05:00:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2021-08-25 23:00:00</td>\n",
       "      <td>2021-09-03 21:00:00</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>2021-09-08 13:00:00</td>\n",
       "      <td>2021-09-14 13:00:00</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2021-09-19 00:00:00</td>\n",
       "      <td>2021-09-27 08:00:00</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>2021-11-22 15:00:00</td>\n",
       "      <td>2021-11-24 08:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>2021-11-26 12:00:00</td>\n",
       "      <td>2021-12-04 08:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>2021-12-16 14:00:00</td>\n",
       "      <td>2021-12-18 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2021-12-21 14:00:00</td>\n",
       "      <td>2021-12-24 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2021-12-24 12:00:00</td>\n",
       "      <td>2022-01-03 09:00:00</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>2022-01-03 13:00:00</td>\n",
       "      <td>2022-01-11 09:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>2022-01-12 14:00:00</td>\n",
       "      <td>2022-01-14 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>2022-01-30 16:00:00</td>\n",
       "      <td>2022-02-04 09:00:00</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2022-02-10 15:00:00</td>\n",
       "      <td>2022-02-12 11:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>2022-02-14 16:00:00</td>\n",
       "      <td>2022-02-16 09:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2022-02-16 14:00:00</td>\n",
       "      <td>2022-02-18 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2022-02-19 10:00:00</td>\n",
       "      <td>2022-02-24 06:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2022-03-06 11:00:00</td>\n",
       "      <td>2022-03-07 11:00:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2022-03-19 14:00:00</td>\n",
       "      <td>2022-03-28 07:00:00</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2022-03-28 12:00:00</td>\n",
       "      <td>2022-04-05 06:00:00</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2023-01-15 15:00:00</td>\n",
       "      <td>2023-01-17 09:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "32    2019-01-14 15:00:00 2019-01-18 11:00:00        93\n",
       "36    2019-01-19 13:00:00 2019-01-26 08:00:00       164\n",
       "40    2019-01-27 11:00:00 2019-01-28 13:00:00        27\n",
       "74    2019-02-10 16:00:00 2019-02-13 07:00:00        64\n",
       "160   2019-03-23 18:00:00 2019-03-26 06:00:00        61\n",
       "302   2019-05-31 08:00:00 2019-06-03 12:00:00        77\n",
       "606   2019-10-28 14:00:00 2019-10-30 22:00:00        57\n",
       "674   2019-12-01 13:00:00 2019-12-04 08:00:00        68\n",
       "682   2019-12-07 14:00:00 2019-12-11 08:00:00        91\n",
       "700   2019-12-18 14:00:00 2019-12-20 09:00:00        44\n",
       "712   2019-12-25 14:00:00 2019-12-30 09:00:00       116\n",
       "724   2020-01-02 14:00:00 2020-01-04 08:00:00        43\n",
       "726   2020-01-04 14:00:00 2020-01-06 10:00:00        45\n",
       "768   2020-01-24 12:00:00 2020-01-26 08:00:00        45\n",
       "790   2020-02-05 14:00:00 2020-02-07 09:00:00        44\n",
       "824   2020-02-23 17:00:00 2020-02-25 09:00:00        41\n",
       "890   2020-03-26 14:00:00 2020-03-27 21:00:00        32\n",
       "906   2020-04-02 02:00:00 2020-04-16 06:00:00       341\n",
       "1090  2020-07-12 21:00:00 2020-08-25 21:00:00      1057\n",
       "1154  2020-09-24 13:00:00 2020-09-25 21:00:00        33\n",
       "1332  2020-12-16 14:00:00 2020-12-18 08:00:00        43\n",
       "1352  2020-12-26 14:00:00 2020-12-28 08:00:00        43\n",
       "1380  2021-01-09 14:00:00 2021-01-13 09:00:00        92\n",
       "1396  2021-01-19 13:00:00 2021-01-21 09:00:00        45\n",
       "1400  2021-01-22 16:00:00 2021-01-24 08:00:00        41\n",
       "1410  2021-01-28 16:00:00 2021-01-30 08:00:00        41\n",
       "1414  2021-01-30 14:00:00 2021-02-01 08:00:00        43\n",
       "1416  2021-02-01 11:00:00 2021-02-03 08:00:00        46\n",
       "1454  2021-02-18 00:00:00 2021-03-08 14:00:00       447\n",
       "1456  2021-03-08 16:00:00 2021-04-19 11:00:00      1003\n",
       "1478  2021-04-28 23:00:00 2021-05-01 21:00:00        71\n",
       "1550  2021-06-05 02:00:00 2021-06-07 07:00:00        54\n",
       "1564  2021-06-13 02:00:00 2021-06-14 09:00:00        32\n",
       "1582  2021-06-22 02:00:00 2021-06-24 08:00:00        55\n",
       "1602  2021-07-03 13:00:00 2021-07-06 05:00:00        65\n",
       "1710  2021-08-25 23:00:00 2021-09-03 21:00:00       215\n",
       "1722  2021-09-08 13:00:00 2021-09-14 13:00:00       145\n",
       "1734  2021-09-19 00:00:00 2021-09-27 08:00:00       201\n",
       "1858  2021-11-22 15:00:00 2021-11-24 08:00:00        42\n",
       "1864  2021-11-26 12:00:00 2021-12-04 08:00:00       189\n",
       "1894  2021-12-16 14:00:00 2021-12-18 09:00:00        44\n",
       "1902  2021-12-21 14:00:00 2021-12-24 09:00:00        68\n",
       "1904  2021-12-24 12:00:00 2022-01-03 09:00:00       238\n",
       "1906  2022-01-03 13:00:00 2022-01-11 09:00:00       189\n",
       "1910  2022-01-12 14:00:00 2022-01-14 08:00:00        43\n",
       "1948  2022-01-30 16:00:00 2022-02-04 09:00:00       114\n",
       "1966  2022-02-10 15:00:00 2022-02-12 11:00:00        45\n",
       "1972  2022-02-14 16:00:00 2022-02-16 09:00:00        42\n",
       "1974  2022-02-16 14:00:00 2022-02-18 10:00:00        45\n",
       "1978  2022-02-19 10:00:00 2022-02-24 06:00:00       117\n",
       "2004  2022-03-06 11:00:00 2022-03-07 11:00:00        25\n",
       "2032  2022-03-19 14:00:00 2022-03-28 07:00:00       209\n",
       "2034  2022-03-28 12:00:00 2022-04-05 06:00:00       187\n",
       "2196  2023-01-15 15:00:00 2023-01-17 09:00:00        43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed = np.sum(const_interval_b[const_interval_b['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed}')\n",
    "const_interval_b[const_interval_b['duration']>24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d09483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in groups of constant values, where duration of constant measurements is > 1 day (24 hours)\n",
    "train_c, const_interval_c = remove_constant_intervals(train_c,24,10**6)\n",
    "\n",
    "#update X_train_a by removing coresponding rows that have been filtered here\n",
    "x_train_c, train_c = align_X_y(x_train_c, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c619c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows removed 4926\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-04 10:00:00</td>\n",
       "      <td>2019-09-05 12:00:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2019-11-11 12:00:00</td>\n",
       "      <td>2019-11-13 08:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2019-11-28 15:00:00</td>\n",
       "      <td>2019-12-05 09:00:00</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2019-12-07 14:00:00</td>\n",
       "      <td>2019-12-13 09:00:00</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2019-12-16 14:00:00</td>\n",
       "      <td>2019-12-21 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2019-12-25 13:00:00</td>\n",
       "      <td>2019-12-30 09:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2020-01-02 14:00:00</td>\n",
       "      <td>2020-01-07 09:00:00</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2020-01-23 15:00:00</td>\n",
       "      <td>2020-01-26 08:00:00</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2020-02-05 14:00:00</td>\n",
       "      <td>2020-02-10 07:00:00</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2020-02-23 17:00:00</td>\n",
       "      <td>2020-03-08 08:00:00</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2020-03-28 18:00:00</td>\n",
       "      <td>2020-03-31 09:00:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2020-11-18 13:00:00</td>\n",
       "      <td>2020-11-22 08:00:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2020-12-16 14:00:00</td>\n",
       "      <td>2020-12-18 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2020-12-21 14:00:00</td>\n",
       "      <td>2020-12-23 09:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>2020-12-25 14:00:00</td>\n",
       "      <td>2020-12-28 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2021-01-09 14:00:00</td>\n",
       "      <td>2021-01-22 10:00:00</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2021-01-22 15:00:00</td>\n",
       "      <td>2021-01-24 10:00:00</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>2021-01-24 13:00:00</td>\n",
       "      <td>2021-02-19 10:00:00</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>2021-03-03 17:00:00</td>\n",
       "      <td>2021-03-06 07:00:00</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>2021-03-08 14:00:00</td>\n",
       "      <td>2021-03-10 08:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>2021-03-20 18:00:00</td>\n",
       "      <td>2021-03-22 05:00:00</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2021-04-09 19:00:00</td>\n",
       "      <td>2021-04-11 08:00:00</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2021-11-24 14:00:00</td>\n",
       "      <td>2021-12-14 09:00:00</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2021-12-21 14:00:00</td>\n",
       "      <td>2022-01-16 10:00:00</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>2022-01-16 13:00:00</td>\n",
       "      <td>2022-01-18 10:00:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2022-01-19 14:00:00</td>\n",
       "      <td>2022-01-22 09:00:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2022-01-24 16:00:00</td>\n",
       "      <td>2022-01-26 10:00:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>2022-01-27 16:00:00</td>\n",
       "      <td>2022-01-30 08:00:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2022-01-30 15:00:00</td>\n",
       "      <td>2022-02-07 11:00:00</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2022-02-08 14:00:00</td>\n",
       "      <td>2022-03-02 09:00:00</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>2022-04-02 18:00:00</td>\n",
       "      <td>2022-04-04 09:00:00</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>2022-04-05 13:00:00</td>\n",
       "      <td>2022-04-08 09:00:00</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2023-02-19 14:00:00</td>\n",
       "      <td>2023-02-21 10:00:00</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2023-02-21 16:00:00</td>\n",
       "      <td>2023-02-23 09:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                 end  duration\n",
       "group                                                  \n",
       "2     2019-09-04 10:00:00 2019-09-05 12:00:00        27\n",
       "180   2019-11-11 12:00:00 2019-11-13 08:00:00        45\n",
       "230   2019-11-28 15:00:00 2019-12-05 09:00:00       163\n",
       "240   2019-12-07 14:00:00 2019-12-13 09:00:00       140\n",
       "256   2019-12-16 14:00:00 2019-12-21 09:00:00       116\n",
       "276   2019-12-25 13:00:00 2019-12-30 09:00:00       117\n",
       "290   2020-01-02 14:00:00 2020-01-07 09:00:00       116\n",
       "340   2020-01-23 15:00:00 2020-01-26 08:00:00        66\n",
       "376   2020-02-05 14:00:00 2020-02-10 07:00:00       114\n",
       "414   2020-02-23 17:00:00 2020-03-08 08:00:00       328\n",
       "484   2020-03-28 18:00:00 2020-03-31 09:00:00        64\n",
       "1150  2020-11-18 13:00:00 2020-11-22 08:00:00        92\n",
       "1238  2020-12-16 14:00:00 2020-12-18 08:00:00        43\n",
       "1252  2020-12-21 14:00:00 2020-12-23 09:00:00        44\n",
       "1264  2020-12-25 14:00:00 2020-12-28 09:00:00        68\n",
       "1312  2021-01-09 14:00:00 2021-01-22 10:00:00       309\n",
       "1316  2021-01-22 15:00:00 2021-01-24 10:00:00        44\n",
       "1318  2021-01-24 13:00:00 2021-02-19 10:00:00       622\n",
       "1358  2021-03-03 17:00:00 2021-03-06 07:00:00        63\n",
       "1374  2021-03-08 14:00:00 2021-03-10 08:00:00        43\n",
       "1408  2021-03-20 18:00:00 2021-03-22 05:00:00        36\n",
       "1458  2021-04-09 19:00:00 2021-04-11 08:00:00        38\n",
       "2122  2021-11-24 14:00:00 2021-12-14 09:00:00       476\n",
       "2146  2021-12-21 14:00:00 2022-01-16 10:00:00       621\n",
       "2148  2022-01-16 13:00:00 2022-01-18 10:00:00        46\n",
       "2152  2022-01-19 14:00:00 2022-01-22 09:00:00        68\n",
       "2164  2022-01-24 16:00:00 2022-01-26 10:00:00        43\n",
       "2168  2022-01-27 16:00:00 2022-01-30 08:00:00        65\n",
       "2172  2022-01-30 15:00:00 2022-02-07 11:00:00       189\n",
       "2178  2022-02-08 14:00:00 2022-03-02 09:00:00       524\n",
       "2284  2022-04-02 18:00:00 2022-04-04 09:00:00        40\n",
       "2290  2022-04-05 13:00:00 2022-04-08 09:00:00        69\n",
       "2486  2023-02-19 14:00:00 2023-02-21 10:00:00        45\n",
       "2490  2023-02-21 16:00:00 2023-02-23 09:00:00        42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_removed = np.sum(const_interval_c[const_interval_c['duration']>24]['duration'])\n",
    "print(f'total number of rows removed {rows_removed}')\n",
    "const_interval_c[const_interval_c['duration']>24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295598a-c357-4143-898f-f57bc361c20f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merge x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7084bebc-37bb-4a70-afd6-5d22049f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a = pd.merge(x_train_a, train_a, left_on='date_forecast', right_on='time', how='inner')\n",
    "merged_b = pd.merge(x_train_b, train_b, left_on='date_forecast', right_on='time', how='inner')\n",
    "merged_c = pd.merge(x_train_c, train_c, left_on='date_forecast', right_on='time', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df46b11c-5cb0-445c-aa2c-b16a28f93dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are plotting on the modified dataset\n",
    "def time_series_plot(feature,merged_data):\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Solar Power Production', color='tab:blue')\n",
    "    ax1.plot(merged_data['time'], merged_data['pv_measurement'], color='tab:blue', label='Solar Power Production')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel(feature, color='tab:red')  \n",
    "    ax2.plot(merged_data['date_forecast'], merged_data[feature], color='tab:red', label=feature)\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'Time Series Plot of Solar Power Production and {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b9338-8fa4-41ed-bd50-584aafeb6421",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handle NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168ddcd0-b2a8-4871-a769-b49b8430e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(merged_data):\n",
    "    df = merged_data.copy()\n",
    "    \n",
    "    nan_cols = ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3',\n",
    "       'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W',\n",
    "       'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K',\n",
    "       'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J',\n",
    "       'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm',\n",
    "       'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm',\n",
    "       'fresh_snow_6h:cm', 'is_day:idx', 'is_in_shadow:idx',\n",
    "       'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx',\n",
    "       'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p',\n",
    "       'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa',\n",
    "       'snow_density:kgm3', 'snow_depth:cm', 'snow_drift:idx',\n",
    "       'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d',\n",
    "       'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K',\n",
    "       'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms',\n",
    "       'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms']\n",
    "    \n",
    "    nan_rows_mask = merged_data.loc[:,nan_cols].isna().all(axis=1)\n",
    "    df = df.drop(df[nan_rows_mask].index, inplace=False)\n",
    "    \n",
    "    df = df.drop(columns = ['snow_density:kgm3','cloud_base_agl:m'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d40687cf-baef-4e0b-87ba-a131726a4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_a = remove_nan(merged_a)\n",
    "merged_b = remove_nan(merged_b)\n",
    "merged_c = remove_nan(merged_c)\n",
    "\n",
    "x_test_a = remove_nan(x_test_a)\n",
    "x_test_b = remove_nan(x_test_b)\n",
    "x_test_c = remove_nan(x_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d8647",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add Cyclical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea1031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cyclical features for hour of the day\n",
    "def add_cyclic(merged_df):\n",
    "    train_data = merged_df.copy()\n",
    "   \n",
    "    train_data['hour_sin'] = np.sin(2 * np.pi * train_data['hour'] / 24)\n",
    "    train_data['hour_cos'] = np.cos(2 * np.pi * train_data['hour'] / 24)\n",
    "    train_data['month_sin'] = np.sin(2 * np.pi * (train_data['month']-1) / 12)\n",
    "    train_data['month_cos'] = np.cos(2 * np.pi * (train_data['month']-1) / 12)\n",
    "    \n",
    "    #train_data.drop(columns = ['hour','month'],inplace = True)\n",
    "    return train_data\n",
    "\n",
    "merged_a = add_cyclic(merged_a)\n",
    "merged_b = add_cyclic(merged_b)\n",
    "merged_c = add_cyclic(merged_c)\n",
    "\n",
    "x_test_a = add_cyclic(x_test_a)\n",
    "x_test_b = add_cyclic(x_test_b)\n",
    "x_test_c = add_cyclic(x_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7d537-27fa-4d76-b9f5-87a487493050",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add direct_rad * sun_elevation feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fef5b1dd-5ce5-4af4-8628-820e7bb1bb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmerged_a = add_rad_x_sun(merged_a)\\nmerged_b = add_rad_x_sun(merged_b)\\nmerged_c = add_rad_x_sun(merged_c)\\n\\nx_test_a = add_rad_x_sun(x_test_a)\\nx_test_b = add_rad_x_sun(x_test_b)\\nx_test_c = add_rad_x_sun(x_test_c)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Did not improve kaggle score\n",
    "def add_rad_x_sun(merged_data):\n",
    "    df = merged_data.copy()\n",
    "    df['rad_x_sun_elevation'] = df['direct_rad:W']*df['sun_elevation:d']\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "merged_a = add_rad_x_sun(merged_a)\n",
    "merged_b = add_rad_x_sun(merged_b)\n",
    "merged_c = add_rad_x_sun(merged_c)\n",
    "\n",
    "x_test_a = add_rad_x_sun(x_test_a)\n",
    "x_test_b = add_rad_x_sun(x_test_b)\n",
    "x_test_c = add_rad_x_sun(x_test_c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd791c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Autogluon model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0ca3f44-2e86-4482-9294-a809526d26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "presets = ['medium_quality','high_quality', 'best_quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c537575-2bed-46f9-9beb-e59cad791533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the random seeds for reproducibility\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25af5b8c-b8b9-4763-9b1c-e7ffda42503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_multiple_autogluon(merged_data, time_limit, location, x_test):\n",
    "    # Assuming merged_data is a DataFrame that includes 'pv_measurement', 'date_forecast', 'time'\n",
    "    merged_df = merged_data.drop(columns=['date_forecast', 'time'])\n",
    "\n",
    "    # List to store predictions from each model\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(5):  # Train 5 different models\n",
    "        # Each model will be saved in a different directory\n",
    "        model_path = f'AutGluonModels/{location}/model_{i}'\n",
    "        \n",
    "        predictor = TabularPredictor(\n",
    "            label='pv_measurement',\n",
    "            eval_metric='mean_absolute_error',\n",
    "            path=model_path\n",
    "        )\n",
    "\n",
    "        predictor.fit(\n",
    "            train_data=merged_df,\n",
    "            verbosity=2,\n",
    "            presets='high_quality',\n",
    "            time_limit=time_limit\n",
    "        )\n",
    "        \n",
    "        # Predict using the current model\n",
    "        preds = predictor.predict(x_test)\n",
    "        predictions.append(preds)\n",
    "\n",
    "    # Convert list of predictions to numpy array for easy averaging\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate the average prediction across all models\n",
    "    avg_prediction = predictions.mean(axis=0)\n",
    "\n",
    "    return avg_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b8bd94e-136d-403e-ad92-e6414cb0e87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/A/model_0/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   94.58 GB / 105.09 GB (90.0%)\n",
      "Train Data Rows:    34019\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 631.79021, 1166.71485)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13983.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.42 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.64 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.74s of the 299.69s of remaining time.\n",
      "\t-266.74\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.27s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 193.36s of the 293.31s of remaining time.\n",
      "\t-267.4574\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.24s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 189.96s of the 289.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.6549\t = Validation score   (-mean_absolute_error)\n",
      "\t171.89s\t = Training   runtime\n",
      "\t84.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 0.53s of the 100.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-794.0664\t = Validation score   (-mean_absolute_error)\n",
      "\t5.63s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.69s of the 91.43s of remaining time.\n",
      "\t-145.6549\t = Validation score   (-mean_absolute_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 90.92s of the 90.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-148.8314\t = Validation score   (-mean_absolute_error)\n",
      "\t18.95s\t = Training   runtime\n",
      "\t1.31s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 68.05s of the 68.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-146.0307\t = Validation score   (-mean_absolute_error)\n",
      "\t12.92s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 51.15s of the 51.13s of remaining time.\n",
      "\t-145.4024\t = Validation score   (-mean_absolute_error)\n",
      "\t125.8s\t = Training   runtime\n",
      "\t2.36s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.69s of the -78.64s of remaining time.\n",
      "\t-144.2876\t = Validation score   (-mean_absolute_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 379.03s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.27s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.24s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t58.61s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.49s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.4s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.11s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t125.8s\t = Training   runtime\n",
      "\t2.36s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.34s\t = Training   runtime\n",
      "Refit complete, total runtime = 67.02s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/A/model_0/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/A/model_1/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   93.63 GB / 105.09 GB (89.1%)\n",
      "Train Data Rows:    34019\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 631.79021, 1166.71485)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13214.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.42 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.64 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.75s of the 299.7s of remaining time.\n",
      "\t-266.74\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.49s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 196.08s of the 296.03s of remaining time.\n",
      "\t-267.4574\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.47s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 192.42s of the 292.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.5416\t = Validation score   (-mean_absolute_error)\n",
      "\t180.34s\t = Training   runtime\n",
      "\t97.44s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.71s of the 96.5s of remaining time.\n",
      "\t-145.5416\t = Validation score   (-mean_absolute_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 96.16s of the 96.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-149.1845\t = Validation score   (-mean_absolute_error)\n",
      "\t23.35s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 68.57s of the 68.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.8385\t = Validation score   (-mean_absolute_error)\n",
      "\t11.54s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 52.99s of the 52.98s of remaining time.\n",
      "\t-145.5046\t = Validation score   (-mean_absolute_error)\n",
      "\t125.17s\t = Training   runtime\n",
      "\t2.38s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.71s of the -75.85s of remaining time.\n",
      "\t-144.3789\t = Validation score   (-mean_absolute_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 376.22s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.49s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.47s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t37.35s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.8s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.12s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t125.17s\t = Training   runtime\n",
      "\t2.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Refit complete, total runtime = 44.82s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/A/model_1/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/A/model_2/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   92.68 GB / 105.09 GB (88.2%)\n",
      "Train Data Rows:    34019\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 631.79021, 1166.71485)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13140.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.42 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.64 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.75s of the 299.69s of remaining time.\n",
      "\t-266.74\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 196.01s of the 295.96s of remaining time.\n",
      "\t-267.4574\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.5s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 192.34s of the 292.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.998\t = Validation score   (-mean_absolute_error)\n",
      "\t184.48s\t = Training   runtime\n",
      "\t83.77s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.7s of the 95.62s of remaining time.\n",
      "\t-145.998\t = Validation score   (-mean_absolute_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 95.26s of the 95.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-149.3939\t = Validation score   (-mean_absolute_error)\n",
      "\t19.72s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 70.7s of the 70.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-146.4637\t = Validation score   (-mean_absolute_error)\n",
      "\t12.45s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 54.43s of the 54.41s of remaining time.\n",
      "\t-146.2085\t = Validation score   (-mean_absolute_error)\n",
      "\t125.2s\t = Training   runtime\n",
      "\t2.4s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.7s of the -74.8s of remaining time.\n",
      "\t-144.9385\t = Validation score   (-mean_absolute_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 375.16s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.5s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t33.02s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.34s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t3.05s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.4s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t125.2s\t = Training   runtime\n",
      "\t2.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Refit complete, total runtime = 40.94s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/A/model_2/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/A/model_3/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   91.73 GB / 105.09 GB (87.3%)\n",
      "Train Data Rows:    34019\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 631.79021, 1166.71485)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12591.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.42 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.64 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.75s of the 299.7s of remaining time.\n",
      "\t-266.74\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.56s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 196.0s of the 295.95s of remaining time.\n",
      "\t-267.4574\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.5s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 192.3s of the 292.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.6235\t = Validation score   (-mean_absolute_error)\n",
      "\t179.55s\t = Training   runtime\n",
      "\t80.1s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.7s of the 99.78s of remaining time.\n",
      "\t-145.6235\t = Validation score   (-mean_absolute_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 99.44s of the 99.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-149.3749\t = Validation score   (-mean_absolute_error)\n",
      "\t22.38s\t = Training   runtime\n",
      "\t1.36s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 73.22s of the 73.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-146.0567\t = Validation score   (-mean_absolute_error)\n",
      "\t12.76s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 56.85s of the 56.83s of remaining time.\n",
      "\t-145.7809\t = Validation score   (-mean_absolute_error)\n",
      "\t124.38s\t = Training   runtime\n",
      "\t2.35s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.7s of the -70.77s of remaining time.\n",
      "\t-144.6235\t = Validation score   (-mean_absolute_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 371.14s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.56s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.5s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t53.3s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.57s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.43s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t124.38s\t = Training   runtime\n",
      "\t2.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.3s\t = Training   runtime\n",
      "Refit complete, total runtime = 61.54s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/A/model_3/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/A/model_4/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   90.78 GB / 105.09 GB (86.4%)\n",
      "Train Data Rows:    34019\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 631.79021, 1166.71485)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12715.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.42 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.64 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.75s of the 299.7s of remaining time.\n",
      "\t-266.74\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.5s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 196.07s of the 296.01s of remaining time.\n",
      "\t-267.4574\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.45s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 192.42s of the 292.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.5637\t = Validation score   (-mean_absolute_error)\n",
      "\t178.64s\t = Training   runtime\n",
      "\t87.09s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.7s of the 98.37s of remaining time.\n",
      "\t-145.5637\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 98.02s of the 98.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-148.9618\t = Validation score   (-mean_absolute_error)\n",
      "\t21.69s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 72.71s of the 72.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.8156\t = Validation score   (-mean_absolute_error)\n",
      "\t11.94s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 57.31s of the 57.29s of remaining time.\n",
      "\t-145.583\t = Validation score   (-mean_absolute_error)\n",
      "\t125.68s\t = Training   runtime\n",
      "\t2.37s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.7s of the -71.75s of remaining time.\n",
      "\t-144.3587\t = Validation score   (-mean_absolute_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 372.15s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.5s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.45s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t36.76s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.58s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.13s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t125.68s\t = Training   runtime\n",
      "\t2.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Refit complete, total runtime = 44.29s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/A/model_4/\")\n"
     ]
    }
   ],
   "source": [
    "pred_a = build_multiple_autogluon(merged_a,300,'A',x_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0fe2a3e-83ac-408e-9614-651eaa883450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.018143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.029512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.114448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.767311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.926270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>761.584656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1513.414307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3659.735107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2975.701660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2330.754639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3033.106934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3271.165039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2648.883301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2883.994141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2234.383789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1542.756836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1249.813843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>700.574585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>206.333649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.015417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      1.018143\n",
       "1      1.029512\n",
       "2      1.114448\n",
       "3     35.767311\n",
       "4    273.926270\n",
       "5    761.584656\n",
       "6   1513.414307\n",
       "7   3659.735107\n",
       "8   2975.701660\n",
       "9   2330.754639\n",
       "10  3033.106934\n",
       "11  3271.165039\n",
       "12  2648.883301\n",
       "13  2883.994141\n",
       "14  2234.383789\n",
       "15  1542.756836\n",
       "16  1249.813843\n",
       "17   700.574585\n",
       "18   206.333649\n",
       "19    18.015417"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred_a).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98ea09ad-9a91-444e-a11e-42dd65c35405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/B/model_0/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   89.83 GB / 105.09 GB (85.5%)\n",
      "Train Data Rows:    25954\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 107.04334, 212.42606)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12434.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.0 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.3s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.62 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.75s of the 299.69s of remaining time.\n",
      "\t-40.8645\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.53s of the 297.47s of remaining time.\n",
      "\t-40.9853\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t2.08s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.3s of the 295.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8299\t = Validation score   (-mean_absolute_error)\n",
      "\t180.38s\t = Training   runtime\n",
      "\t102.03s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.69s of the 98.05s of remaining time.\n",
      "\t-20.8299\t = Validation score   (-mean_absolute_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.71s of the 97.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.8139\t = Validation score   (-mean_absolute_error)\n",
      "\t37.91s\t = Training   runtime\n",
      "\t2.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 55.72s of the 55.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3472\t = Validation score   (-mean_absolute_error)\n",
      "\t13.58s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 36.07s of the 36.06s of remaining time.\n",
      "\t-21.0459\t = Validation score   (-mean_absolute_error)\n",
      "\t103.64s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.69s of the -69.89s of remaining time.\n",
      "\t-20.9086\t = Validation score   (-mean_absolute_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 370.2s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t2.08s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t38.54s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.0s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.94s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t103.64s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.27s\t = Training   runtime\n",
      "Refit complete, total runtime = 43.71s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/B/model_0/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/B/model_1/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   89.17 GB / 105.09 GB (84.9%)\n",
      "Train Data Rows:    25954\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 107.04334, 212.42606)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12508.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.0 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.3s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.62 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.74s of the 299.68s of remaining time.\n",
      "\t-40.8645\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t2.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.49s of the 297.43s of remaining time.\n",
      "\t-40.9853\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.22s of the 295.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.832\t = Validation score   (-mean_absolute_error)\n",
      "\t181.39s\t = Training   runtime\n",
      "\t98.67s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.68s of the 97.63s of remaining time.\n",
      "\t-20.832\t = Validation score   (-mean_absolute_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.2s of the 97.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.6784\t = Validation score   (-mean_absolute_error)\n",
      "\t20.35s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 73.24s of the 73.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3205\t = Validation score   (-mean_absolute_error)\n",
      "\t11.52s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 58.33s of the 58.31s of remaining time.\n",
      "\t-21.0415\t = Validation score   (-mean_absolute_error)\n",
      "\t105.22s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.68s of the -49.2s of remaining time.\n",
      "\t-20.8823\t = Validation score   (-mean_absolute_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 349.53s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t2.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.12s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t37.31s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t3.31s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.9s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t105.22s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.27s\t = Training   runtime\n",
      "Refit complete, total runtime = 43.81s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/B/model_1/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/B/model_2/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   88.52 GB / 105.09 GB (84.2%)\n",
      "Train Data Rows:    25954\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 107.04334, 212.42606)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12461.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.0 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.3s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.62 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.74s of the 299.68s of remaining time.\n",
      "\t-40.8645\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.47s of the 297.41s of remaining time.\n",
      "\t-40.9853\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.08s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.25s of the 295.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8513\t = Validation score   (-mean_absolute_error)\n",
      "\t192.01s\t = Training   runtime\n",
      "\t85.38s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.69s of the 91.74s of remaining time.\n",
      "\t-20.8513\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 91.44s of the 91.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.7573\t = Validation score   (-mean_absolute_error)\n",
      "\t22.11s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 65.51s of the 65.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3194\t = Validation score   (-mean_absolute_error)\n",
      "\t11.07s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 50.34s of the 50.33s of remaining time.\n",
      "\t-21.1033\t = Validation score   (-mean_absolute_error)\n",
      "\t103.65s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.69s of the -55.6s of remaining time.\n",
      "\t-20.923\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 355.92s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.08s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t29.91s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.28s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.42s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.16s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t103.65s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.28s\t = Training   runtime\n",
      "Refit complete, total runtime = 35.61s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/B/model_2/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/B/model_3/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   87.86 GB / 105.09 GB (83.6%)\n",
      "Train Data Rows:    25954\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 107.04334, 212.42606)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12454.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.0 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.62 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.76s of the 299.7s of remaining time.\n",
      "\t-40.8645\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.57s of the 297.52s of remaining time.\n",
      "\t-40.9853\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.35s of the 295.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.831\t = Validation score   (-mean_absolute_error)\n",
      "\t181.11s\t = Training   runtime\n",
      "\t94.22s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.71s of the 99.12s of remaining time.\n",
      "\t-20.831\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 98.83s of the 98.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.7067\t = Validation score   (-mean_absolute_error)\n",
      "\t18.15s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 77.42s of the 77.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.2967\t = Validation score   (-mean_absolute_error)\n",
      "\t11.14s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 62.57s of the 62.56s of remaining time.\n",
      "\t-21.0404\t = Validation score   (-mean_absolute_error)\n",
      "\t104.42s\t = Training   runtime\n",
      "\t2.23s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.71s of the -45.36s of remaining time.\n",
      "\t-20.8719\t = Validation score   (-mean_absolute_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 346.12s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t53.76s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.28s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.78s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.22s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t104.42s\t = Training   runtime\n",
      "\t2.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.69s\t = Training   runtime\n",
      "Refit complete, total runtime = 60.31s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/B/model_3/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/B/model_4/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   87.21 GB / 105.09 GB (83.0%)\n",
      "Train Data Rows:    25954\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 107.04334, 212.42606)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12391.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.0 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.3s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.62 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.75s of the 299.69s of remaining time.\n",
      "\t-40.8645\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t2.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.54s of the 297.48s of remaining time.\n",
      "\t-40.9853\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.33s of the 295.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8318\t = Validation score   (-mean_absolute_error)\n",
      "\t180.82s\t = Training   runtime\n",
      "\t90.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 0.98s of the 100.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-139.5653\t = Validation score   (-mean_absolute_error)\n",
      "\t7.92s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.69s of the 89.16s of remaining time.\n",
      "\t-20.8318\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 88.81s of the 88.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.8631\t = Validation score   (-mean_absolute_error)\n",
      "\t19.45s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 65.74s of the 65.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3608\t = Validation score   (-mean_absolute_error)\n",
      "\t10.92s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 51.63s of the 51.62s of remaining time.\n",
      "\t-21.0062\t = Validation score   (-mean_absolute_error)\n",
      "\t106.38s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.69s of the -57.05s of remaining time.\n",
      "\t-20.903\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 357.38s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t2.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.06s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t36.37s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.35s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.26s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.16s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t106.38s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.28s\t = Training   runtime\n",
      "Refit complete, total runtime = 42.22s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/B/model_4/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/C/model_0/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   86.55 GB / 105.09 GB (82.4%)\n",
      "Train Data Rows:    21145\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 95.80127, 179.41992)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12409.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.97 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.48 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-33.1764\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t2.48s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.18s of the 297.15s of remaining time.\n",
      "\t-33.1734\t = Validation score   (-mean_absolute_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.45s of the 295.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.7477\t = Validation score   (-mean_absolute_error)\n",
      "\t167.16s\t = Training   runtime\n",
      "\t78.81s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 15.2s of the 115.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.1451\t = Validation score   (-mean_absolute_error)\n",
      "\t24.32s\t = Training   runtime\n",
      "\t2.26s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.77s of the 86.43s of remaining time.\n",
      "\t-18.747\t = Validation score   (-mean_absolute_error)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 85.42s of the 85.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.6705\t = Validation score   (-mean_absolute_error)\n",
      "\t24.12s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 49.85s of the 49.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.4274\t = Validation score   (-mean_absolute_error)\n",
      "\t11.75s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 34.8s of the 34.77s of remaining time.\n",
      "\t-19.1225\t = Validation score   (-mean_absolute_error)\n",
      "\t75.83s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.77s of the -42.87s of remaining time.\n",
      "\t-18.9526\t = Validation score   (-mean_absolute_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 343.17s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t2.48s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.1s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t36.6s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.49s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.96s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.11s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.1s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t75.83s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.27s\t = Training   runtime\n",
      "Refit complete, total runtime = 44.81s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/C/model_0/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/C/model_1/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   86.12 GB / 105.09 GB (81.9%)\n",
      "Train Data Rows:    21145\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 95.80127, 179.41992)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12354.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.97 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.48 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.8s of the 299.76s of remaining time.\n",
      "\t-33.1764\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.28s of the 298.25s of remaining time.\n",
      "\t-33.1734\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.39s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.74s of the 296.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.7477\t = Validation score   (-mean_absolute_error)\n",
      "\t167.1s\t = Training   runtime\n",
      "\t80.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 16.69s of the 116.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3554\t = Validation score   (-mean_absolute_error)\n",
      "\t19.77s\t = Training   runtime\n",
      "\t2.6s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.77s of the 93.21s of remaining time.\n",
      "\t-18.7409\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 92.87s of the 92.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.6712\t = Validation score   (-mean_absolute_error)\n",
      "\t19.98s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 69.49s of the 69.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.454\t = Validation score   (-mean_absolute_error)\n",
      "\t11.24s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 54.59s of the 54.58s of remaining time.\n",
      "\t-19.0924\t = Validation score   (-mean_absolute_error)\n",
      "\t76.2s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.77s of the -23.31s of remaining time.\n",
      "\t-18.942\t = Validation score   (-mean_absolute_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 323.61s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.39s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t33.41s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.86s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t1.95s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.9s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t76.2s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Refit complete, total runtime = 41.82s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/C/model_1/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/C/model_2/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   85.68 GB / 105.09 GB (81.5%)\n",
      "Train Data Rows:    21145\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 95.80127, 179.41992)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12304.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.97 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.48 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-33.1764\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.4s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.27s of the 298.24s of remaining time.\n",
      "\t-33.1734\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.74s of the 296.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.7477\t = Validation score   (-mean_absolute_error)\n",
      "\t191.5s\t = Training   runtime\n",
      "\t131.01s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.77s of the 92.14s of remaining time.\n",
      "\t-18.7477\t = Validation score   (-mean_absolute_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 91.83s of the 91.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.6112\t = Validation score   (-mean_absolute_error)\n",
      "\t15.94s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 72.2s of the 72.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.3882\t = Validation score   (-mean_absolute_error)\n",
      "\t11.03s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 56.85s of the 56.83s of remaining time.\n",
      "\t-19.1602\t = Validation score   (-mean_absolute_error)\n",
      "\t74.47s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.77s of the -19.46s of remaining time.\n",
      "\t-18.9658\t = Validation score   (-mean_absolute_error)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 319.75s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.4s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t31.03s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.3s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.38s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.14s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t74.47s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.24s\t = Training   runtime\n",
      "Refit complete, total runtime = 36.78s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/C/model_2/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/C/model_3/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   85.25 GB / 105.09 GB (81.1%)\n",
      "Train Data Rows:    21145\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 95.80127, 179.41992)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12274.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.97 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.48 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.8s of the 299.77s of remaining time.\n",
      "\t-33.1764\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.27s of the 298.24s of remaining time.\n",
      "\t-33.1734\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.36s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.79s of the 296.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.7477\t = Validation score   (-mean_absolute_error)\n",
      "\t170.62s\t = Training   runtime\n",
      "\t79.98s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 14.45s of the 114.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.6753\t = Validation score   (-mean_absolute_error)\n",
      "\t17.32s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.77s of the 93.5s of remaining time.\n",
      "\t-18.7444\t = Validation score   (-mean_absolute_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 93.18s of the 93.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.6764\t = Validation score   (-mean_absolute_error)\n",
      "\t24.58s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 64.39s of the 64.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.365\t = Validation score   (-mean_absolute_error)\n",
      "\t11.97s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 48.73s of the 48.72s of remaining time.\n",
      "\t-19.1367\t = Validation score   (-mean_absolute_error)\n",
      "\t76.6s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.77s of the -29.82s of remaining time.\n",
      "\t-18.9695\t = Validation score   (-mean_absolute_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 330.1s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.36s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t32.65s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t5.56s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.3s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t6.99s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.72s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t76.6s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Refit complete, total runtime = 52.52s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/C/model_3/\")\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutGluonModels/C/model_4/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Debian 5.10.197-1 (2023-09-29)\n",
      "Disk Space Avail:   84.81 GB / 105.09 GB (80.7%)\n",
      "Train Data Rows:    21145\n",
      "Train Data Columns: 53\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 95.80127, 179.41992)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6294.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.97 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  5 | ['year', 'month', 'day', 'hour', 'estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  4 | ['year', 'month', 'day', 'hour']\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.4s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.48 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.51s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.61s of the 299.48s of remaining time.\n",
      "\t-33.1764\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.4s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 195.92s of the 295.79s of remaining time.\n",
      "\t-33.1734\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t2.82s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 192.81s of the 292.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.7477\t = Validation score   (-mean_absolute_error)\n",
      "\t171.95s\t = Training   runtime\n",
      "\t77.46s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 6.59s of the 106.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.6874\t = Validation score   (-mean_absolute_error)\n",
      "\t10.3s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.49s of the 92.58s of remaining time.\n",
      "\t-18.7477\t = Validation score   (-mean_absolute_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 92.22s of the 92.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.6424\t = Validation score   (-mean_absolute_error)\n",
      "\t20.98s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 67.59s of the 67.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.3666\t = Validation score   (-mean_absolute_error)\n",
      "\t11.63s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 52.78s of the 52.77s of remaining time.\n",
      "\t-19.1117\t = Validation score   (-mean_absolute_error)\n",
      "\t75.05s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.49s of the -24.0s of remaining time.\n",
      "\t-18.9483\t = Validation score   (-mean_absolute_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 324.33s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.4s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.07s\t = Training   runtime\n",
      "\t2.82s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t30.31s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t1.22s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.34s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.09s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.89s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t75.05s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Refit complete, total runtime = 36.45s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutGluonModels/C/model_4/\")\n"
     ]
    }
   ],
   "source": [
    "pred_b = build_multiple_autogluon(merged_b,300,'B',x_test_b)\n",
    "pred_c = build_multiple_autogluon(merged_c,300,'C',x_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900ebe1-7eda-455c-9538-8cf0ac0af4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autogluon(merged_data, time_limit,location):\n",
    "    merged_df = merged_data.drop(columns=['date_forecast', 'time'])\n",
    "    \n",
    "    predictor = TabularPredictor(\n",
    "        label ='pv_measurement',\n",
    "        eval_metric= 'mean_absolute_error',\n",
    "        path = f'AutGluonModels/{location}'\n",
    "    )\n",
    "\n",
    "    predictor.fit(\n",
    "        train_data = merged_df, \n",
    "        verbosity = 2,\n",
    "        presets='best_quality', \n",
    "        time_limit= time_limit,\n",
    "        #holdout_frac=0.2\n",
    "    )\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28fdf3-51ca-49e6-a537-a486d4ae128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = build_autogluon(merged_a,300,'A')\n",
    "model_b = build_autogluon(merged_b,300,'B')\n",
    "model_c = build_autogluon(merged_c,300,'C')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67684c52-a72c-492b-9428-ac0a64049be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predict and Submit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b63a33-669f-4e43-beb5-ee8a5e5df1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_a = model_a.predict(x_test_a)\n",
    "pred_b = model_b.predict(x_test_b)\n",
    "pred_c = model_c.predict(x_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98989635-e755-4cb3-808e-fcaffbce7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub(pred_a,pred_b,pred_c):\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    submission['prediction'] = np.concatenate([pred_a,pred_b,pred_c])\n",
    "    submission.loc[submission['prediction'] <6 , 'prediction'] = 0\n",
    "    return submission\n",
    "\n",
    "sub = create_sub(pred_a,pred_b,pred_c)\n",
    "#sub = create_sub(laged_pred_a,laged_pred_b,laged_pred_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1683dcc-00d2-4aff-b745-0ac2269a55c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35.767311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>273.926270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2155</td>\n",
       "      <td>53.993336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>36.625397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2157</td>\n",
       "      <td>13.183255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2158</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2159</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  prediction\n",
       "0        0    0.000000\n",
       "1        1    0.000000\n",
       "2        2    0.000000\n",
       "3        3   35.767311\n",
       "4        4  273.926270\n",
       "...    ...         ...\n",
       "2155  2155   53.993336\n",
       "2156  2156   36.625397\n",
       "2157  2157   13.183255\n",
       "2158  2158    0.000000\n",
       "2159  2159    0.000000\n",
       "\n",
       "[2160 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d456bf31-9668-4eb2-98a9-7097c3679b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f'Submissions/Autogluon/avg5Autgluon300sek.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24076d9-b911-498d-87ea-23c55b6691e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,model_name,location):\n",
    "    save_directory = 'Saved_models/'+ location.upper()\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    # Define the path to save the model\n",
    "    model_file_path = os.path.join(save_directory, f'{model_name}.cbm')\n",
    "\n",
    "    # Save the model\n",
    "    model.save_model(model_file_path)\n",
    "\n",
    "    print(f\"Model successfully saved at {model_file_path}\")\n",
    "    \n",
    "save_model(model_a,'cyclical_catBoost','A')\n",
    "save_model(model_b,'cyclical_catBoost','B')\n",
    "save_model(model_c,'cyclical_catBoost','C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754cbdf-96c1-464c-8234-6b2e4ff37ab0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea45b7-a8fc-4c20-b887-b3ad124e0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_importance(model):\n",
    "    feats = {'feature':merged_a.drop(columns =['date_forecast','time','pv_measurement']).columns,\n",
    "         'importance':model.get_feature_importance()}\n",
    "    df = pd.DataFrame(feats).sort_values('importance',ascending = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231c4d3-d6ce-4ad3-8b7c-a7b1985c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feat_importance(model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf40fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_preds(pred1,pred2):\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Scatter plot\n",
    "    plt.scatter(pred1['prediction'], pred2['prediction'], alpha=0.5)\n",
    "\n",
    "    # Line of equality (for reference)\n",
    "    plt.plot([pred1['prediction'].min(), pred1['prediction'].max()],\n",
    "             [pred2['prediction'].min(), pred2['prediction'].max()],\n",
    "             color='red', linestyle='--')\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Predictions from First Model')\n",
    "    plt.ylabel('Predictions from New model')\n",
    "    plt.title('Comparison of Predictions from Two Models')\n",
    "\n",
    "    # Show plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471709c6-c455-48b0-b3b9-ff1d0eba5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_two_preds(sub,sub_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(preds):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    predictions= preds['predict'].as_data_frame()\n",
    "    predictions['time'] = test['time'].unique()\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Prediction', color='tab:blue')\n",
    "    ax1.plot(predictions['time'], predictions['predict'], color='tab:blue', label='Solar Power Production')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'Time Series Plot of prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8937d-fd7d-478c-9dae-77c249bf96d6",
   "metadata": {},
   "source": [
    "### Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1282dc2-ab41-4e86-a742-869ce7a9d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_average2.csv')\n",
    "df.loc[df['prediction'] < 8, 'prediction'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eba965-56c9-46bd-8310-64a3c19d8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'Submissions/merged_models3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34416f8d-98d7-475e-b7f7-4d9b27b49dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "maks = max([train_a['pv_measurement'].max(),train_b['pv_measurement'].max(),train_c['pv_measurement'].max()])\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
