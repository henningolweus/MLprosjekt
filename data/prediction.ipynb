{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Exclude boolean columns (location_A, location_B, location_C)\n",
    "# columns_to_scale = x_train.columns.difference(['location_A', 'location_B', 'location_C'])\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# x_train[columns_to_scale] = scaler.fit_transform(x_train[columns_to_scale])\n",
    "# x_test[columns_to_scale] = scaler.transform(x_test[columns_to_scale])\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('cleaned_data/x_train_combined.csv')\n",
    "y_train = pd.read_csv('cleaned_data/y_train_combined.csv')\n",
    "x_test = pd.read_csv('cleaned_data/x_test_combined.csv')\n",
    "\n",
    "# Determine the split index\n",
    "split_index = int(0.875 * len(x_train))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train_df = x_train[:split_index]\n",
    "y_train_df = y_train[:split_index]\n",
    "x_valid_df = x_train[split_index:]\n",
    "y_valid_df = y_train[split_index:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Exclude boolean columns (location_A, location_B, location_C)\n",
    "# columns_to_scale = x_train.columns.difference(['location_A', 'location_B', 'location_C'])\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# x_train[columns_to_scale] = scaler.fit_transform(x_train[columns_to_scale])\n",
    "# x_test[columns_to_scale] = scaler.transform(x_test[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train_df,label = y_train_df['pv_measurement'])\n",
    "dval = xgb.DMatrix(x_valid_df,label = y_valid_df['pv_measurement'])\n",
    "test = xgb.DMatrix(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'booster': 'gbtree',\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'alpha': 0.1,\n",
    "    'lambda': 1,\n",
    "\n",
    "}\n",
    "#  Train the model\n",
    "num_boost_round = 1000  # Maximum number of boosting rounds\n",
    "early_stopping_rounds = 50  # Stop if validation score doesn't improve for 50 rounds\n",
    "\n",
    "evals = [(dtrain, 'train'), (dval, 'eval')]\n",
    "progress = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:410.81769\teval-mae:355.02348\n",
      "[1]\ttrain-mae:391.97774\teval-mae:339.55657\n",
      "[2]\ttrain-mae:374.25054\teval-mae:324.94830\n",
      "[3]\ttrain-mae:357.63684\teval-mae:311.05315\n",
      "[4]\ttrain-mae:341.91711\teval-mae:298.07872\n",
      "[5]\ttrain-mae:327.01209\teval-mae:285.79752\n",
      "[6]\ttrain-mae:313.06909\teval-mae:274.27079\n",
      "[7]\ttrain-mae:299.99073\teval-mae:263.35323\n",
      "[8]\ttrain-mae:287.64472\teval-mae:253.14326\n",
      "[9]\ttrain-mae:276.06925\teval-mae:243.46777\n",
      "[10]\ttrain-mae:265.26259\teval-mae:234.37246\n",
      "[11]\ttrain-mae:255.10855\teval-mae:225.55454\n",
      "[12]\ttrain-mae:245.64420\teval-mae:217.29854\n",
      "[13]\ttrain-mae:236.73054\teval-mae:209.58611\n",
      "[14]\ttrain-mae:228.37144\teval-mae:202.30888\n",
      "[15]\ttrain-mae:220.49649\teval-mae:195.30857\n",
      "[16]\ttrain-mae:213.13562\teval-mae:188.77218\n",
      "[17]\ttrain-mae:206.20922\teval-mae:182.57907\n",
      "[18]\ttrain-mae:199.74358\teval-mae:176.63054\n",
      "[19]\ttrain-mae:193.56542\teval-mae:171.00853\n",
      "[20]\ttrain-mae:187.85561\teval-mae:165.76284\n",
      "[21]\ttrain-mae:182.43327\teval-mae:160.91161\n",
      "[22]\ttrain-mae:177.30652\teval-mae:156.11713\n",
      "[23]\ttrain-mae:172.46042\teval-mae:151.68600\n",
      "[24]\ttrain-mae:167.95608\teval-mae:147.39305\n",
      "[25]\ttrain-mae:163.66523\teval-mae:143.42788\n",
      "[26]\ttrain-mae:159.64401\teval-mae:139.58790\n",
      "[27]\ttrain-mae:155.87950\teval-mae:136.06595\n",
      "[28]\ttrain-mae:152.28809\teval-mae:132.64840\n",
      "[29]\ttrain-mae:148.91363\teval-mae:129.60709\n",
      "[30]\ttrain-mae:145.83760\teval-mae:126.64765\n",
      "[31]\ttrain-mae:142.80112\teval-mae:123.64516\n",
      "[32]\ttrain-mae:139.95073\teval-mae:120.88365\n",
      "[33]\ttrain-mae:137.24746\teval-mae:118.30406\n",
      "[34]\ttrain-mae:134.66509\teval-mae:115.90952\n",
      "[35]\ttrain-mae:132.30442\teval-mae:113.49494\n",
      "[36]\ttrain-mae:130.06955\teval-mae:111.43243\n",
      "[37]\ttrain-mae:127.87850\teval-mae:109.34755\n",
      "[38]\ttrain-mae:125.81401\teval-mae:107.40521\n",
      "[39]\ttrain-mae:123.85263\teval-mae:105.61457\n",
      "[40]\ttrain-mae:122.05476\teval-mae:103.88164\n",
      "[41]\ttrain-mae:120.29870\teval-mae:102.17115\n",
      "[42]\ttrain-mae:118.67005\teval-mae:100.62013\n",
      "[43]\ttrain-mae:117.08873\teval-mae:99.05333\n",
      "[44]\ttrain-mae:115.61234\teval-mae:97.61041\n",
      "[45]\ttrain-mae:114.24285\teval-mae:96.26771\n",
      "[46]\ttrain-mae:112.88733\teval-mae:94.85164\n",
      "[47]\ttrain-mae:111.66063\teval-mae:93.72111\n",
      "[48]\ttrain-mae:110.46925\teval-mae:92.47091\n",
      "[49]\ttrain-mae:109.32371\teval-mae:91.35090\n",
      "[50]\ttrain-mae:108.23351\teval-mae:90.24244\n",
      "[51]\ttrain-mae:107.17763\teval-mae:89.32720\n",
      "[52]\ttrain-mae:106.22550\teval-mae:88.30372\n",
      "[53]\ttrain-mae:105.30532\teval-mae:87.42298\n",
      "[54]\ttrain-mae:104.39901\teval-mae:86.63783\n",
      "[55]\ttrain-mae:103.55148\teval-mae:85.88218\n",
      "[56]\ttrain-mae:102.73317\teval-mae:85.05868\n",
      "[57]\ttrain-mae:101.96426\teval-mae:84.33197\n",
      "[58]\ttrain-mae:101.29480\teval-mae:83.73911\n",
      "[59]\ttrain-mae:100.60879\teval-mae:83.04310\n",
      "[60]\ttrain-mae:99.89402\teval-mae:82.43282\n",
      "[61]\ttrain-mae:99.26755\teval-mae:81.94727\n",
      "[62]\ttrain-mae:98.67753\teval-mae:81.42143\n",
      "[63]\ttrain-mae:98.09074\teval-mae:80.88221\n",
      "[64]\ttrain-mae:97.51527\teval-mae:80.38451\n",
      "[65]\ttrain-mae:96.94719\teval-mae:79.92575\n",
      "[66]\ttrain-mae:96.44590\teval-mae:79.50271\n",
      "[67]\ttrain-mae:95.95345\teval-mae:79.11743\n",
      "[68]\ttrain-mae:95.51119\teval-mae:78.64960\n",
      "[69]\ttrain-mae:95.05650\teval-mae:78.28089\n",
      "[70]\ttrain-mae:94.64190\teval-mae:77.87159\n",
      "[71]\ttrain-mae:94.20321\teval-mae:77.50840\n",
      "[72]\ttrain-mae:93.80408\teval-mae:77.15228\n",
      "[73]\ttrain-mae:93.43012\teval-mae:76.86743\n",
      "[74]\ttrain-mae:93.02298\teval-mae:76.48129\n",
      "[75]\ttrain-mae:92.72998\teval-mae:76.18921\n",
      "[76]\ttrain-mae:92.38305\teval-mae:75.81947\n",
      "[77]\ttrain-mae:92.03395\teval-mae:75.46722\n",
      "[78]\ttrain-mae:91.71749\teval-mae:75.27124\n",
      "[79]\ttrain-mae:91.37077\teval-mae:74.96117\n",
      "[80]\ttrain-mae:91.05110\teval-mae:74.76957\n",
      "[81]\ttrain-mae:90.79293\teval-mae:75.13910\n",
      "[82]\ttrain-mae:90.52882\teval-mae:74.98730\n",
      "[83]\ttrain-mae:90.25805\teval-mae:74.69502\n",
      "[84]\ttrain-mae:89.96253\teval-mae:74.33284\n",
      "[85]\ttrain-mae:89.78646\teval-mae:74.17755\n",
      "[86]\ttrain-mae:89.58976\teval-mae:74.11452\n",
      "[87]\ttrain-mae:89.37593\teval-mae:73.98362\n",
      "[88]\ttrain-mae:89.18955\teval-mae:73.86250\n",
      "[89]\ttrain-mae:88.96215\teval-mae:73.68021\n",
      "[90]\ttrain-mae:88.81827\teval-mae:73.47063\n",
      "[91]\ttrain-mae:88.62632\teval-mae:73.44447\n",
      "[92]\ttrain-mae:88.40956\teval-mae:73.31992\n",
      "[93]\ttrain-mae:88.18531\teval-mae:73.28182\n",
      "[94]\ttrain-mae:87.97147\teval-mae:73.23206\n",
      "[95]\ttrain-mae:87.75716\teval-mae:73.05993\n",
      "[96]\ttrain-mae:87.52485\teval-mae:72.97193\n",
      "[97]\ttrain-mae:87.43959\teval-mae:72.95868\n",
      "[98]\ttrain-mae:87.29001\teval-mae:72.97686\n",
      "[99]\ttrain-mae:87.14418\teval-mae:73.06064\n",
      "[100]\ttrain-mae:86.98273\teval-mae:72.96730\n",
      "[101]\ttrain-mae:86.82814\teval-mae:72.92858\n",
      "[102]\ttrain-mae:86.67918\teval-mae:73.09475\n",
      "[103]\ttrain-mae:86.55413\teval-mae:73.00291\n",
      "[104]\ttrain-mae:86.39767\teval-mae:72.91043\n",
      "[105]\ttrain-mae:86.22188\teval-mae:72.87108\n",
      "[106]\ttrain-mae:86.03673\teval-mae:72.74150\n",
      "[107]\ttrain-mae:85.92063\teval-mae:72.71265\n",
      "[108]\ttrain-mae:85.76516\teval-mae:72.66119\n",
      "[109]\ttrain-mae:85.62637\teval-mae:72.60763\n",
      "[110]\ttrain-mae:85.46256\teval-mae:72.57923\n",
      "[111]\ttrain-mae:85.33606\teval-mae:72.51039\n",
      "[112]\ttrain-mae:85.22137\teval-mae:72.51322\n",
      "[113]\ttrain-mae:85.12790\teval-mae:72.37016\n",
      "[114]\ttrain-mae:85.03329\teval-mae:72.35308\n",
      "[115]\ttrain-mae:84.90203\teval-mae:72.41017\n",
      "[116]\ttrain-mae:84.76117\teval-mae:72.39134\n",
      "[117]\ttrain-mae:84.58415\teval-mae:72.33554\n",
      "[118]\ttrain-mae:84.50803\teval-mae:72.38022\n",
      "[119]\ttrain-mae:84.40182\teval-mae:72.31198\n",
      "[120]\ttrain-mae:84.29025\teval-mae:72.26949\n",
      "[121]\ttrain-mae:84.22946\teval-mae:72.20904\n",
      "[122]\ttrain-mae:84.15543\teval-mae:72.21694\n",
      "[123]\ttrain-mae:84.08366\teval-mae:72.22107\n",
      "[124]\ttrain-mae:84.01840\teval-mae:71.99249\n",
      "[125]\ttrain-mae:83.95230\teval-mae:72.00878\n",
      "[126]\ttrain-mae:83.90405\teval-mae:71.99469\n",
      "[127]\ttrain-mae:83.83204\teval-mae:72.01653\n",
      "[128]\ttrain-mae:83.68279\teval-mae:72.13340\n",
      "[129]\ttrain-mae:83.59316\teval-mae:72.08488\n",
      "[130]\ttrain-mae:83.49560\teval-mae:72.02575\n",
      "[131]\ttrain-mae:83.40332\teval-mae:71.92515\n",
      "[132]\ttrain-mae:83.30643\teval-mae:71.95182\n",
      "[133]\ttrain-mae:83.20537\teval-mae:71.87870\n",
      "[134]\ttrain-mae:83.10798\teval-mae:71.82668\n",
      "[135]\ttrain-mae:83.04252\teval-mae:72.03023\n",
      "[136]\ttrain-mae:82.98431\teval-mae:72.03752\n",
      "[137]\ttrain-mae:82.89897\teval-mae:71.99937\n",
      "[138]\ttrain-mae:82.78581\teval-mae:72.00009\n",
      "[139]\ttrain-mae:82.70416\teval-mae:72.04056\n",
      "[140]\ttrain-mae:82.58558\teval-mae:72.03055\n",
      "[141]\ttrain-mae:82.44215\teval-mae:71.87291\n",
      "[142]\ttrain-mae:82.39257\teval-mae:71.85165\n",
      "[143]\ttrain-mae:82.33926\teval-mae:72.09019\n",
      "[144]\ttrain-mae:82.30153\teval-mae:72.26073\n",
      "[145]\ttrain-mae:82.25191\teval-mae:72.35795\n",
      "[146]\ttrain-mae:82.17570\teval-mae:72.35589\n",
      "[147]\ttrain-mae:82.14436\teval-mae:72.39543\n",
      "[148]\ttrain-mae:82.05023\teval-mae:72.26627\n",
      "[149]\ttrain-mae:81.98783\teval-mae:72.22858\n",
      "[150]\ttrain-mae:81.91694\teval-mae:72.20190\n",
      "[151]\ttrain-mae:81.79270\teval-mae:72.23951\n",
      "[152]\ttrain-mae:81.74925\teval-mae:72.26531\n",
      "[153]\ttrain-mae:81.71549\teval-mae:72.24510\n",
      "[154]\ttrain-mae:81.61347\teval-mae:72.22957\n",
      "[155]\ttrain-mae:81.53984\teval-mae:72.16421\n",
      "[156]\ttrain-mae:81.46124\teval-mae:72.20586\n",
      "[157]\ttrain-mae:81.37032\teval-mae:72.18639\n",
      "[158]\ttrain-mae:81.29595\teval-mae:72.19797\n",
      "[159]\ttrain-mae:81.24101\teval-mae:72.23064\n",
      "[160]\ttrain-mae:81.16019\teval-mae:72.00572\n",
      "[161]\ttrain-mae:81.06497\teval-mae:71.96935\n",
      "[162]\ttrain-mae:80.97997\teval-mae:72.04753\n",
      "[163]\ttrain-mae:80.85656\teval-mae:72.03556\n",
      "[164]\ttrain-mae:80.76853\teval-mae:72.03841\n",
      "[165]\ttrain-mae:80.70957\teval-mae:71.82050\n",
      "[166]\ttrain-mae:80.65072\teval-mae:71.86089\n",
      "[167]\ttrain-mae:80.61130\teval-mae:71.88159\n",
      "[168]\ttrain-mae:80.55273\teval-mae:71.95385\n",
      "[169]\ttrain-mae:80.49156\teval-mae:71.97506\n",
      "[170]\ttrain-mae:80.36425\teval-mae:71.96152\n",
      "[171]\ttrain-mae:80.25753\teval-mae:71.90941\n",
      "[172]\ttrain-mae:80.20000\teval-mae:71.88570\n",
      "[173]\ttrain-mae:80.13860\teval-mae:71.46594\n",
      "[174]\ttrain-mae:80.01774\teval-mae:71.37679\n",
      "[175]\ttrain-mae:79.92556\teval-mae:71.39881\n",
      "[176]\ttrain-mae:79.84652\teval-mae:71.52144\n",
      "[177]\ttrain-mae:79.78678\teval-mae:71.48741\n",
      "[178]\ttrain-mae:79.73917\teval-mae:71.45778\n",
      "[179]\ttrain-mae:79.67048\teval-mae:71.78451\n",
      "[180]\ttrain-mae:79.61373\teval-mae:71.80962\n",
      "[181]\ttrain-mae:79.52755\teval-mae:71.80339\n",
      "[182]\ttrain-mae:79.42654\teval-mae:71.83864\n",
      "[183]\ttrain-mae:79.34058\teval-mae:71.82006\n",
      "[184]\ttrain-mae:79.28294\teval-mae:71.78377\n",
      "[185]\ttrain-mae:79.20440\teval-mae:71.76264\n",
      "[186]\ttrain-mae:79.12447\teval-mae:71.66137\n",
      "[187]\ttrain-mae:79.06964\teval-mae:71.65907\n",
      "[188]\ttrain-mae:79.01850\teval-mae:71.63968\n",
      "[189]\ttrain-mae:78.96977\teval-mae:71.65514\n",
      "[190]\ttrain-mae:78.86709\teval-mae:71.57677\n",
      "[191]\ttrain-mae:78.78626\teval-mae:71.56033\n",
      "[192]\ttrain-mae:78.72802\teval-mae:71.57093\n",
      "[193]\ttrain-mae:78.69615\teval-mae:71.24905\n",
      "[194]\ttrain-mae:78.56645\teval-mae:71.21990\n",
      "[195]\ttrain-mae:78.52346\teval-mae:71.20390\n",
      "[196]\ttrain-mae:78.44909\teval-mae:71.21923\n",
      "[197]\ttrain-mae:78.40702\teval-mae:71.23862\n",
      "[198]\ttrain-mae:78.35784\teval-mae:71.16229\n",
      "[199]\ttrain-mae:78.24783\teval-mae:71.18275\n",
      "[200]\ttrain-mae:78.18641\teval-mae:71.17216\n",
      "[201]\ttrain-mae:78.12917\teval-mae:71.12901\n",
      "[202]\ttrain-mae:78.02726\teval-mae:71.09649\n",
      "[203]\ttrain-mae:77.97807\teval-mae:71.09035\n",
      "[204]\ttrain-mae:77.91396\teval-mae:71.13910\n",
      "[205]\ttrain-mae:77.86270\teval-mae:71.14982\n",
      "[206]\ttrain-mae:77.79941\teval-mae:71.16572\n",
      "[207]\ttrain-mae:77.73056\teval-mae:71.14678\n",
      "[208]\ttrain-mae:77.63432\teval-mae:71.08640\n",
      "[209]\ttrain-mae:77.52949\teval-mae:71.16875\n",
      "[210]\ttrain-mae:77.46786\teval-mae:71.24206\n",
      "[211]\ttrain-mae:77.43684\teval-mae:71.47841\n",
      "[212]\ttrain-mae:77.38935\teval-mae:71.48968\n",
      "[213]\ttrain-mae:77.29483\teval-mae:71.25805\n",
      "[214]\ttrain-mae:77.24326\teval-mae:71.31630\n",
      "[215]\ttrain-mae:77.16474\teval-mae:71.19877\n",
      "[216]\ttrain-mae:77.11059\teval-mae:71.11064\n",
      "[217]\ttrain-mae:77.06116\teval-mae:71.11073\n",
      "[218]\ttrain-mae:76.97922\teval-mae:71.07204\n",
      "[219]\ttrain-mae:76.93053\teval-mae:71.08011\n",
      "[220]\ttrain-mae:76.89810\teval-mae:70.92863\n",
      "[221]\ttrain-mae:76.88947\teval-mae:71.13218\n",
      "[222]\ttrain-mae:76.82241\teval-mae:71.15847\n",
      "[223]\ttrain-mae:76.77458\teval-mae:71.18375\n",
      "[224]\ttrain-mae:76.70933\teval-mae:71.15209\n",
      "[225]\ttrain-mae:76.65010\teval-mae:71.06906\n",
      "[226]\ttrain-mae:76.56730\teval-mae:71.02673\n",
      "[227]\ttrain-mae:76.51444\teval-mae:70.96031\n",
      "[228]\ttrain-mae:76.44786\teval-mae:70.97453\n",
      "[229]\ttrain-mae:76.39792\teval-mae:70.96926\n",
      "[230]\ttrain-mae:76.35906\teval-mae:70.99250\n",
      "[231]\ttrain-mae:76.32727\teval-mae:71.00820\n",
      "[232]\ttrain-mae:76.27343\teval-mae:70.98217\n",
      "[233]\ttrain-mae:76.23241\teval-mae:71.01236\n",
      "[234]\ttrain-mae:76.18350\teval-mae:70.93961\n",
      "[235]\ttrain-mae:76.11398\teval-mae:70.96415\n",
      "[236]\ttrain-mae:76.07132\teval-mae:70.97272\n",
      "[237]\ttrain-mae:76.01217\teval-mae:70.93505\n",
      "[238]\ttrain-mae:75.95292\teval-mae:70.93214\n",
      "[239]\ttrain-mae:75.88901\teval-mae:71.10904\n",
      "[240]\ttrain-mae:75.79134\teval-mae:71.05676\n",
      "[241]\ttrain-mae:75.75484\teval-mae:71.03942\n",
      "[242]\ttrain-mae:75.69879\teval-mae:70.89792\n",
      "[243]\ttrain-mae:75.65492\teval-mae:70.80253\n",
      "[244]\ttrain-mae:75.58558\teval-mae:70.80167\n",
      "[245]\ttrain-mae:75.56300\teval-mae:70.84084\n",
      "[246]\ttrain-mae:75.52349\teval-mae:70.86005\n",
      "[247]\ttrain-mae:75.42270\teval-mae:70.85412\n",
      "[248]\ttrain-mae:75.36991\teval-mae:71.22671\n",
      "[249]\ttrain-mae:75.34956\teval-mae:71.17300\n",
      "[250]\ttrain-mae:75.28229\teval-mae:71.14739\n",
      "[251]\ttrain-mae:75.19823\teval-mae:71.13332\n",
      "[252]\ttrain-mae:75.15624\teval-mae:71.14281\n",
      "[253]\ttrain-mae:75.12797\teval-mae:71.03363\n",
      "[254]\ttrain-mae:75.11365\teval-mae:71.22673\n",
      "[255]\ttrain-mae:75.06244\teval-mae:71.25757\n",
      "[256]\ttrain-mae:74.99838\teval-mae:71.22035\n",
      "[257]\ttrain-mae:74.94292\teval-mae:71.20167\n",
      "[258]\ttrain-mae:74.90079\teval-mae:71.23559\n",
      "[259]\ttrain-mae:74.81784\teval-mae:71.23982\n",
      "[260]\ttrain-mae:74.76704\teval-mae:71.23683\n",
      "[261]\ttrain-mae:74.69106\teval-mae:71.23164\n",
      "[262]\ttrain-mae:74.60776\teval-mae:71.50443\n",
      "[263]\ttrain-mae:74.52854\teval-mae:71.51509\n",
      "[264]\ttrain-mae:74.47024\teval-mae:71.34510\n",
      "[265]\ttrain-mae:74.39102\teval-mae:71.32897\n",
      "[266]\ttrain-mae:74.35444\teval-mae:71.34993\n",
      "[267]\ttrain-mae:74.31641\teval-mae:71.37339\n",
      "[268]\ttrain-mae:74.25606\teval-mae:71.35189\n",
      "[269]\ttrain-mae:74.19180\teval-mae:71.42114\n",
      "[270]\ttrain-mae:74.13413\teval-mae:71.44881\n",
      "[271]\ttrain-mae:74.11480\teval-mae:71.43719\n",
      "[272]\ttrain-mae:74.06316\teval-mae:71.46921\n",
      "[273]\ttrain-mae:73.98526\teval-mae:71.47361\n",
      "[274]\ttrain-mae:73.91729\teval-mae:71.46418\n",
      "[275]\ttrain-mae:73.82955\teval-mae:71.55258\n",
      "[276]\ttrain-mae:73.74951\teval-mae:71.61987\n",
      "[277]\ttrain-mae:73.67900\teval-mae:71.59371\n",
      "[278]\ttrain-mae:73.62468\teval-mae:71.60900\n",
      "[279]\ttrain-mae:73.56625\teval-mae:71.64131\n",
      "[280]\ttrain-mae:73.51769\teval-mae:71.64310\n",
      "[281]\ttrain-mae:73.48691\teval-mae:71.80548\n",
      "[282]\ttrain-mae:73.45617\teval-mae:71.82059\n",
      "[283]\ttrain-mae:73.41725\teval-mae:71.86103\n",
      "[284]\ttrain-mae:73.34079\teval-mae:71.84636\n",
      "[285]\ttrain-mae:73.28223\teval-mae:71.83833\n",
      "[286]\ttrain-mae:73.25773\teval-mae:72.00766\n",
      "[287]\ttrain-mae:73.22152\teval-mae:72.02950\n",
      "[288]\ttrain-mae:73.16271\teval-mae:72.03366\n",
      "[289]\ttrain-mae:73.09749\teval-mae:72.11477\n",
      "[290]\ttrain-mae:73.04727\teval-mae:72.06892\n",
      "[291]\ttrain-mae:73.00599\teval-mae:72.08861\n",
      "[292]\ttrain-mae:72.93390\teval-mae:72.09849\n",
      "[293]\ttrain-mae:72.85456\teval-mae:72.13450\n",
      "Best MAE: 70.80 with 245 rounds\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    evals_result=progress\n",
    ")\n",
    "\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "         bst.best_score,\n",
    "         bst.best_iteration+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.2806997 ,  2.3543084 ,  2.9639523 , ...,  1.544247  ,\n",
       "        0.22856957, -1.0557479 ], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = bst.predict(test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Convert the numpy array to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, columns=['prediction'])\n",
    "\n",
    "# Join the 'id' column from sample_submission with the predictions\n",
    "sample_submission['prediction'] = predictions_df['prediction']\n",
    "\n",
    "# Save to CSV\n",
    "sample_submission.to_csv('my_first_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
